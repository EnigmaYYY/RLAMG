//
// Generated by LLVM NVPTX Back-End
//

.version 8.4
.target sm_89
.address_size 64

	// .globl	_fwd_kernel             // -- Begin function _fwd_kernel
.extern .shared .align 16 .b8 global_smem[];
                                        // @_fwd_kernel
.visible .entry _fwd_kernel(
	.param .u64 .ptr .global .align 1 _fwd_kernel_param_0,
	.param .u64 .ptr .global .align 1 _fwd_kernel_param_1,
	.param .u64 .ptr .global .align 1 _fwd_kernel_param_2,
	.param .u64 .ptr .global .align 1 _fwd_kernel_param_3,
	.param .u64 .ptr .global .align 1 _fwd_kernel_param_4,
	.param .u64 .ptr .global .align 1 _fwd_kernel_param_5,
	.param .f32 _fwd_kernel_param_6,
	.param .u64 .ptr .global .align 1 _fwd_kernel_param_7,
	.param .u64 .ptr .global .align 1 _fwd_kernel_param_8,
	.param .u64 .ptr .global .align 1 _fwd_kernel_param_9,
	.param .u64 .ptr .global .align 1 _fwd_kernel_param_10,
	.param .u64 .ptr .global .align 1 _fwd_kernel_param_11,
	.param .u32 _fwd_kernel_param_12,
	.param .u32 _fwd_kernel_param_13,
	.param .u32 _fwd_kernel_param_14,
	.param .u32 _fwd_kernel_param_15,
	.param .u32 _fwd_kernel_param_16,
	.param .u32 _fwd_kernel_param_17,
	.param .u32 _fwd_kernel_param_18,
	.param .u32 _fwd_kernel_param_19,
	.param .u32 _fwd_kernel_param_20,
	.param .u32 _fwd_kernel_param_21,
	.param .u32 _fwd_kernel_param_22,
	.param .u32 _fwd_kernel_param_23,
	.param .u32 _fwd_kernel_param_24,
	.param .u32 _fwd_kernel_param_25,
	.param .u32 _fwd_kernel_param_26
)
.reqntid 128, 1, 1
{
	.reg .pred 	%p<626>;
	.reg .b16 	%rs<865>;
	.reg .b32 	%r<7410>;
	.reg .f32 	%f<9064>;
	.reg .b64 	%rd<552>;
	.loc	1 36 0                          // prefix_prefill.py:36:0
$L__func_begin0:
	.loc	1 36 0                          // prefix_prefill.py:36:0

// %bb.0:
	ld.param.u32 	%r673, [_fwd_kernel_param_24];
	ld.param.u32 	%r672, [_fwd_kernel_param_21];
	ld.param.f32 	%f2401, [_fwd_kernel_param_6];
	ld.param.u64 	%rd111, [_fwd_kernel_param_4];
	ld.param.u64 	%rd110, [_fwd_kernel_param_3];
	ld.param.u64 	%rd132, [_fwd_kernel_param_0];
$L__tmp0:
	.loc	1 86 30                         // prefix_prefill.py:86:30
	// begin inline asm
	mov.u32 %r674, %ctaid.x;
	// end inline asm
	.loc	1 87 29                         // prefix_prefill.py:87:29
	// begin inline asm
	mov.u32 %r675, %ctaid.y;
	// end inline asm
	.loc	1 88 28                         // prefix_prefill.py:88:28
	// begin inline asm
	mov.u32 %r676, %ctaid.z;
	// end inline asm
	.loc	1 90 30                         // prefix_prefill.py:90:30
	mul.hi.s32 	%r808, %r675, 715827883;
	shr.u32 	%r809, %r808, 31;
	add.s32 	%r2, %r808, %r809;
	ld.param.u64 	%rd133, [_fwd_kernel_param_5];
	.loc	1 92 43                         // prefix_prefill.py:92:43
	mul.wide.s32 	%rd134, %r674, 4;
	ld.param.u64 	%rd135, [_fwd_kernel_param_10];
	add.s64 	%rd113, %rd135, %rd134;
	mov.pred 	%p546, -1;
	.loc	1 92 32                         // prefix_prefill.py:92:32
	// begin inline asm
	mov.u32 %r677, 0x0;
	@%p546 ld.global.b32 { %r677 }, [ %rd113 + 0 ];
	// end inline asm
	ld.param.u64 	%rd136, [_fwd_kernel_param_9];
	.loc	1 93 57                         // prefix_prefill.py:93:57
	add.s64 	%rd114, %rd136, %rd134;
	.loc	1 93 43                         // prefix_prefill.py:93:43
	// begin inline asm
	mov.u32 %r678, 0x0;
	@%p546 ld.global.b32 { %r678 }, [ %rd114 + 0 ];
	// end inline asm
	.loc	1 94 68                         // prefix_prefill.py:94:68
	add.s64 	%rd115, %rd114, 4;
	.loc	1 94 42                         // prefix_prefill.py:94:42
	// begin inline asm
	mov.u32 %r679, 0x0;
	@%p546 ld.global.b32 { %r679 }, [ %rd115 + 0 ];
	// end inline asm
	.loc	1 96 27                         // prefix_prefill.py:96:27
	sub.s32 	%r4, %r679, %r678;
	ld.param.u32 	%r810, [_fwd_kernel_param_12];
	.loc	1 97 44                         // prefix_prefill.py:97:44
	sub.s32 	%r5, %r677, %r4;
	ld.param.u32 	%r811, [_fwd_kernel_param_13];
	.loc	1 104 32                        // prefix_prefill.py:104:32
	shl.b32 	%r6, %r676, 7;
	ld.param.u32 	%r812, [_fwd_kernel_param_14];
	.loc	1 112 26                        // prefix_prefill.py:112:26
	mov.u32 	%r7, %tid.x;
	and.b32  	%r8, %r7, 31;
	shr.u32 	%r9, %r7, 5;
	and.b32  	%r10, %r7, 32;
	and.b32  	%r11, %r7, 64;
	bfe.u32 	%r12, %r7, 4, 3;
	or.b32  	%r13, %r12, 8;
	ld.param.u32 	%r813, [_fwd_kernel_param_22];
	or.b32  	%r14, %r12, 16;
	ld.param.u32 	%r814, [_fwd_kernel_param_23];
	or.b32  	%r15, %r12, 24;
	ld.param.u32 	%r815, [_fwd_kernel_param_25];
	ld.param.u32 	%r816, [_fwd_kernel_param_26];
	or.b32  	%r16, %r12, 56;
	or.b32  	%r17, %r12, 48;
	or.b32  	%r18, %r12, 40;
	or.b32  	%r19, %r12, 32;
	shl.b32 	%r20, %r7, 3;
	and.b32  	%r21, %r20, 8;
	and.b32  	%r22, %r7, 8;
	and.b32  	%r23, %r20, 120;
	shr.u32 	%r818, %r10, 1;
	shr.u32 	%r820, %r11, 1;
	shr.u32 	%r822, %r7, 1;
	and.b32  	%r823, %r822, 8;
	bfe.u32 	%r824, %r7, 1, 4;
	or.b32  	%r825, %r824, %r818;
	or.b32  	%r24, %r825, %r820;
	.loc	1 114 33                        // prefix_prefill.py:114:33
	or.b32  	%r25, %r6, %r12;
	or.b32  	%r26, %r6, %r13;
	or.b32  	%r27, %r6, %r14;
	or.b32  	%r28, %r6, %r15;
	or.b32  	%r30, %r6, %r19;
	or.b32  	%r32, %r6, %r18;
	or.b32  	%r34, %r6, %r17;
	or.b32  	%r36, %r6, %r16;
	or.b32  	%r37, %r25, 64;
	or.b32  	%r38, %r25, 72;
	or.b32  	%r39, %r25, 80;
	or.b32  	%r40, %r25, 88;
	or.b32  	%r41, %r25, 96;
	or.b32  	%r42, %r25, 104;
	or.b32  	%r43, %r25, 112;
	or.b32  	%r44, %r25, 120;
	.loc	1 116 45                        // prefix_prefill.py:116:45
	add.s32 	%r49, %r678, %r25;
	add.s32 	%r50, %r678, %r26;
	add.s32 	%r51, %r678, %r27;
	add.s32 	%r52, %r678, %r28;
	add.s32 	%r53, %r678, %r30;
	add.s32 	%r54, %r678, %r32;
	add.s32 	%r55, %r678, %r34;
	add.s32 	%r56, %r678, %r36;
	add.s32 	%r57, %r678, %r37;
	add.s32 	%r58, %r678, %r38;
	add.s32 	%r59, %r678, %r39;
	add.s32 	%r60, %r678, %r40;
	add.s32 	%r61, %r678, %r41;
	add.s32 	%r62, %r678, %r42;
	add.s32 	%r63, %r678, %r43;
	add.s32 	%r64, %r678, %r44;
	.loc	1 117 13                        // prefix_prefill.py:117:13
	mad.lo.s32 	%r826, %r675, %r812, %r23;
	.loc	1 117 36                        // prefix_prefill.py:117:36
	mad.lo.s32 	%r827, %r49, %r811, %r826;
	mad.lo.s32 	%r828, %r50, %r811, %r826;
	mad.lo.s32 	%r829, %r51, %r811, %r826;
	mad.lo.s32 	%r830, %r52, %r811, %r826;
	mad.lo.s32 	%r831, %r53, %r811, %r826;
	mad.lo.s32 	%r832, %r54, %r811, %r826;
	mad.lo.s32 	%r833, %r55, %r811, %r826;
	mad.lo.s32 	%r834, %r56, %r811, %r826;
	mad.lo.s32 	%r835, %r57, %r811, %r826;
	mad.lo.s32 	%r836, %r58, %r811, %r826;
	mad.lo.s32 	%r837, %r59, %r811, %r826;
	mad.lo.s32 	%r838, %r60, %r811, %r826;
	mad.lo.s32 	%r839, %r61, %r811, %r826;
	mad.lo.s32 	%r840, %r62, %r811, %r826;
	mad.lo.s32 	%r841, %r63, %r811, %r826;
	mad.lo.s32 	%r842, %r64, %r811, %r826;
	.loc	1 125 35                        // prefix_prefill.py:125:35
	setp.lt.s32 	%p4, %r25, %r4;
	setp.lt.s32 	%p9, %r26, %r4;
	setp.lt.s32 	%p14, %r27, %r4;
	setp.lt.s32 	%p19, %r28, %r4;
	setp.lt.s32 	%p24, %r30, %r4;
	setp.lt.s32 	%p29, %r32, %r4;
	setp.lt.s32 	%p34, %r34, %r4;
	setp.lt.s32 	%p39, %r36, %r4;
	setp.lt.s32 	%p44, %r37, %r4;
	setp.lt.s32 	%p49, %r38, %r4;
	setp.lt.s32 	%p54, %r39, %r4;
	setp.lt.s32 	%p59, %r40, %r4;
	setp.lt.s32 	%p64, %r41, %r4;
	setp.lt.s32 	%p69, %r42, %r4;
	setp.lt.s32 	%p74, %r43, %r4;
	setp.lt.s32 	%p79, %r44, %r4;
	.loc	1 123 20                        // prefix_prefill.py:123:20
	mul.wide.s32 	%rd137, %r827, 2;
	add.s64 	%rd116, %rd132, %rd137;
	mul.wide.s32 	%rd138, %r828, 2;
	add.s64 	%rd117, %rd132, %rd138;
	mul.wide.s32 	%rd139, %r829, 2;
	add.s64 	%rd118, %rd132, %rd139;
	mul.wide.s32 	%rd140, %r830, 2;
	add.s64 	%rd119, %rd132, %rd140;
	mul.wide.s32 	%rd141, %r831, 2;
	add.s64 	%rd120, %rd132, %rd141;
	mul.wide.s32 	%rd142, %r832, 2;
	add.s64 	%rd121, %rd132, %rd142;
	mul.wide.s32 	%rd143, %r833, 2;
	add.s64 	%rd122, %rd132, %rd143;
	mul.wide.s32 	%rd144, %r834, 2;
	add.s64 	%rd123, %rd132, %rd144;
	mul.wide.s32 	%rd145, %r835, 2;
	add.s64 	%rd124, %rd132, %rd145;
	mul.wide.s32 	%rd146, %r836, 2;
	add.s64 	%rd125, %rd132, %rd146;
	mul.wide.s32 	%rd147, %r837, 2;
	add.s64 	%rd126, %rd132, %rd147;
	mul.wide.s32 	%rd148, %r838, 2;
	add.s64 	%rd127, %rd132, %rd148;
	mul.wide.s32 	%rd149, %r839, 2;
	add.s64 	%rd128, %rd132, %rd149;
	mul.wide.s32 	%rd150, %r840, 2;
	add.s64 	%rd129, %rd132, %rd150;
	mul.wide.s32 	%rd151, %r841, 2;
	add.s64 	%rd130, %rd132, %rd151;
	mul.wide.s32 	%rd152, %r842, 2;
	add.s64 	%rd131, %rd132, %rd152;
	mov.b32 	%r684, 0;
	.loc	1 123 16                        // prefix_prefill.py:123:16
	// begin inline asm
	mov.u32 %r680, 0x0;
	mov.u32 %r681, 0x0;
	mov.u32 %r682, 0x0;
	mov.u32 %r683, 0x0;
	@%p4 ld.global.v4.b32 { %r680, %r681, %r682, %r683 }, [ %rd116 + 0 ];
	@!%p4 mov.u32 %r680, %r684;
	@!%p4 mov.u32 %r681, %r684;
	@!%p4 mov.u32 %r682, %r684;
	@!%p4 mov.u32 %r683, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r688, 0x0;
	mov.u32 %r689, 0x0;
	mov.u32 %r690, 0x0;
	mov.u32 %r691, 0x0;
	@%p9 ld.global.v4.b32 { %r688, %r689, %r690, %r691 }, [ %rd117 + 0 ];
	@!%p9 mov.u32 %r688, %r684;
	@!%p9 mov.u32 %r689, %r684;
	@!%p9 mov.u32 %r690, %r684;
	@!%p9 mov.u32 %r691, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r696, 0x0;
	mov.u32 %r697, 0x0;
	mov.u32 %r698, 0x0;
	mov.u32 %r699, 0x0;
	@%p14 ld.global.v4.b32 { %r696, %r697, %r698, %r699 }, [ %rd118 + 0 ];
	@!%p14 mov.u32 %r696, %r684;
	@!%p14 mov.u32 %r697, %r684;
	@!%p14 mov.u32 %r698, %r684;
	@!%p14 mov.u32 %r699, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r704, 0x0;
	mov.u32 %r705, 0x0;
	mov.u32 %r706, 0x0;
	mov.u32 %r707, 0x0;
	@%p19 ld.global.v4.b32 { %r704, %r705, %r706, %r707 }, [ %rd119 + 0 ];
	@!%p19 mov.u32 %r704, %r684;
	@!%p19 mov.u32 %r705, %r684;
	@!%p19 mov.u32 %r706, %r684;
	@!%p19 mov.u32 %r707, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r712, 0x0;
	mov.u32 %r713, 0x0;
	mov.u32 %r714, 0x0;
	mov.u32 %r715, 0x0;
	@%p24 ld.global.v4.b32 { %r712, %r713, %r714, %r715 }, [ %rd120 + 0 ];
	@!%p24 mov.u32 %r712, %r684;
	@!%p24 mov.u32 %r713, %r684;
	@!%p24 mov.u32 %r714, %r684;
	@!%p24 mov.u32 %r715, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r720, 0x0;
	mov.u32 %r721, 0x0;
	mov.u32 %r722, 0x0;
	mov.u32 %r723, 0x0;
	@%p29 ld.global.v4.b32 { %r720, %r721, %r722, %r723 }, [ %rd121 + 0 ];
	@!%p29 mov.u32 %r720, %r684;
	@!%p29 mov.u32 %r721, %r684;
	@!%p29 mov.u32 %r722, %r684;
	@!%p29 mov.u32 %r723, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r728, 0x0;
	mov.u32 %r729, 0x0;
	mov.u32 %r730, 0x0;
	mov.u32 %r731, 0x0;
	@%p34 ld.global.v4.b32 { %r728, %r729, %r730, %r731 }, [ %rd122 + 0 ];
	@!%p34 mov.u32 %r728, %r684;
	@!%p34 mov.u32 %r729, %r684;
	@!%p34 mov.u32 %r730, %r684;
	@!%p34 mov.u32 %r731, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r736, 0x0;
	mov.u32 %r737, 0x0;
	mov.u32 %r738, 0x0;
	mov.u32 %r739, 0x0;
	@%p39 ld.global.v4.b32 { %r736, %r737, %r738, %r739 }, [ %rd123 + 0 ];
	@!%p39 mov.u32 %r736, %r684;
	@!%p39 mov.u32 %r737, %r684;
	@!%p39 mov.u32 %r738, %r684;
	@!%p39 mov.u32 %r739, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r744, 0x0;
	mov.u32 %r745, 0x0;
	mov.u32 %r746, 0x0;
	mov.u32 %r747, 0x0;
	@%p44 ld.global.v4.b32 { %r744, %r745, %r746, %r747 }, [ %rd124 + 0 ];
	@!%p44 mov.u32 %r744, %r684;
	@!%p44 mov.u32 %r745, %r684;
	@!%p44 mov.u32 %r746, %r684;
	@!%p44 mov.u32 %r747, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r752, 0x0;
	mov.u32 %r753, 0x0;
	mov.u32 %r754, 0x0;
	mov.u32 %r755, 0x0;
	@%p49 ld.global.v4.b32 { %r752, %r753, %r754, %r755 }, [ %rd125 + 0 ];
	@!%p49 mov.u32 %r752, %r684;
	@!%p49 mov.u32 %r753, %r684;
	@!%p49 mov.u32 %r754, %r684;
	@!%p49 mov.u32 %r755, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r760, 0x0;
	mov.u32 %r761, 0x0;
	mov.u32 %r762, 0x0;
	mov.u32 %r763, 0x0;
	@%p54 ld.global.v4.b32 { %r760, %r761, %r762, %r763 }, [ %rd126 + 0 ];
	@!%p54 mov.u32 %r760, %r684;
	@!%p54 mov.u32 %r761, %r684;
	@!%p54 mov.u32 %r762, %r684;
	@!%p54 mov.u32 %r763, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r768, 0x0;
	mov.u32 %r769, 0x0;
	mov.u32 %r770, 0x0;
	mov.u32 %r771, 0x0;
	@%p59 ld.global.v4.b32 { %r768, %r769, %r770, %r771 }, [ %rd127 + 0 ];
	@!%p59 mov.u32 %r768, %r684;
	@!%p59 mov.u32 %r769, %r684;
	@!%p59 mov.u32 %r770, %r684;
	@!%p59 mov.u32 %r771, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r776, 0x0;
	mov.u32 %r777, 0x0;
	mov.u32 %r778, 0x0;
	mov.u32 %r779, 0x0;
	@%p64 ld.global.v4.b32 { %r776, %r777, %r778, %r779 }, [ %rd128 + 0 ];
	@!%p64 mov.u32 %r776, %r684;
	@!%p64 mov.u32 %r777, %r684;
	@!%p64 mov.u32 %r778, %r684;
	@!%p64 mov.u32 %r779, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r784, 0x0;
	mov.u32 %r785, 0x0;
	mov.u32 %r786, 0x0;
	mov.u32 %r787, 0x0;
	@%p69 ld.global.v4.b32 { %r784, %r785, %r786, %r787 }, [ %rd129 + 0 ];
	@!%p69 mov.u32 %r784, %r684;
	@!%p69 mov.u32 %r785, %r684;
	@!%p69 mov.u32 %r786, %r684;
	@!%p69 mov.u32 %r787, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r792, 0x0;
	mov.u32 %r793, 0x0;
	mov.u32 %r794, 0x0;
	mov.u32 %r795, 0x0;
	@%p74 ld.global.v4.b32 { %r792, %r793, %r794, %r795 }, [ %rd130 + 0 ];
	@!%p74 mov.u32 %r792, %r684;
	@!%p74 mov.u32 %r793, %r684;
	@!%p74 mov.u32 %r794, %r684;
	@!%p74 mov.u32 %r795, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r800, 0x0;
	mov.u32 %r801, 0x0;
	mov.u32 %r802, 0x0;
	mov.u32 %r803, 0x0;
	@%p79 ld.global.v4.b32 { %r800, %r801, %r802, %r803 }, [ %rd131 + 0 ];
	@!%p79 mov.u32 %r800, %r684;
	@!%p79 mov.u32 %r801, %r684;
	@!%p79 mov.u32 %r802, %r684;
	@!%p79 mov.u32 %r803, %r684;
	// end inline asm
	xor.b32  	%r907, %r23, %r823;
	xor.b32  	%r908, %r907, %r818;
	xor.b32  	%r909, %r908, %r820;
	shl.b32 	%r910, %r12, 7;
	or.b32  	%r65, %r909, %r910;
	shl.b32 	%r911, %r65, 1;
	mov.u32 	%r912, global_smem;
	add.s32 	%r913, %r912, %r911;
	st.shared.v4.b32 	[%r913], {%r680, %r681, %r682, %r683};
	st.shared.v4.b32 	[%r913+2048], {%r688, %r689, %r690, %r691};
	st.shared.v4.b32 	[%r913+4096], {%r696, %r697, %r698, %r699};
	st.shared.v4.b32 	[%r913+6144], {%r704, %r705, %r706, %r707};
	st.shared.v4.b32 	[%r913+8192], {%r712, %r713, %r714, %r715};
	st.shared.v4.b32 	[%r913+10240], {%r720, %r721, %r722, %r723};
	st.shared.v4.b32 	[%r913+12288], {%r728, %r729, %r730, %r731};
	st.shared.v4.b32 	[%r913+14336], {%r736, %r737, %r738, %r739};
	st.shared.v4.b32 	[%r913+16384], {%r744, %r745, %r746, %r747};
	st.shared.v4.b32 	[%r913+18432], {%r752, %r753, %r754, %r755};
	st.shared.v4.b32 	[%r913+20480], {%r760, %r761, %r762, %r763};
	st.shared.v4.b32 	[%r913+22528], {%r768, %r769, %r770, %r771};
	st.shared.v4.b32 	[%r913+24576], {%r776, %r777, %r778, %r779};
	st.shared.v4.b32 	[%r913+26624], {%r784, %r785, %r786, %r787};
	st.shared.v4.b32 	[%r913+28672], {%r792, %r793, %r794, %r795};
	st.shared.v4.b32 	[%r913+30720], {%r800, %r801, %r802, %r803};
	.loc	1 138 41                        // prefix_prefill.py:138:41
	mul.lo.s32 	%r914, %r674, %r810;
	.loc	1 138 29                        // prefix_prefill.py:138:29
	mul.wide.s32 	%rd153, %r914, 4;
	add.s64 	%rd1, %rd133, %rd153;
	.loc	1 142 60                        // prefix_prefill.py:142:60
	mul.lo.s32 	%r66, %r2, %r813;
	.loc	1 143 32                        // prefix_prefill.py:143:32
	bfe.u32 	%r915, %r20, 3, 4;
	.loc	1 143 37                        // prefix_prefill.py:143:37
	mul.lo.s32 	%r67, %r814, %r915;
	.loc	1 144 34                        // prefix_prefill.py:144:34
	shl.b32 	%r916, %r7, 1;
	and.b32  	%r68, %r916, 6;
	.loc	1 149 31                        // prefix_prefill.py:149:31
	mul.lo.s32 	%r917, %r2, %r815;
	.loc	1 150 35                        // prefix_prefill.py:150:35
	mul.lo.s32 	%r918, %r816, %r24;
	shl.b32 	%r919, %r816, 6;
	add.s32 	%r920, %r918, %r919;
	.loc	1 151 27                        // prefix_prefill.py:151:27
	or.b32  	%r70, %r21, 1;
	or.b32  	%r71, %r21, 2;
	or.b32  	%r72, %r21, 3;
	or.b32  	%r73, %r21, 4;
	or.b32  	%r74, %r21, 5;
	or.b32  	%r75, %r21, 6;
	or.b32  	%r76, %r21, 7;
	.loc	1 135 28                        // prefix_prefill.py:135:28
	add.s32 	%r921, %r5, 15;
	and.b32  	%r7391, %r921, -64;
	add.s32 	%r78, %r917, %r918;
	add.s32 	%r79, %r917, %r920;
	setp.lt.s32 	%p84, %r7391, 1;
	mov.f32 	%f8516, 0fFF800000;
	mov.f32 	%f8788, 0f3F800000;
	mov.f32 	%f8524, 0f00000000;
	add.s32 	%r7312, %r66, %r67;
	and.b32  	%r7313, %r7, 7;
	bfe.u32 	%r7314, %r7, 3, 1;
	shr.u32 	%r7315, %r8, 4;
	shl.b32 	%r7316, %r9, 1;
	xor.b32  	%r7317, %r21, %r22;
	shl.b32 	%r7318, %r24, 5;
	bfe.u32 	%r7319, %r7, 2, 1;
	mov.u16 	%rs258, 0;
	mov.f32 	%f8525, %f8524;
	mov.f32 	%f8526, %f8524;
	mov.f32 	%f8527, %f8524;
	mov.f32 	%f8528, %f8524;
	mov.f32 	%f8529, %f8524;
	mov.f32 	%f8530, %f8524;
	mov.f32 	%f8531, %f8524;
	mov.f32 	%f8532, %f8524;
	mov.f32 	%f8533, %f8524;
	mov.f32 	%f8534, %f8524;
	mov.f32 	%f8535, %f8524;
	mov.f32 	%f8536, %f8524;
	mov.f32 	%f8537, %f8524;
	mov.f32 	%f8538, %f8524;
	mov.f32 	%f8539, %f8524;
	mov.f32 	%f8540, %f8524;
	mov.f32 	%f8541, %f8524;
	mov.f32 	%f8542, %f8524;
	mov.f32 	%f8543, %f8524;
	mov.f32 	%f8544, %f8524;
	mov.f32 	%f8545, %f8524;
	mov.f32 	%f8546, %f8524;
	mov.f32 	%f8547, %f8524;
	mov.f32 	%f8548, %f8524;
	mov.f32 	%f8549, %f8524;
	mov.f32 	%f8550, %f8524;
	mov.f32 	%f8551, %f8524;
	mov.f32 	%f8552, %f8524;
	mov.f32 	%f8553, %f8524;
	mov.f32 	%f8554, %f8524;
	mov.f32 	%f8555, %f8524;
	mov.f32 	%f8556, %f8524;
	mov.f32 	%f8557, %f8524;
	mov.f32 	%f8558, %f8524;
	mov.f32 	%f8559, %f8524;
	mov.f32 	%f8560, %f8524;
	mov.f32 	%f8561, %f8524;
	mov.f32 	%f8562, %f8524;
	mov.f32 	%f8563, %f8524;
	mov.f32 	%f8564, %f8524;
	mov.f32 	%f8565, %f8524;
	mov.f32 	%f8566, %f8524;
	mov.f32 	%f8567, %f8524;
	mov.f32 	%f8568, %f8524;
	mov.f32 	%f8569, %f8524;
	mov.f32 	%f8570, %f8524;
	mov.f32 	%f8571, %f8524;
	mov.f32 	%f8572, %f8524;
	mov.f32 	%f8573, %f8524;
	mov.f32 	%f8574, %f8524;
	mov.f32 	%f8575, %f8524;
	mov.f32 	%f8576, %f8524;
	mov.f32 	%f8577, %f8524;
	mov.f32 	%f8578, %f8524;
	mov.f32 	%f8579, %f8524;
	mov.f32 	%f8580, %f8524;
	mov.f32 	%f8581, %f8524;
	mov.f32 	%f8582, %f8524;
	mov.f32 	%f8583, %f8524;
	mov.f32 	%f8584, %f8524;
	mov.f32 	%f8585, %f8524;
	mov.f32 	%f8586, %f8524;
	mov.f32 	%f8587, %f8524;
	mov.f32 	%f8588, %f8524;
	mov.f32 	%f8589, %f8524;
	mov.f32 	%f8590, %f8524;
	mov.f32 	%f8591, %f8524;
	mov.f32 	%f8592, %f8524;
	mov.f32 	%f8593, %f8524;
	mov.f32 	%f8594, %f8524;
	mov.f32 	%f8595, %f8524;
	mov.f32 	%f8596, %f8524;
	mov.f32 	%f8597, %f8524;
	mov.f32 	%f8598, %f8524;
	mov.f32 	%f8599, %f8524;
	mov.f32 	%f8600, %f8524;
	mov.f32 	%f8601, %f8524;
	mov.f32 	%f8602, %f8524;
	mov.f32 	%f8603, %f8524;
	mov.f32 	%f8604, %f8524;
	mov.f32 	%f8605, %f8524;
	mov.f32 	%f8606, %f8524;
	mov.f32 	%f8607, %f8524;
	mov.f32 	%f8608, %f8524;
	mov.f32 	%f8609, %f8524;
	mov.f32 	%f8610, %f8524;
	mov.f32 	%f8611, %f8524;
	mov.f32 	%f8612, %f8524;
	mov.f32 	%f8613, %f8524;
	mov.f32 	%f8614, %f8524;
	mov.f32 	%f8615, %f8524;
	mov.f32 	%f8616, %f8524;
	mov.f32 	%f8617, %f8524;
	mov.f32 	%f8618, %f8524;
	mov.f32 	%f8619, %f8524;
	mov.f32 	%f8620, %f8524;
	mov.f32 	%f8621, %f8524;
	mov.f32 	%f8622, %f8524;
	mov.f32 	%f8623, %f8524;
	mov.f32 	%f8624, %f8524;
	mov.f32 	%f8625, %f8524;
	mov.f32 	%f8626, %f8524;
	mov.f32 	%f8627, %f8524;
	mov.f32 	%f8628, %f8524;
	mov.f32 	%f8629, %f8524;
	mov.f32 	%f8630, %f8524;
	mov.f32 	%f8631, %f8524;
	mov.f32 	%f8632, %f8524;
	mov.f32 	%f8633, %f8524;
	mov.f32 	%f8634, %f8524;
	mov.f32 	%f8635, %f8524;
	mov.f32 	%f8636, %f8524;
	mov.f32 	%f8637, %f8524;
	mov.f32 	%f8638, %f8524;
	mov.f32 	%f8639, %f8524;
	mov.f32 	%f8640, %f8524;
	mov.f32 	%f8641, %f8524;
	mov.f32 	%f8642, %f8524;
	mov.f32 	%f8643, %f8524;
	mov.f32 	%f8644, %f8524;
	mov.f32 	%f8645, %f8524;
	mov.f32 	%f8646, %f8524;
	mov.f32 	%f8647, %f8524;
	mov.f32 	%f8648, %f8524;
	mov.f32 	%f8649, %f8524;
	mov.f32 	%f8650, %f8524;
	mov.f32 	%f8651, %f8524;
	mov.f32 	%f8789, %f8788;
	mov.f32 	%f8790, %f8788;
	mov.f32 	%f8791, %f8788;
	mov.f32 	%f8517, %f8516;
	mov.f32 	%f8518, %f8516;
	mov.f32 	%f8519, %f8516;
	@%p84 bra 	$L__BB0_4;
// %bb.1:                               // %.lr.ph
	.loc	1 0 28                          // prefix_prefill.py:0:28
	add.s32 	%r926, %r912, 32768;
	add.s32 	%r80, %r926, %r911;
	and.b32  	%r931, %r7316, 6;
	or.b32  	%r932, %r931, %r7314;
	xor.b32  	%r933, %r7315, %r7313;
	shl.b32 	%r934, %r933, 4;
	shl.b32 	%r935, %r932, 11;
	shl.b32 	%r936, %r7313, 8;
	or.b32  	%r937, %r935, %r936;
	or.b32  	%r938, %r934, %r937;
	add.s32 	%r1046, %r912, %r938;
	or.b32  	%r939, %r7315, 2;
	xor.b32  	%r940, %r939, %r7313;
	shl.b32 	%r941, %r940, 4;
	or.b32  	%r942, %r941, %r937;
	add.s32 	%r1051, %r912, %r942;
	or.b32  	%r943, %r7315, 4;
	xor.b32  	%r944, %r943, %r7313;
	shl.b32 	%r945, %r944, 4;
	or.b32  	%r946, %r945, %r937;
	add.s32 	%r1056, %r912, %r946;
	or.b32  	%r947, %r7315, 6;
	xor.b32  	%r948, %r947, %r7313;
	shl.b32 	%r949, %r948, 4;
	or.b32  	%r950, %r949, %r937;
	add.s32 	%r1061, %r912, %r950;
	or.b32  	%r951, %r7315, 8;
	xor.b32  	%r952, %r951, %r7313;
	shl.b32 	%r953, %r952, 4;
	or.b32  	%r954, %r953, %r937;
	add.s32 	%r1066, %r912, %r954;
	or.b32  	%r955, %r7315, 10;
	xor.b32  	%r956, %r955, %r7313;
	shl.b32 	%r957, %r956, 4;
	or.b32  	%r958, %r957, %r937;
	add.s32 	%r1071, %r912, %r958;
	or.b32  	%r959, %r7315, 12;
	xor.b32  	%r960, %r959, %r7313;
	shl.b32 	%r961, %r960, 4;
	or.b32  	%r962, %r961, %r937;
	add.s32 	%r1076, %r912, %r962;
	or.b32  	%r963, %r7315, 14;
	xor.b32  	%r964, %r963, %r7313;
	shl.b32 	%r965, %r964, 4;
	or.b32  	%r966, %r965, %r937;
	add.s32 	%r1081, %r912, %r966;
	add.s32 	%r1086, %r1046, 16384;
	add.s32 	%r1091, %r1051, 16384;
	add.s32 	%r1096, %r1056, 16384;
	add.s32 	%r1101, %r1061, 16384;
	add.s32 	%r1106, %r1066, 16384;
	add.s32 	%r1111, %r1071, 16384;
	add.s32 	%r1116, %r1076, 16384;
	add.s32 	%r1121, %r1081, 16384;
	shl.b32 	%r967, %r7315, 3;
	or.b32  	%r968, %r967, %r7313;
	xor.b32  	%r969, %r7314, %r7313;
	shl.b32 	%r970, %r969, 4;
	shl.b32 	%r971, %r968, 8;
	or.b32  	%r972, %r971, %r970;
	add.s32 	%r1126, %r926, %r972;
	or.b32  	%r973, %r7314, 2;
	xor.b32  	%r974, %r973, %r7313;
	shl.b32 	%r975, %r974, 4;
	or.b32  	%r976, %r975, %r971;
	add.s32 	%r1131, %r926, %r976;
	or.b32  	%r977, %r7314, 4;
	xor.b32  	%r978, %r977, %r7313;
	shl.b32 	%r979, %r978, 4;
	or.b32  	%r980, %r979, %r971;
	add.s32 	%r1136, %r926, %r980;
	or.b32  	%r981, %r7314, 6;
	xor.b32  	%r982, %r981, %r7313;
	shl.b32 	%r983, %r982, 4;
	or.b32  	%r984, %r983, %r971;
	add.s32 	%r1141, %r926, %r984;
	or.b32  	%r985, %r7314, 8;
	xor.b32  	%r986, %r985, %r7313;
	shl.b32 	%r987, %r986, 4;
	or.b32  	%r988, %r987, %r971;
	add.s32 	%r1146, %r926, %r988;
	or.b32  	%r989, %r7314, 10;
	xor.b32  	%r990, %r989, %r7313;
	shl.b32 	%r991, %r990, 4;
	or.b32  	%r992, %r991, %r971;
	add.s32 	%r1151, %r926, %r992;
	or.b32  	%r993, %r7314, 12;
	xor.b32  	%r994, %r993, %r7313;
	shl.b32 	%r995, %r994, 4;
	or.b32  	%r996, %r995, %r971;
	add.s32 	%r1156, %r926, %r996;
	or.b32  	%r997, %r7314, 14;
	xor.b32  	%r998, %r997, %r7313;
	shl.b32 	%r999, %r998, 4;
	or.b32  	%r1000, %r999, %r971;
	add.s32 	%r1161, %r926, %r1000;
	shl.b32 	%r1002, %r7317, 1;
	or.b32  	%r1004, %r7318, %r1002;
	add.s32 	%r105, %r926, %r1004;
	add.s32 	%r106, %r105, 2048;
	xor.b32  	%r1006, %r7314, %r7319;
	shl.b32 	%r1007, %r1006, 4;
	shl.b32 	%r1008, %r968, 5;
	or.b32  	%r1009, %r1008, %r1007;
	add.s32 	%r1434, %r926, %r1009;
	add.s32 	%r1439, %r1434, 512;
	add.s32 	%r1444, %r1434, 1024;
	add.s32 	%r1449, %r1434, 1536;
	add.s32 	%r1454, %r1434, 2048;
	add.s32 	%r1459, %r1434, 2560;
	add.s32 	%r1464, %r1434, 3072;
	add.s32 	%r1469, %r1434, 3584;
	shl.b32 	%r1010, %r12, 3;
	.loc	1 135 28                        // prefix_prefill.py:135:28
	add.s32 	%r115, %r7312, %r1010;
	add.s32 	%r116, %r115, 64;
	mov.f32 	%f8788, 0f3F800000;
	mov.f32 	%f8516, 0fFF800000;
	mov.f32 	%f8524, 0f00000000;
	mov.u64 	%rd550, %rd1;
	mov.f32 	%f8525, %f8524;
	mov.f32 	%f8526, %f8524;
	mov.f32 	%f8527, %f8524;
	mov.f32 	%f8528, %f8524;
	mov.f32 	%f8529, %f8524;
	mov.f32 	%f8530, %f8524;
	mov.f32 	%f8531, %f8524;
	mov.f32 	%f8532, %f8524;
	mov.f32 	%f8533, %f8524;
	mov.f32 	%f8534, %f8524;
	mov.f32 	%f8535, %f8524;
	mov.f32 	%f8536, %f8524;
	mov.f32 	%f8537, %f8524;
	mov.f32 	%f8538, %f8524;
	mov.f32 	%f8539, %f8524;
	mov.f32 	%f8540, %f8524;
	mov.f32 	%f8541, %f8524;
	mov.f32 	%f8542, %f8524;
	mov.f32 	%f8543, %f8524;
	mov.f32 	%f8544, %f8524;
	mov.f32 	%f8545, %f8524;
	mov.f32 	%f8546, %f8524;
	mov.f32 	%f8547, %f8524;
	mov.f32 	%f8548, %f8524;
	mov.f32 	%f8549, %f8524;
	mov.f32 	%f8550, %f8524;
	mov.f32 	%f8551, %f8524;
	mov.f32 	%f8552, %f8524;
	mov.f32 	%f8553, %f8524;
	mov.f32 	%f8554, %f8524;
	mov.f32 	%f8555, %f8524;
	mov.f32 	%f8556, %f8524;
	mov.f32 	%f8557, %f8524;
	mov.f32 	%f8558, %f8524;
	mov.f32 	%f8559, %f8524;
	mov.f32 	%f8560, %f8524;
	mov.f32 	%f8561, %f8524;
	mov.f32 	%f8562, %f8524;
	mov.f32 	%f8563, %f8524;
	mov.f32 	%f8564, %f8524;
	mov.f32 	%f8565, %f8524;
	mov.f32 	%f8566, %f8524;
	mov.f32 	%f8567, %f8524;
	mov.f32 	%f8568, %f8524;
	mov.f32 	%f8569, %f8524;
	mov.f32 	%f8570, %f8524;
	mov.f32 	%f8571, %f8524;
	mov.f32 	%f8572, %f8524;
	mov.f32 	%f8573, %f8524;
	mov.f32 	%f8574, %f8524;
	mov.f32 	%f8575, %f8524;
	mov.f32 	%f8576, %f8524;
	mov.f32 	%f8577, %f8524;
	mov.f32 	%f8578, %f8524;
	mov.f32 	%f8579, %f8524;
	mov.f32 	%f8580, %f8524;
	mov.f32 	%f8581, %f8524;
	mov.f32 	%f8582, %f8524;
	mov.f32 	%f8583, %f8524;
	mov.f32 	%f8584, %f8524;
	mov.f32 	%f8585, %f8524;
	mov.f32 	%f8586, %f8524;
	mov.f32 	%f8587, %f8524;
	mov.f32 	%f8588, %f8524;
	mov.f32 	%f8589, %f8524;
	mov.f32 	%f8590, %f8524;
	mov.f32 	%f8591, %f8524;
	mov.f32 	%f8592, %f8524;
	mov.f32 	%f8593, %f8524;
	mov.f32 	%f8594, %f8524;
	mov.f32 	%f8595, %f8524;
	mov.f32 	%f8596, %f8524;
	mov.f32 	%f8597, %f8524;
	mov.f32 	%f8598, %f8524;
	mov.f32 	%f8599, %f8524;
	mov.f32 	%f8600, %f8524;
	mov.f32 	%f8601, %f8524;
	mov.f32 	%f8602, %f8524;
	mov.f32 	%f8603, %f8524;
	mov.f32 	%f8604, %f8524;
	mov.f32 	%f8605, %f8524;
	mov.f32 	%f8606, %f8524;
	mov.f32 	%f8607, %f8524;
	mov.f32 	%f8608, %f8524;
	mov.f32 	%f8609, %f8524;
	mov.f32 	%f8610, %f8524;
	mov.f32 	%f8611, %f8524;
	mov.f32 	%f8612, %f8524;
	mov.f32 	%f8613, %f8524;
	mov.f32 	%f8614, %f8524;
	mov.f32 	%f8615, %f8524;
	mov.f32 	%f8616, %f8524;
	mov.f32 	%f8617, %f8524;
	mov.f32 	%f8618, %f8524;
	mov.f32 	%f8619, %f8524;
	mov.f32 	%f8620, %f8524;
	mov.f32 	%f8621, %f8524;
	mov.f32 	%f8622, %f8524;
	mov.f32 	%f8623, %f8524;
	mov.f32 	%f8624, %f8524;
	mov.f32 	%f8625, %f8524;
	mov.f32 	%f8626, %f8524;
	mov.f32 	%f8627, %f8524;
	mov.f32 	%f8628, %f8524;
	mov.f32 	%f8629, %f8524;
	mov.f32 	%f8630, %f8524;
	mov.f32 	%f8631, %f8524;
	mov.f32 	%f8632, %f8524;
	mov.f32 	%f8633, %f8524;
	mov.f32 	%f8634, %f8524;
	mov.f32 	%f8635, %f8524;
	mov.f32 	%f8636, %f8524;
	mov.f32 	%f8637, %f8524;
	mov.f32 	%f8638, %f8524;
	mov.f32 	%f8639, %f8524;
	mov.f32 	%f8640, %f8524;
	mov.f32 	%f8641, %f8524;
	mov.f32 	%f8642, %f8524;
	mov.f32 	%f8643, %f8524;
	mov.f32 	%f8644, %f8524;
	mov.f32 	%f8645, %f8524;
	mov.f32 	%f8646, %f8524;
	mov.f32 	%f8647, %f8524;
	mov.f32 	%f8648, %f8524;
	mov.f32 	%f8649, %f8524;
	mov.f32 	%f8650, %f8524;
	mov.f32 	%f8651, %f8524;
	mov.u32 	%r7326, %r684;
	mov.f32 	%f8517, %f8516;
	mov.f32 	%f8518, %f8516;
	mov.f32 	%f8519, %f8516;
	mov.f32 	%f8789, %f8788;
	mov.f32 	%f8790, %f8788;
	mov.f32 	%f8791, %f8788;
	bra.uni 	$L__BB0_2;
$L__BB0_28:                             //   in Loop: Header=BB0_2 Depth=1
	.loc	1 0 0                           // prefix_prefill.py:0:0
	add.s32 	%r438, %r2835, %r70;
	add.s32 	%r439, %r2835, %r71;
	add.s32 	%r440, %r2835, %r72;
	add.s32 	%r441, %r2835, %r73;
	add.s32 	%r442, %r2835, %r74;
	add.s32 	%r443, %r2835, %r75;
	add.s32 	%r444, %r2835, %r76;
	add.s32 	%r446, %r2836, %r70;
	add.s32 	%r447, %r2836, %r71;
	add.s32 	%r448, %r2836, %r72;
	add.s32 	%r449, %r2836, %r73;
	add.s32 	%r450, %r2836, %r74;
	add.s32 	%r451, %r2836, %r75;
	add.s32 	%r452, %r2836, %r76;
	.loc	1 202 28                        // prefix_prefill.py:202:28
	add.s32 	%r3141, %r7324, 48;
	add.s32 	%r3142, %r7324, 49;
	add.s32 	%r3143, %r7324, 50;
	add.s32 	%r3144, %r7324, 51;
	add.s32 	%r3145, %r7324, 52;
	add.s32 	%r3146, %r7324, 53;
	add.s32 	%r3147, %r7324, 54;
	.loc	1 202 50                        // prefix_prefill.py:202:50
	add.s32 	%r3148, %r7324, 55;
	setp.lt.s32 	%p265, %r3141, %r5;
	setp.lt.s32 	%p267, %r3142, %r5;
	setp.lt.s32 	%p269, %r3143, %r5;
	setp.lt.s32 	%p271, %r3144, %r5;
	setp.lt.s32 	%p273, %r3145, %r5;
	setp.lt.s32 	%p275, %r3146, %r5;
	setp.lt.s32 	%p277, %r3147, %r5;
	setp.lt.s32 	%p279, %r3148, %r5;
	.loc	1 200 26                        // prefix_prefill.py:200:26
	add.s64 	%rd302, %rd111, %rd534;
	mul.wide.s32 	%rd319, %r438, 2;
	add.s64 	%rd303, %rd111, %rd319;
	mul.wide.s32 	%rd320, %r439, 2;
	add.s64 	%rd304, %rd111, %rd320;
	mul.wide.s32 	%rd321, %r440, 2;
	add.s64 	%rd305, %rd111, %rd321;
	mul.wide.s32 	%rd322, %r441, 2;
	add.s64 	%rd306, %rd111, %rd322;
	mul.wide.s32 	%rd323, %r442, 2;
	add.s64 	%rd307, %rd111, %rd323;
	mul.wide.s32 	%rd324, %r443, 2;
	add.s64 	%rd308, %rd111, %rd324;
	mul.wide.s32 	%rd325, %r444, 2;
	add.s64 	%rd309, %rd111, %rd325;
	add.s64 	%rd310, %rd111, %rd535;
	mul.wide.s32 	%rd327, %r446, 2;
	add.s64 	%rd311, %rd111, %rd327;
	mul.wide.s32 	%rd328, %r447, 2;
	add.s64 	%rd312, %rd111, %rd328;
	mul.wide.s32 	%rd329, %r448, 2;
	add.s64 	%rd313, %rd111, %rd329;
	mul.wide.s32 	%rd330, %r449, 2;
	add.s64 	%rd314, %rd111, %rd330;
	mul.wide.s32 	%rd331, %r450, 2;
	add.s64 	%rd315, %rd111, %rd331;
	mul.wide.s32 	%rd332, %r451, 2;
	add.s64 	%rd316, %rd111, %rd332;
	mul.wide.s32 	%rd333, %r452, 2;
	add.s64 	%rd317, %rd111, %rd333;
	.loc	1 200 16                        // prefix_prefill.py:200:16
	// begin inline asm
	mov.u16 %rs193, 0x0;
	@%p265 ld.global.b16 { %rs193 }, [ %rd302 + 0 ];
	@!%p265 mov.u16 %rs193, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs195, 0x0;
	@%p267 ld.global.b16 { %rs195 }, [ %rd303 + 0 ];
	@!%p267 mov.u16 %rs195, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs197, 0x0;
	@%p269 ld.global.b16 { %rs197 }, [ %rd304 + 0 ];
	@!%p269 mov.u16 %rs197, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs199, 0x0;
	@%p271 ld.global.b16 { %rs199 }, [ %rd305 + 0 ];
	@!%p271 mov.u16 %rs199, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs201, 0x0;
	@%p273 ld.global.b16 { %rs201 }, [ %rd306 + 0 ];
	@!%p273 mov.u16 %rs201, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs203, 0x0;
	@%p275 ld.global.b16 { %rs203 }, [ %rd307 + 0 ];
	@!%p275 mov.u16 %rs203, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs205, 0x0;
	@%p277 ld.global.b16 { %rs205 }, [ %rd308 + 0 ];
	@!%p277 mov.u16 %rs205, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs207, 0x0;
	@%p279 ld.global.b16 { %rs207 }, [ %rd309 + 0 ];
	@!%p279 mov.u16 %rs207, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs209, 0x0;
	@%p265 ld.global.b16 { %rs209 }, [ %rd310 + 0 ];
	@!%p265 mov.u16 %rs209, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs211, 0x0;
	@%p267 ld.global.b16 { %rs211 }, [ %rd311 + 0 ];
	@!%p267 mov.u16 %rs211, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs213, 0x0;
	@%p269 ld.global.b16 { %rs213 }, [ %rd312 + 0 ];
	@!%p269 mov.u16 %rs213, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs215, 0x0;
	@%p271 ld.global.b16 { %rs215 }, [ %rd313 + 0 ];
	@!%p271 mov.u16 %rs215, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs217, 0x0;
	@%p273 ld.global.b16 { %rs217 }, [ %rd314 + 0 ];
	@!%p273 mov.u16 %rs217, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs219, 0x0;
	@%p275 ld.global.b16 { %rs219 }, [ %rd315 + 0 ];
	@!%p275 mov.u16 %rs219, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs221, 0x0;
	@%p277 ld.global.b16 { %rs221 }, [ %rd316 + 0 ];
	@!%p277 mov.u16 %rs221, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs223, 0x0;
	@%p279 ld.global.b16 { %rs223 }, [ %rd317 + 0 ];
	@!%p279 mov.u16 %rs223, %rs258;
	// end inline asm
	mov.b32 	%r7383, {%rs193, %rs195};
	mov.b32 	%r7384, {%rs197, %rs199};
	mov.b32 	%r7385, {%rs201, %rs203};
	mov.b32 	%r7386, {%rs205, %rs207};
	mov.b32 	%r7387, {%rs209, %rs211};
	mov.b32 	%r7388, {%rs213, %rs215};
	mov.b32 	%r7389, {%rs217, %rs219};
	mov.b32 	%r7390, {%rs221, %rs223};
$L__BB0_30:                             //   in Loop: Header=BB0_2 Depth=1
	.loc	1 197 11                        // prefix_prefill.py:197:11
	bar.sync 	0;
	st.shared.v4.b32 	[%r105], {%r7383, %r7384, %r7385, %r7386};
	st.shared.v4.b32 	[%r106], {%r7387, %r7388, %r7389, %r7390};
	.loc	1 211 17                        // prefix_prefill.py:211:17
	mov.b32 	%r3157, %f4656;
	// begin inline asm
	cvt.rn.bf16.f32 %rs225, %r3157;
	// end inline asm
	mov.b32 	%r3158, %f4658;
	// begin inline asm
	cvt.rn.bf16.f32 %rs226, %r3158;
	// end inline asm
	mov.b32 	%r3159, %f4660;
	// begin inline asm
	cvt.rn.bf16.f32 %rs227, %r3159;
	// end inline asm
	mov.b32 	%r3160, %f4662;
	// begin inline asm
	cvt.rn.bf16.f32 %rs228, %r3160;
	// end inline asm
	mov.b32 	%r3161, %f4664;
	// begin inline asm
	cvt.rn.bf16.f32 %rs229, %r3161;
	// end inline asm
	mov.b32 	%r3162, %f4666;
	// begin inline asm
	cvt.rn.bf16.f32 %rs230, %r3162;
	// end inline asm
	mov.b32 	%r3163, %f4668;
	// begin inline asm
	cvt.rn.bf16.f32 %rs231, %r3163;
	// end inline asm
	mov.b32 	%r3164, %f4670;
	// begin inline asm
	cvt.rn.bf16.f32 %rs232, %r3164;
	// end inline asm
	mov.b32 	%r3165, %f4672;
	// begin inline asm
	cvt.rn.bf16.f32 %rs233, %r3165;
	// end inline asm
	mov.b32 	%r3166, %f4674;
	// begin inline asm
	cvt.rn.bf16.f32 %rs234, %r3166;
	// end inline asm
	mov.b32 	%r3167, %f4676;
	// begin inline asm
	cvt.rn.bf16.f32 %rs235, %r3167;
	// end inline asm
	mov.b32 	%r3168, %f4678;
	// begin inline asm
	cvt.rn.bf16.f32 %rs236, %r3168;
	// end inline asm
	mov.b32 	%r3169, %f4680;
	// begin inline asm
	cvt.rn.bf16.f32 %rs237, %r3169;
	// end inline asm
	mov.b32 	%r3170, %f4682;
	// begin inline asm
	cvt.rn.bf16.f32 %rs238, %r3170;
	// end inline asm
	mov.b32 	%r3171, %f4684;
	// begin inline asm
	cvt.rn.bf16.f32 %rs239, %r3171;
	// end inline asm
	mov.b32 	%r3172, %f4686;
	// begin inline asm
	cvt.rn.bf16.f32 %rs240, %r3172;
	// end inline asm
	mov.b32 	%r3213, {%rs225, %rs226};
	mov.b32 	%r3214, {%rs227, %rs228};
	mov.b32 	%r3215, {%rs229, %rs230};
	mov.b32 	%r3216, {%rs231, %rs232};
	mov.b32 	%r3309, {%rs233, %rs234};
	mov.b32 	%r3310, {%rs235, %rs236};
	mov.b32 	%r3311, {%rs237, %rs238};
	mov.b32 	%r3312, {%rs239, %rs240};
	.loc	1 197 11                        // prefix_prefill.py:197:11
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3217, %r3218, %r3223, %r3224 }, [ %r1434 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3229, %r3230, %r3235, %r3236 }, [ %r1439 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3241, %r3242, %r3247, %r3248 }, [ %r1444 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3253, %r3254, %r3259, %r3260 }, [ %r1449 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3265, %r3266, %r3271, %r3272 }, [ %r1454 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3277, %r3278, %r3283, %r3284 }, [ %r1459 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3289, %r3290, %r3295, %r3296 }, [ %r1464 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3301, %r3302, %r3307, %r3308 }, [ %r1469 + 0 ];
	// end inline asm
	.loc	1 213 24                        // prefix_prefill.py:213:24
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8524, %f8525, %f8526, %f8527 }, { %r3213, %r3214, %r3215, %r3216 }, { %r3217, %r3218 }, { %f8524, %f8525, %f8526, %f8527 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8528, %f8529, %f8530, %f8531 }, { %r3213, %r3214, %r3215, %r3216 }, { %r3223, %r3224 }, { %f8528, %f8529, %f8530, %f8531 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8532, %f8533, %f8534, %f8535 }, { %r3213, %r3214, %r3215, %r3216 }, { %r3229, %r3230 }, { %f8532, %f8533, %f8534, %f8535 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8536, %f8537, %f8538, %f8539 }, { %r3213, %r3214, %r3215, %r3216 }, { %r3235, %r3236 }, { %f8536, %f8537, %f8538, %f8539 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8540, %f8541, %f8542, %f8543 }, { %r3213, %r3214, %r3215, %r3216 }, { %r3241, %r3242 }, { %f8540, %f8541, %f8542, %f8543 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8544, %f8545, %f8546, %f8547 }, { %r3213, %r3214, %r3215, %r3216 }, { %r3247, %r3248 }, { %f8544, %f8545, %f8546, %f8547 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8548, %f8549, %f8550, %f8551 }, { %r3213, %r3214, %r3215, %r3216 }, { %r3253, %r3254 }, { %f8548, %f8549, %f8550, %f8551 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8552, %f8553, %f8554, %f8555 }, { %r3213, %r3214, %r3215, %r3216 }, { %r3259, %r3260 }, { %f8552, %f8553, %f8554, %f8555 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8556, %f8557, %f8558, %f8559 }, { %r3213, %r3214, %r3215, %r3216 }, { %r3265, %r3266 }, { %f8556, %f8557, %f8558, %f8559 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8560, %f8561, %f8562, %f8563 }, { %r3213, %r3214, %r3215, %r3216 }, { %r3271, %r3272 }, { %f8560, %f8561, %f8562, %f8563 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8564, %f8565, %f8566, %f8567 }, { %r3213, %r3214, %r3215, %r3216 }, { %r3277, %r3278 }, { %f8564, %f8565, %f8566, %f8567 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8568, %f8569, %f8570, %f8571 }, { %r3213, %r3214, %r3215, %r3216 }, { %r3283, %r3284 }, { %f8568, %f8569, %f8570, %f8571 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8572, %f8573, %f8574, %f8575 }, { %r3213, %r3214, %r3215, %r3216 }, { %r3289, %r3290 }, { %f8572, %f8573, %f8574, %f8575 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8576, %f8577, %f8578, %f8579 }, { %r3213, %r3214, %r3215, %r3216 }, { %r3295, %r3296 }, { %f8576, %f8577, %f8578, %f8579 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8580, %f8581, %f8582, %f8583 }, { %r3213, %r3214, %r3215, %r3216 }, { %r3301, %r3302 }, { %f8580, %f8581, %f8582, %f8583 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8584, %f8585, %f8586, %f8587 }, { %r3213, %r3214, %r3215, %r3216 }, { %r3307, %r3308 }, { %f8584, %f8585, %f8586, %f8587 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8588, %f8589, %f8590, %f8591 }, { %r3309, %r3310, %r3311, %r3312 }, { %r3217, %r3218 }, { %f8588, %f8589, %f8590, %f8591 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8592, %f8593, %f8594, %f8595 }, { %r3309, %r3310, %r3311, %r3312 }, { %r3223, %r3224 }, { %f8592, %f8593, %f8594, %f8595 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8596, %f8597, %f8598, %f8599 }, { %r3309, %r3310, %r3311, %r3312 }, { %r3229, %r3230 }, { %f8596, %f8597, %f8598, %f8599 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8600, %f8601, %f8602, %f8603 }, { %r3309, %r3310, %r3311, %r3312 }, { %r3235, %r3236 }, { %f8600, %f8601, %f8602, %f8603 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8604, %f8605, %f8606, %f8607 }, { %r3309, %r3310, %r3311, %r3312 }, { %r3241, %r3242 }, { %f8604, %f8605, %f8606, %f8607 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8608, %f8609, %f8610, %f8611 }, { %r3309, %r3310, %r3311, %r3312 }, { %r3247, %r3248 }, { %f8608, %f8609, %f8610, %f8611 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8612, %f8613, %f8614, %f8615 }, { %r3309, %r3310, %r3311, %r3312 }, { %r3253, %r3254 }, { %f8612, %f8613, %f8614, %f8615 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8616, %f8617, %f8618, %f8619 }, { %r3309, %r3310, %r3311, %r3312 }, { %r3259, %r3260 }, { %f8616, %f8617, %f8618, %f8619 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8620, %f8621, %f8622, %f8623 }, { %r3309, %r3310, %r3311, %r3312 }, { %r3265, %r3266 }, { %f8620, %f8621, %f8622, %f8623 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8624, %f8625, %f8626, %f8627 }, { %r3309, %r3310, %r3311, %r3312 }, { %r3271, %r3272 }, { %f8624, %f8625, %f8626, %f8627 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8628, %f8629, %f8630, %f8631 }, { %r3309, %r3310, %r3311, %r3312 }, { %r3277, %r3278 }, { %f8628, %f8629, %f8630, %f8631 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8632, %f8633, %f8634, %f8635 }, { %r3309, %r3310, %r3311, %r3312 }, { %r3283, %r3284 }, { %f8632, %f8633, %f8634, %f8635 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8636, %f8637, %f8638, %f8639 }, { %r3309, %r3310, %r3311, %r3312 }, { %r3289, %r3290 }, { %f8636, %f8637, %f8638, %f8639 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8640, %f8641, %f8642, %f8643 }, { %r3309, %r3310, %r3311, %r3312 }, { %r3295, %r3296 }, { %f8640, %f8641, %f8642, %f8643 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8644, %f8645, %f8646, %f8647 }, { %r3309, %r3310, %r3311, %r3312 }, { %r3301, %r3302 }, { %f8644, %f8645, %f8646, %f8647 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8648, %f8649, %f8650, %f8651 }, { %r3309, %r3310, %r3311, %r3312 }, { %r3307, %r3308 }, { %f8648, %f8649, %f8650, %f8651 };
	// end inline asm
	.loc	1 215 28                        // prefix_prefill.py:215:28
	fma.rn.f32 	%f8788, %f1145, %f4688, %f1169;
	fma.rn.f32 	%f8789, %f1146, %f4690, %f1170;
	fma.rn.f32 	%f8790, %f1147, %f4692, %f1171;
	fma.rn.f32 	%f8791, %f1148, %f4694, %f1172;
	.loc	1 135 28                        // prefix_prefill.py:135:28
	add.s64 	%rd550, %rd550, 16;
	setp.lt.s32 	%p297, %r7326, %r7391;
	@%p297 bra 	$L__BB0_2;
	bra.uni 	$L__BB0_4;
$L__BB0_2:                              // =>This Inner Loop Header: Depth=1
	.loc	1 138 21                        // prefix_prefill.py:138:21
	// begin inline asm
	mov.u32 %r1011, 0x0;
	@%p546 ld.global.b32 { %r1011 }, [ %rd550 + 0 ];
	// end inline asm
	.loc	1 142 26                        // prefix_prefill.py:142:26
	mul.lo.s32 	%r1012, %r1011, %r672;
	.loc	1 144 24                        // prefix_prefill.py:144:24
	add.s32 	%r154, %r68, %r7326;
	add.s32 	%r155, %r154, 1;
	add.s32 	%r156, %r154, 8;
	add.s32 	%r157, %r154, 9;
	add.s32 	%r158, %r1012, %r115;
	add.s32 	%r159, %r1012, %r116;
	.loc	1 148 31                        // prefix_prefill.py:148:31
	mul.lo.s32 	%r1013, %r1011, %r673;
	add.s32 	%r1014, %r1013, %r78;
	add.s32 	%r1015, %r1013, %r79;
	.loc	1 151 17                        // prefix_prefill.py:151:17
	add.s32 	%r160, %r1014, %r21;
	add.s32 	%r168, %r1015, %r21;
	.loc	1 153 34                        // prefix_prefill.py:153:34
	add.s32 	%r176, %r7326, 16;
	setp.le.s32 	%p86, %r176, %r5;
	add.s32 	%r7325, %r12, %r7326;
	mul.wide.s32 	%rd548, %r158, 2;
	mul.wide.s32 	%rd549, %r159, 2;
	@%p86 bra 	$L__BB0_8;
// %bb.3:                               //   in Loop: Header=BB0_2 Depth=1
	.loc	1 144 24                        // prefix_prefill.py:144:24
	add.s32 	%r1041, %r7325, 8;
	.loc	1 158 50                        // prefix_prefill.py:158:50
	setp.lt.s32 	%p89, %r7325, %r5;
	setp.lt.s32 	%p94, %r1041, %r5;
	.loc	1 156 26                        // prefix_prefill.py:156:26
	add.s64 	%rd159, %rd110, %rd548;
	add.s64 	%rd160, %rd110, %rd549;
	mov.b32 	%r1028, 0;
	.loc	1 156 16                        // prefix_prefill.py:156:16
	// begin inline asm
	mov.u32 %r7333, 0x0;
	mov.u32 %r7334, 0x0;
	mov.u32 %r7331, 0x0;
	mov.u32 %r7332, 0x0;
	@%p89 ld.global.v4.b32 { %r7333, %r7334, %r7331, %r7332 }, [ %rd159 + 0 ];
	@!%p89 mov.u32 %r7333, %r1028;
	@!%p89 mov.u32 %r7334, %r1028;
	@!%p89 mov.u32 %r7331, %r1028;
	@!%p89 mov.u32 %r7332, %r1028;
	// end inline asm
	// begin inline asm
	mov.u32 %r7327, 0x0;
	mov.u32 %r7328, 0x0;
	mov.u32 %r7329, 0x0;
	mov.u32 %r7330, 0x0;
	@%p94 ld.global.v4.b32 { %r7327, %r7328, %r7329, %r7330 }, [ %rd160 + 0 ];
	@!%p94 mov.u32 %r7327, %r1028;
	@!%p94 mov.u32 %r7328, %r1028;
	@!%p94 mov.u32 %r7329, %r1028;
	@!%p94 mov.u32 %r7330, %r1028;
	// end inline asm
	.loc	1 153 11                        // prefix_prefill.py:153:11
	bra.uni 	$L__BB0_9;
$L__BB0_8:                              //   in Loop: Header=BB0_2 Depth=1
	.loc	1 161 39                        // prefix_prefill.py:161:39
	add.s64 	%rd155, %rd110, %rd548;
	add.s64 	%rd156, %rd110, %rd549;
	.loc	1 161 29                        // prefix_prefill.py:161:29
	// begin inline asm
	mov.u32 %r7333, 0x0;
	mov.u32 %r7334, 0x0;
	mov.u32 %r7331, 0x0;
	mov.u32 %r7332, 0x0;
	@%p546 ld.global.v4.b32 { %r7333, %r7334, %r7331, %r7332 }, [ %rd155 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r7327, 0x0;
	mov.u32 %r7328, 0x0;
	mov.u32 %r7329, 0x0;
	mov.u32 %r7330, 0x0;
	@%p546 ld.global.v4.b32 { %r7327, %r7328, %r7329, %r7330 }, [ %rd156 + 0 ];
	// end inline asm
$L__BB0_9:                              //   in Loop: Header=BB0_2 Depth=1
	.loc	1 153 11                        // prefix_prefill.py:153:11
	bar.sync 	0;
	st.shared.v4.b32 	[%r80], {%r7333, %r7334, %r7331, %r7332};
	st.shared.v4.b32 	[%r80+2048], {%r7327, %r7328, %r7329, %r7330};
	.loc	1 123 16                        // prefix_prefill.py:123:16
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2904, %r2905, %r2906, %r2907 }, [ %r1046 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2928, %r2929, %r2930, %r2931 }, [ %r1051 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2952, %r2953, %r2954, %r2955 }, [ %r1056 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2976, %r2977, %r2978, %r2979 }, [ %r1061 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3000, %r3001, %r3002, %r3003 }, [ %r1066 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3024, %r3025, %r3026, %r3027 }, [ %r1071 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3048, %r3049, %r3050, %r3051 }, [ %r1076 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3072, %r3073, %r3074, %r3075 }, [ %r1081 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2916, %r2917, %r2918, %r2919 }, [ %r1086 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2940, %r2941, %r2942, %r2943 }, [ %r1091 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2964, %r2965, %r2966, %r2967 }, [ %r1096 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2988, %r2989, %r2990, %r2991 }, [ %r1101 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3012, %r3013, %r3014, %r3015 }, [ %r1106 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3036, %r3037, %r3038, %r3039 }, [ %r1111 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3060, %r3061, %r3062, %r3063 }, [ %r1116 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3084, %r3085, %r3086, %r3087 }, [ %r1121 + 0 ];
	// end inline asm
	.loc	1 153 11                        // prefix_prefill.py:153:11
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1166, %r1167, %r1172, %r1173 }, [ %r1126 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1190, %r1191, %r1196, %r1197 }, [ %r1131 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1214, %r1215, %r1220, %r1221 }, [ %r1136 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1238, %r1239, %r1244, %r1245 }, [ %r1141 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1262, %r1263, %r1268, %r1269 }, [ %r1146 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1286, %r1287, %r1292, %r1293 }, [ %r1151 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1310, %r1311, %r1316, %r1317 }, [ %r1156 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1334, %r1335, %r1340, %r1341 }, [ %r1161 + 0 ];
	// end inline asm
	mov.f32 	%f4456, 0f00000000;
	.loc	1 169 23                        // prefix_prefill.py:169:23
	mov.f32 	%f2452, %f4456;
	mov.f32 	%f2453, %f4456;
	mov.f32 	%f2454, %f4456;
	mov.f32 	%f2455, %f4456;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2452, %f2453, %f2454, %f2455 }, { %r2904, %r2905, %r2906, %r2907 }, { %r1166, %r1167 }, { %f2452, %f2453, %f2454, %f2455 };
	// end inline asm
	mov.f32 	%f2460, %f4456;
	mov.f32 	%f2461, %f4456;
	mov.f32 	%f2462, %f4456;
	mov.f32 	%f2463, %f4456;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2460, %f2461, %f2462, %f2463 }, { %r2904, %r2905, %r2906, %r2907 }, { %r1172, %r1173 }, { %f2460, %f2461, %f2462, %f2463 };
	// end inline asm
	mov.f32 	%f2468, %f4456;
	mov.f32 	%f2469, %f4456;
	mov.f32 	%f2470, %f4456;
	mov.f32 	%f2471, %f4456;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2468, %f2469, %f2470, %f2471 }, { %r2916, %r2917, %r2918, %r2919 }, { %r1166, %r1167 }, { %f2468, %f2469, %f2470, %f2471 };
	// end inline asm
	mov.f32 	%f2476, %f4456;
	mov.f32 	%f2477, %f4456;
	mov.f32 	%f2478, %f4456;
	mov.f32 	%f2479, %f4456;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2476, %f2477, %f2478, %f2479 }, { %r2916, %r2917, %r2918, %r2919 }, { %r1172, %r1173 }, { %f2476, %f2477, %f2478, %f2479 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2452, %f2453, %f2454, %f2455 }, { %r2928, %r2929, %r2930, %r2931 }, { %r1190, %r1191 }, { %f2452, %f2453, %f2454, %f2455 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2460, %f2461, %f2462, %f2463 }, { %r2928, %r2929, %r2930, %r2931 }, { %r1196, %r1197 }, { %f2460, %f2461, %f2462, %f2463 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2468, %f2469, %f2470, %f2471 }, { %r2940, %r2941, %r2942, %r2943 }, { %r1190, %r1191 }, { %f2468, %f2469, %f2470, %f2471 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2476, %f2477, %f2478, %f2479 }, { %r2940, %r2941, %r2942, %r2943 }, { %r1196, %r1197 }, { %f2476, %f2477, %f2478, %f2479 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2452, %f2453, %f2454, %f2455 }, { %r2952, %r2953, %r2954, %r2955 }, { %r1214, %r1215 }, { %f2452, %f2453, %f2454, %f2455 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2460, %f2461, %f2462, %f2463 }, { %r2952, %r2953, %r2954, %r2955 }, { %r1220, %r1221 }, { %f2460, %f2461, %f2462, %f2463 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2468, %f2469, %f2470, %f2471 }, { %r2964, %r2965, %r2966, %r2967 }, { %r1214, %r1215 }, { %f2468, %f2469, %f2470, %f2471 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2476, %f2477, %f2478, %f2479 }, { %r2964, %r2965, %r2966, %r2967 }, { %r1220, %r1221 }, { %f2476, %f2477, %f2478, %f2479 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2452, %f2453, %f2454, %f2455 }, { %r2976, %r2977, %r2978, %r2979 }, { %r1238, %r1239 }, { %f2452, %f2453, %f2454, %f2455 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2460, %f2461, %f2462, %f2463 }, { %r2976, %r2977, %r2978, %r2979 }, { %r1244, %r1245 }, { %f2460, %f2461, %f2462, %f2463 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2468, %f2469, %f2470, %f2471 }, { %r2988, %r2989, %r2990, %r2991 }, { %r1238, %r1239 }, { %f2468, %f2469, %f2470, %f2471 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2476, %f2477, %f2478, %f2479 }, { %r2988, %r2989, %r2990, %r2991 }, { %r1244, %r1245 }, { %f2476, %f2477, %f2478, %f2479 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2452, %f2453, %f2454, %f2455 }, { %r3000, %r3001, %r3002, %r3003 }, { %r1262, %r1263 }, { %f2452, %f2453, %f2454, %f2455 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2460, %f2461, %f2462, %f2463 }, { %r3000, %r3001, %r3002, %r3003 }, { %r1268, %r1269 }, { %f2460, %f2461, %f2462, %f2463 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2468, %f2469, %f2470, %f2471 }, { %r3012, %r3013, %r3014, %r3015 }, { %r1262, %r1263 }, { %f2468, %f2469, %f2470, %f2471 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2476, %f2477, %f2478, %f2479 }, { %r3012, %r3013, %r3014, %r3015 }, { %r1268, %r1269 }, { %f2476, %f2477, %f2478, %f2479 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2452, %f2453, %f2454, %f2455 }, { %r3024, %r3025, %r3026, %r3027 }, { %r1286, %r1287 }, { %f2452, %f2453, %f2454, %f2455 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2460, %f2461, %f2462, %f2463 }, { %r3024, %r3025, %r3026, %r3027 }, { %r1292, %r1293 }, { %f2460, %f2461, %f2462, %f2463 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2468, %f2469, %f2470, %f2471 }, { %r3036, %r3037, %r3038, %r3039 }, { %r1286, %r1287 }, { %f2468, %f2469, %f2470, %f2471 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2476, %f2477, %f2478, %f2479 }, { %r3036, %r3037, %r3038, %r3039 }, { %r1292, %r1293 }, { %f2476, %f2477, %f2478, %f2479 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2452, %f2453, %f2454, %f2455 }, { %r3048, %r3049, %r3050, %r3051 }, { %r1310, %r1311 }, { %f2452, %f2453, %f2454, %f2455 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2460, %f2461, %f2462, %f2463 }, { %r3048, %r3049, %r3050, %r3051 }, { %r1316, %r1317 }, { %f2460, %f2461, %f2462, %f2463 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2468, %f2469, %f2470, %f2471 }, { %r3060, %r3061, %r3062, %r3063 }, { %r1310, %r1311 }, { %f2468, %f2469, %f2470, %f2471 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2476, %f2477, %f2478, %f2479 }, { %r3060, %r3061, %r3062, %r3063 }, { %r1316, %r1317 }, { %f2476, %f2477, %f2478, %f2479 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2452, %f2453, %f2454, %f2455 }, { %r3072, %r3073, %r3074, %r3075 }, { %r1334, %r1335 }, { %f2452, %f2453, %f2454, %f2455 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2460, %f2461, %f2462, %f2463 }, { %r3072, %r3073, %r3074, %r3075 }, { %r1340, %r1341 }, { %f2460, %f2461, %f2462, %f2463 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2468, %f2469, %f2470, %f2471 }, { %r3084, %r3085, %r3086, %r3087 }, { %r1334, %r1335 }, { %f2468, %f2469, %f2470, %f2471 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2476, %f2477, %f2478, %f2479 }, { %r3084, %r3085, %r3086, %r3087 }, { %r1340, %r1341 }, { %f2476, %f2477, %f2478, %f2479 };
	// end inline asm
	.loc	1 170 55                        // prefix_prefill.py:170:55
	setp.lt.s32 	%p100, %r154, %r5;
	setp.lt.s32 	%p101, %r155, %r5;
	setp.lt.s32 	%p102, %r156, %r5;
	setp.lt.s32 	%p103, %r157, %r5;
	.loc	1 171 22                        // prefix_prefill.py:171:22
	selp.f32 	%f2716, %f2452, 0fFF800000, %p100;
	selp.f32 	%f2717, %f2453, 0fFF800000, %p101;
	selp.f32 	%f2718, %f2454, 0fFF800000, %p100;
	selp.f32 	%f2719, %f2455, 0fFF800000, %p101;
	selp.f32 	%f2720, %f2460, 0fFF800000, %p102;
	selp.f32 	%f2721, %f2461, 0fFF800000, %p103;
	selp.f32 	%f2722, %f2462, 0fFF800000, %p102;
	selp.f32 	%f2723, %f2463, 0fFF800000, %p103;
	selp.f32 	%f2724, %f2468, 0fFF800000, %p100;
	selp.f32 	%f2725, %f2469, 0fFF800000, %p101;
	selp.f32 	%f2726, %f2470, 0fFF800000, %p100;
	selp.f32 	%f2727, %f2471, 0fFF800000, %p101;
	selp.f32 	%f2728, %f2476, 0fFF800000, %p102;
	selp.f32 	%f2729, %f2477, 0fFF800000, %p103;
	selp.f32 	%f2730, %f2478, 0fFF800000, %p102;
	selp.f32 	%f2731, %f2479, 0fFF800000, %p103;
	.loc	1 172 14                        // prefix_prefill.py:172:14
	mul.f32 	%f2732, %f2401, %f2716;
	mul.f32 	%f2733, %f2401, %f2717;
	mul.f32 	%f2734, %f2401, %f2718;
	mul.f32 	%f2735, %f2401, %f2719;
	mul.f32 	%f2736, %f2401, %f2720;
	mul.f32 	%f2737, %f2401, %f2721;
	mul.f32 	%f2738, %f2401, %f2722;
	mul.f32 	%f2739, %f2401, %f2723;
	mul.f32 	%f2740, %f2401, %f2724;
	mul.f32 	%f2741, %f2401, %f2725;
	mul.f32 	%f2742, %f2401, %f2726;
	mul.f32 	%f2743, %f2401, %f2727;
	mul.f32 	%f2744, %f2401, %f2728;
	mul.f32 	%f2745, %f2401, %f2729;
	mul.f32 	%f2746, %f2401, %f2730;
	mul.f32 	%f2747, %f2401, %f2731;
$L__tmp1:
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f2748, %f2732, %f2733;
	max.f32 	%f2749, %f2734, %f2735;
	max.f32 	%f2750, %f2748, %f2736;
	max.f32 	%f2751, %f2750, %f2737;
	max.f32 	%f2752, %f2749, %f2738;
	max.f32 	%f2753, %f2752, %f2739;
	max.f32 	%f2754, %f2740, %f2741;
	max.f32 	%f2755, %f2742, %f2743;
	max.f32 	%f2756, %f2754, %f2744;
	max.f32 	%f2757, %f2756, %f2745;
	max.f32 	%f2758, %f2755, %f2746;
	max.f32 	%f2759, %f2758, %f2747;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r1358, %f2751;
	shfl.sync.bfly.b32	%r1359, %r1358, 2, 31, -1;
	mov.b32 	%f2760, %r1359;
	mov.b32 	%r1360, %f2753;
	mov.b32 	%r1361, %f2757;
	mov.b32 	%r1362, %f2759;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f2761, %f2751, %f2760;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r1363, %f2761;
	shfl.sync.bfly.b32	%r1364, %r1363, 1, 31, -1;
	shfl.sync.bfly.b32	%r1365, %r1360, 2, 31, -1;
	mov.b32 	%f2762, %r1365;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f2763, %f2753, %f2762;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r1366, %f2763;
	shfl.sync.bfly.b32	%r1367, %r1366, 1, 31, -1;
	shfl.sync.bfly.b32	%r1368, %r1361, 2, 31, -1;
	mov.b32 	%f2764, %r1368;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f2765, %f2757, %f2764;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r1369, %f2765;
	shfl.sync.bfly.b32	%r1370, %r1369, 1, 31, -1;
	shfl.sync.bfly.b32	%r1371, %r1362, 2, 31, -1;
	mov.b32 	%f2766, %r1371;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f2767, %f2759, %f2766;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r1372, %f2767;
	shfl.sync.bfly.b32	%r1373, %r1372, 1, 31, -1;
	mov.b32 	%f2768, %r1373;
	mov.b32 	%f2769, %r1370;
	mov.b32 	%f2770, %r1367;
	mov.b32 	%f2771, %r1364;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f2772, %f2761, %f2771;
	max.f32 	%f2773, %f2763, %f2770;
	max.f32 	%f2774, %f2765, %f2769;
	max.f32 	%f2775, %f2767, %f2768;
$L__tmp2:
	.loc	1 190 31                        // prefix_prefill.py:190:31
	max.f32 	%f276, %f8519, %f2775;
	max.f32 	%f275, %f8518, %f2774;
	max.f32 	%f274, %f8517, %f2773;
	max.f32 	%f273, %f8516, %f2772;
	.loc	1 191 24                        // prefix_prefill.py:191:24
	neg.f32 	%f2776, %f273;
	fma.rn.f32 	%f2777, %f2401, %f2716, %f2776;
	fma.rn.f32 	%f2778, %f2401, %f2717, %f2776;
	neg.f32 	%f2779, %f274;
	fma.rn.f32 	%f2780, %f2401, %f2718, %f2779;
	fma.rn.f32 	%f2781, %f2401, %f2719, %f2779;
	fma.rn.f32 	%f2782, %f2401, %f2720, %f2776;
	fma.rn.f32 	%f2783, %f2401, %f2721, %f2776;
	fma.rn.f32 	%f2784, %f2401, %f2722, %f2779;
	fma.rn.f32 	%f2785, %f2401, %f2723, %f2779;
	neg.f32 	%f2786, %f275;
	fma.rn.f32 	%f2787, %f2401, %f2724, %f2786;
	fma.rn.f32 	%f2788, %f2401, %f2725, %f2786;
	neg.f32 	%f2789, %f276;
	fma.rn.f32 	%f2790, %f2401, %f2726, %f2789;
	fma.rn.f32 	%f2791, %f2401, %f2727, %f2789;
	fma.rn.f32 	%f2792, %f2401, %f2728, %f2786;
	fma.rn.f32 	%f2793, %f2401, %f2729, %f2786;
	fma.rn.f32 	%f2794, %f2401, %f2730, %f2789;
	fma.rn.f32 	%f2795, %f2401, %f2731, %f2789;
	.loc	1 191 19                        // prefix_prefill.py:191:19
	mul.f32 	%f2677, %f2777, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f2676, %f2677;
	// end inline asm
	mul.f32 	%f2679, %f2778, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f2678, %f2679;
	// end inline asm
	mul.f32 	%f2681, %f2780, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f2680, %f2681;
	// end inline asm
	mul.f32 	%f2683, %f2781, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f2682, %f2683;
	// end inline asm
	mul.f32 	%f2685, %f2782, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f2684, %f2685;
	// end inline asm
	mul.f32 	%f2687, %f2783, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f2686, %f2687;
	// end inline asm
	mul.f32 	%f2689, %f2784, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f2688, %f2689;
	// end inline asm
	mul.f32 	%f2691, %f2785, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f2690, %f2691;
	// end inline asm
	mul.f32 	%f2693, %f2787, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f2692, %f2693;
	// end inline asm
	mul.f32 	%f2695, %f2788, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f2694, %f2695;
	// end inline asm
	mul.f32 	%f2697, %f2790, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f2696, %f2697;
	// end inline asm
	mul.f32 	%f2699, %f2791, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f2698, %f2699;
	// end inline asm
	mul.f32 	%f2701, %f2792, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f2700, %f2701;
	// end inline asm
	mul.f32 	%f2703, %f2793, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f2702, %f2703;
	// end inline asm
	mul.f32 	%f2705, %f2794, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f2704, %f2705;
	// end inline asm
	mul.f32 	%f2707, %f2795, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f2706, %f2707;
	// end inline asm
$L__tmp3:
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f2796, %f2676, %f2678;
	add.f32 	%f2797, %f2680, %f2682;
	add.f32 	%f2798, %f2796, %f2684;
	add.f32 	%f2799, %f2798, %f2686;
	add.f32 	%f2800, %f2797, %f2688;
	add.f32 	%f2801, %f2800, %f2690;
	add.f32 	%f2802, %f2692, %f2694;
	add.f32 	%f2803, %f2696, %f2698;
	add.f32 	%f2804, %f2802, %f2700;
	add.f32 	%f2805, %f2804, %f2702;
	add.f32 	%f2806, %f2803, %f2704;
	add.f32 	%f2807, %f2806, %f2706;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r1374, %f2799;
	shfl.sync.bfly.b32	%r1375, %r1374, 2, 31, -1;
	mov.b32 	%f2808, %r1375;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f2809, %f2799, %f2808;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r1376, %f2809;
	shfl.sync.bfly.b32	%r1377, %r1376, 1, 31, -1;
	mov.b32 	%r1378, %f2801;
	shfl.sync.bfly.b32	%r1379, %r1378, 2, 31, -1;
	mov.b32 	%f2810, %r1379;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f2811, %f2801, %f2810;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r1380, %f2811;
	shfl.sync.bfly.b32	%r1381, %r1380, 1, 31, -1;
	mov.b32 	%r1382, %f2805;
	shfl.sync.bfly.b32	%r1383, %r1382, 2, 31, -1;
	mov.b32 	%f2812, %r1383;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f2813, %f2805, %f2812;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r1384, %f2813;
	shfl.sync.bfly.b32	%r1385, %r1384, 1, 31, -1;
	mov.b32 	%r1386, %f2807;
	shfl.sync.bfly.b32	%r1387, %r1386, 2, 31, -1;
	mov.b32 	%f2814, %r1387;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f2815, %f2807, %f2814;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r1388, %f2815;
	shfl.sync.bfly.b32	%r1389, %r1388, 1, 31, -1;
$L__tmp4:
	.loc	1 193 29                        // prefix_prefill.py:193:29
	sub.f32 	%f2820, %f8519, %f276;
	sub.f32 	%f2821, %f8518, %f275;
	sub.f32 	%f2822, %f8517, %f274;
	sub.f32 	%f2823, %f8516, %f273;
	.loc	1 193 23                        // prefix_prefill.py:193:23
	mul.f32 	%f2709, %f2823, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f2708, %f2709;
	// end inline asm
	mul.f32 	%f2711, %f2822, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f2710, %f2711;
	// end inline asm
	mul.f32 	%f2713, %f2821, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f2712, %f2713;
	// end inline asm
	mul.f32 	%f2715, %f2820, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f2714, %f2715;
	// end inline asm
	.loc	1 194 20                        // prefix_prefill.py:194:20
	mul.f32 	%f2824, %f8524, %f2708;
	mul.f32 	%f2825, %f8525, %f2708;
	mul.f32 	%f2826, %f8526, %f2710;
	mul.f32 	%f2827, %f8527, %f2710;
	mul.f32 	%f2832, %f8528, %f2708;
	mul.f32 	%f2833, %f8529, %f2708;
	mul.f32 	%f2834, %f8530, %f2710;
	mul.f32 	%f2835, %f8531, %f2710;
	mul.f32 	%f2840, %f8532, %f2708;
	mul.f32 	%f2841, %f8533, %f2708;
	mul.f32 	%f2842, %f8534, %f2710;
	mul.f32 	%f2843, %f8535, %f2710;
	mul.f32 	%f2848, %f8536, %f2708;
	mul.f32 	%f2849, %f8537, %f2708;
	mul.f32 	%f2850, %f8538, %f2710;
	mul.f32 	%f2851, %f8539, %f2710;
	mul.f32 	%f2856, %f8540, %f2708;
	mul.f32 	%f2857, %f8541, %f2708;
	mul.f32 	%f2858, %f8542, %f2710;
	mul.f32 	%f2859, %f8543, %f2710;
	mul.f32 	%f2864, %f8544, %f2708;
	mul.f32 	%f2865, %f8545, %f2708;
	mul.f32 	%f2866, %f8546, %f2710;
	mul.f32 	%f2867, %f8547, %f2710;
	mul.f32 	%f2872, %f8548, %f2708;
	mul.f32 	%f2873, %f8549, %f2708;
	mul.f32 	%f2874, %f8550, %f2710;
	mul.f32 	%f2875, %f8551, %f2710;
	mul.f32 	%f2880, %f8552, %f2708;
	mul.f32 	%f2881, %f8553, %f2708;
	mul.f32 	%f2882, %f8554, %f2710;
	mul.f32 	%f2883, %f8555, %f2710;
	mul.f32 	%f2888, %f8556, %f2708;
	mul.f32 	%f2889, %f8557, %f2708;
	mul.f32 	%f2890, %f8558, %f2710;
	mul.f32 	%f2891, %f8559, %f2710;
	mul.f32 	%f2896, %f8560, %f2708;
	mul.f32 	%f2897, %f8561, %f2708;
	mul.f32 	%f2898, %f8562, %f2710;
	mul.f32 	%f2899, %f8563, %f2710;
	mul.f32 	%f2904, %f8564, %f2708;
	mul.f32 	%f2905, %f8565, %f2708;
	mul.f32 	%f2906, %f8566, %f2710;
	mul.f32 	%f2907, %f8567, %f2710;
	mul.f32 	%f2912, %f8568, %f2708;
	mul.f32 	%f2913, %f8569, %f2708;
	mul.f32 	%f2914, %f8570, %f2710;
	mul.f32 	%f2915, %f8571, %f2710;
	mul.f32 	%f2920, %f8572, %f2708;
	mul.f32 	%f2921, %f8573, %f2708;
	mul.f32 	%f2922, %f8574, %f2710;
	mul.f32 	%f2923, %f8575, %f2710;
	mul.f32 	%f2928, %f8576, %f2708;
	mul.f32 	%f2929, %f8577, %f2708;
	mul.f32 	%f2930, %f8578, %f2710;
	mul.f32 	%f2931, %f8579, %f2710;
	mul.f32 	%f2936, %f8580, %f2708;
	mul.f32 	%f2937, %f8581, %f2708;
	mul.f32 	%f2938, %f8582, %f2710;
	mul.f32 	%f2939, %f8583, %f2710;
	mul.f32 	%f2944, %f8584, %f2708;
	mul.f32 	%f2945, %f8585, %f2708;
	mul.f32 	%f2946, %f8586, %f2710;
	mul.f32 	%f2947, %f8587, %f2710;
	mul.f32 	%f2952, %f8588, %f2712;
	mul.f32 	%f2953, %f8589, %f2712;
	mul.f32 	%f2954, %f8590, %f2714;
	mul.f32 	%f2955, %f8591, %f2714;
	mul.f32 	%f2960, %f8592, %f2712;
	mul.f32 	%f2961, %f8593, %f2712;
	mul.f32 	%f2962, %f8594, %f2714;
	mul.f32 	%f2963, %f8595, %f2714;
	mul.f32 	%f2968, %f8596, %f2712;
	mul.f32 	%f2969, %f8597, %f2712;
	mul.f32 	%f2970, %f8598, %f2714;
	mul.f32 	%f2971, %f8599, %f2714;
	mul.f32 	%f2976, %f8600, %f2712;
	mul.f32 	%f2977, %f8601, %f2712;
	mul.f32 	%f2978, %f8602, %f2714;
	mul.f32 	%f2979, %f8603, %f2714;
	mul.f32 	%f2984, %f8604, %f2712;
	mul.f32 	%f2985, %f8605, %f2712;
	mul.f32 	%f2986, %f8606, %f2714;
	mul.f32 	%f2987, %f8607, %f2714;
	mul.f32 	%f2992, %f8608, %f2712;
	mul.f32 	%f2993, %f8609, %f2712;
	mul.f32 	%f2994, %f8610, %f2714;
	mul.f32 	%f2995, %f8611, %f2714;
	mul.f32 	%f3000, %f8612, %f2712;
	mul.f32 	%f3001, %f8613, %f2712;
	mul.f32 	%f3002, %f8614, %f2714;
	mul.f32 	%f3003, %f8615, %f2714;
	mul.f32 	%f3008, %f8616, %f2712;
	mul.f32 	%f3009, %f8617, %f2712;
	mul.f32 	%f3010, %f8618, %f2714;
	mul.f32 	%f3011, %f8619, %f2714;
	mul.f32 	%f3016, %f8620, %f2712;
	mul.f32 	%f3017, %f8621, %f2712;
	mul.f32 	%f3018, %f8622, %f2714;
	mul.f32 	%f3019, %f8623, %f2714;
	mul.f32 	%f3024, %f8624, %f2712;
	mul.f32 	%f3025, %f8625, %f2712;
	mul.f32 	%f3026, %f8626, %f2714;
	mul.f32 	%f3027, %f8627, %f2714;
	mul.f32 	%f3032, %f8628, %f2712;
	mul.f32 	%f3033, %f8629, %f2712;
	mul.f32 	%f3034, %f8630, %f2714;
	mul.f32 	%f3035, %f8631, %f2714;
	mul.f32 	%f3040, %f8632, %f2712;
	mul.f32 	%f3041, %f8633, %f2712;
	mul.f32 	%f3042, %f8634, %f2714;
	mul.f32 	%f3043, %f8635, %f2714;
	mul.f32 	%f3048, %f8636, %f2712;
	mul.f32 	%f3049, %f8637, %f2712;
	mul.f32 	%f3050, %f8638, %f2714;
	mul.f32 	%f3051, %f8639, %f2714;
	mul.f32 	%f3056, %f8640, %f2712;
	mul.f32 	%f3057, %f8641, %f2712;
	mul.f32 	%f3058, %f8642, %f2714;
	mul.f32 	%f3059, %f8643, %f2714;
	mul.f32 	%f3064, %f8644, %f2712;
	mul.f32 	%f3065, %f8645, %f2712;
	mul.f32 	%f3066, %f8646, %f2714;
	mul.f32 	%f3067, %f8647, %f2714;
	mul.f32 	%f3072, %f8648, %f2712;
	mul.f32 	%f3073, %f8649, %f2712;
	mul.f32 	%f3074, %f8650, %f2714;
	mul.f32 	%f3075, %f8651, %f2714;
	add.s32 	%r7324, %r21, %r7326;
	mul.wide.s32 	%rd546, %r160, 2;
	mul.wide.s32 	%rd547, %r168, 2;
	.loc	1 197 11                        // prefix_prefill.py:197:11
	@%p86 bra 	$L__BB0_11;
// %bb.10:                              //   in Loop: Header=BB0_2 Depth=1
	.loc	1 0 0                           // prefix_prefill.py:0:0
	add.s32 	%r161, %r1014, %r70;
	add.s32 	%r162, %r1014, %r71;
	add.s32 	%r163, %r1014, %r72;
	add.s32 	%r164, %r1014, %r73;
	add.s32 	%r165, %r1014, %r74;
	add.s32 	%r166, %r1014, %r75;
	add.s32 	%r167, %r1014, %r76;
	add.s32 	%r169, %r1015, %r70;
	add.s32 	%r170, %r1015, %r71;
	add.s32 	%r171, %r1015, %r72;
	add.s32 	%r172, %r1015, %r73;
	add.s32 	%r173, %r1015, %r74;
	add.s32 	%r174, %r1015, %r75;
	add.s32 	%r175, %r1015, %r76;
	.loc	1 202 28                        // prefix_prefill.py:202:28
	add.s32 	%r1399, %r7324, 1;
	add.s32 	%r1400, %r7324, 2;
	add.s32 	%r1401, %r7324, 3;
	add.s32 	%r1402, %r7324, 4;
	add.s32 	%r1403, %r7324, 5;
	add.s32 	%r1404, %r7324, 6;
	.loc	1 202 50                        // prefix_prefill.py:202:50
	add.s32 	%r1405, %r7324, 7;
	setp.lt.s32 	%p106, %r7324, %r5;
	setp.lt.s32 	%p108, %r1399, %r5;
	setp.lt.s32 	%p110, %r1400, %r5;
	setp.lt.s32 	%p112, %r1401, %r5;
	setp.lt.s32 	%p114, %r1402, %r5;
	setp.lt.s32 	%p116, %r1403, %r5;
	setp.lt.s32 	%p118, %r1404, %r5;
	setp.lt.s32 	%p120, %r1405, %r5;
	.loc	1 200 26                        // prefix_prefill.py:200:26
	add.s64 	%rd167, %rd111, %rd546;
	mul.wide.s32 	%rd184, %r161, 2;
	add.s64 	%rd168, %rd111, %rd184;
	mul.wide.s32 	%rd185, %r162, 2;
	add.s64 	%rd169, %rd111, %rd185;
	mul.wide.s32 	%rd186, %r163, 2;
	add.s64 	%rd170, %rd111, %rd186;
	mul.wide.s32 	%rd187, %r164, 2;
	add.s64 	%rd171, %rd111, %rd187;
	mul.wide.s32 	%rd188, %r165, 2;
	add.s64 	%rd172, %rd111, %rd188;
	mul.wide.s32 	%rd189, %r166, 2;
	add.s64 	%rd173, %rd111, %rd189;
	mul.wide.s32 	%rd190, %r167, 2;
	add.s64 	%rd174, %rd111, %rd190;
	add.s64 	%rd175, %rd111, %rd547;
	mul.wide.s32 	%rd192, %r169, 2;
	add.s64 	%rd176, %rd111, %rd192;
	mul.wide.s32 	%rd193, %r170, 2;
	add.s64 	%rd177, %rd111, %rd193;
	mul.wide.s32 	%rd194, %r171, 2;
	add.s64 	%rd178, %rd111, %rd194;
	mul.wide.s32 	%rd195, %r172, 2;
	add.s64 	%rd179, %rd111, %rd195;
	mul.wide.s32 	%rd196, %r173, 2;
	add.s64 	%rd180, %rd111, %rd196;
	mul.wide.s32 	%rd197, %r174, 2;
	add.s64 	%rd181, %rd111, %rd197;
	mul.wide.s32 	%rd198, %r175, 2;
	add.s64 	%rd182, %rd111, %rd198;
	.loc	1 200 16                        // prefix_prefill.py:200:16
	// begin inline asm
	mov.u16 %rs1, 0x0;
	@%p106 ld.global.b16 { %rs1 }, [ %rd167 + 0 ];
	@!%p106 mov.u16 %rs1, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs3, 0x0;
	@%p108 ld.global.b16 { %rs3 }, [ %rd168 + 0 ];
	@!%p108 mov.u16 %rs3, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs5, 0x0;
	@%p110 ld.global.b16 { %rs5 }, [ %rd169 + 0 ];
	@!%p110 mov.u16 %rs5, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs7, 0x0;
	@%p112 ld.global.b16 { %rs7 }, [ %rd170 + 0 ];
	@!%p112 mov.u16 %rs7, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs9, 0x0;
	@%p114 ld.global.b16 { %rs9 }, [ %rd171 + 0 ];
	@!%p114 mov.u16 %rs9, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs11, 0x0;
	@%p116 ld.global.b16 { %rs11 }, [ %rd172 + 0 ];
	@!%p116 mov.u16 %rs11, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs13, 0x0;
	@%p118 ld.global.b16 { %rs13 }, [ %rd173 + 0 ];
	@!%p118 mov.u16 %rs13, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs15, 0x0;
	@%p120 ld.global.b16 { %rs15 }, [ %rd174 + 0 ];
	@!%p120 mov.u16 %rs15, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs17, 0x0;
	@%p106 ld.global.b16 { %rs17 }, [ %rd175 + 0 ];
	@!%p106 mov.u16 %rs17, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs19, 0x0;
	@%p108 ld.global.b16 { %rs19 }, [ %rd176 + 0 ];
	@!%p108 mov.u16 %rs19, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs21, 0x0;
	@%p110 ld.global.b16 { %rs21 }, [ %rd177 + 0 ];
	@!%p110 mov.u16 %rs21, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs23, 0x0;
	@%p112 ld.global.b16 { %rs23 }, [ %rd178 + 0 ];
	@!%p112 mov.u16 %rs23, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs25, 0x0;
	@%p114 ld.global.b16 { %rs25 }, [ %rd179 + 0 ];
	@!%p114 mov.u16 %rs25, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs27, 0x0;
	@%p116 ld.global.b16 { %rs27 }, [ %rd180 + 0 ];
	@!%p116 mov.u16 %rs27, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs29, 0x0;
	@%p118 ld.global.b16 { %rs29 }, [ %rd181 + 0 ];
	@!%p118 mov.u16 %rs29, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs31, 0x0;
	@%p120 ld.global.b16 { %rs31 }, [ %rd182 + 0 ];
	@!%p120 mov.u16 %rs31, %rs258;
	// end inline asm
	mov.b32 	%r7335, {%rs1, %rs3};
	mov.b32 	%r7336, {%rs5, %rs7};
	mov.b32 	%r7337, {%rs9, %rs11};
	mov.b32 	%r7338, {%rs13, %rs15};
	mov.b32 	%r7339, {%rs17, %rs19};
	mov.b32 	%r7340, {%rs21, %rs23};
	mov.b32 	%r7341, {%rs25, %rs27};
	mov.b32 	%r7342, {%rs29, %rs31};
	.loc	1 197 11                        // prefix_prefill.py:197:11
	bra.uni 	$L__BB0_12;
$L__BB0_11:                             //   in Loop: Header=BB0_2 Depth=1
	.loc	1 205 39                        // prefix_prefill.py:205:39
	add.s64 	%rd163, %rd111, %rd546;
	add.s64 	%rd164, %rd111, %rd547;
	.loc	1 205 29                        // prefix_prefill.py:205:29
	// begin inline asm
	mov.u32 %r7335, 0x0;
	mov.u32 %r7336, 0x0;
	mov.u32 %r7337, 0x0;
	mov.u32 %r7338, 0x0;
	@%p546 ld.global.v4.b32 { %r7335, %r7336, %r7337, %r7338 }, [ %rd163 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r7339, 0x0;
	mov.u32 %r7340, 0x0;
	mov.u32 %r7341, 0x0;
	mov.u32 %r7342, 0x0;
	@%p546 ld.global.v4.b32 { %r7339, %r7340, %r7341, %r7342 }, [ %rd164 + 0 ];
	// end inline asm
$L__BB0_12:                             //   in Loop: Header=BB0_2 Depth=1
	.loc	1 197 11                        // prefix_prefill.py:197:11
	bar.sync 	0;
	st.shared.v4.b32 	[%r105], {%r7335, %r7336, %r7337, %r7338};
	st.shared.v4.b32 	[%r106], {%r7339, %r7340, %r7341, %r7342};
	.loc	1 211 17                        // prefix_prefill.py:211:17
	mov.b32 	%r1414, %f2676;
	// begin inline asm
	cvt.rn.bf16.f32 %rs33, %r1414;
	// end inline asm
	mov.b32 	%r1415, %f2678;
	// begin inline asm
	cvt.rn.bf16.f32 %rs34, %r1415;
	// end inline asm
	mov.b32 	%r1416, %f2680;
	// begin inline asm
	cvt.rn.bf16.f32 %rs35, %r1416;
	// end inline asm
	mov.b32 	%r1417, %f2682;
	// begin inline asm
	cvt.rn.bf16.f32 %rs36, %r1417;
	// end inline asm
	mov.b32 	%r1418, %f2684;
	// begin inline asm
	cvt.rn.bf16.f32 %rs37, %r1418;
	// end inline asm
	mov.b32 	%r1419, %f2686;
	// begin inline asm
	cvt.rn.bf16.f32 %rs38, %r1419;
	// end inline asm
	mov.b32 	%r1420, %f2688;
	// begin inline asm
	cvt.rn.bf16.f32 %rs39, %r1420;
	// end inline asm
	mov.b32 	%r1421, %f2690;
	// begin inline asm
	cvt.rn.bf16.f32 %rs40, %r1421;
	// end inline asm
	mov.b32 	%r1422, %f2692;
	// begin inline asm
	cvt.rn.bf16.f32 %rs41, %r1422;
	// end inline asm
	mov.b32 	%r1423, %f2694;
	// begin inline asm
	cvt.rn.bf16.f32 %rs42, %r1423;
	// end inline asm
	mov.b32 	%r1424, %f2696;
	// begin inline asm
	cvt.rn.bf16.f32 %rs43, %r1424;
	// end inline asm
	mov.b32 	%r1425, %f2698;
	// begin inline asm
	cvt.rn.bf16.f32 %rs44, %r1425;
	// end inline asm
	mov.b32 	%r1426, %f2700;
	// begin inline asm
	cvt.rn.bf16.f32 %rs45, %r1426;
	// end inline asm
	mov.b32 	%r1427, %f2702;
	// begin inline asm
	cvt.rn.bf16.f32 %rs46, %r1427;
	// end inline asm
	mov.b32 	%r1428, %f2704;
	// begin inline asm
	cvt.rn.bf16.f32 %rs47, %r1428;
	// end inline asm
	mov.b32 	%r1429, %f2706;
	// begin inline asm
	cvt.rn.bf16.f32 %rs48, %r1429;
	// end inline asm
	mov.b32 	%r1470, {%rs33, %rs34};
	mov.b32 	%r1471, {%rs35, %rs36};
	mov.b32 	%r1472, {%rs37, %rs38};
	mov.b32 	%r1473, {%rs39, %rs40};
	mov.b32 	%r1566, {%rs41, %rs42};
	mov.b32 	%r1567, {%rs43, %rs44};
	mov.b32 	%r1568, {%rs45, %rs46};
	mov.b32 	%r1569, {%rs47, %rs48};
	.loc	1 197 11                        // prefix_prefill.py:197:11
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1474, %r1475, %r1480, %r1481 }, [ %r1434 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1486, %r1487, %r1492, %r1493 }, [ %r1439 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1498, %r1499, %r1504, %r1505 }, [ %r1444 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1510, %r1511, %r1516, %r1517 }, [ %r1449 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1522, %r1523, %r1528, %r1529 }, [ %r1454 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1534, %r1535, %r1540, %r1541 }, [ %r1459 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1546, %r1547, %r1552, %r1553 }, [ %r1464 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1558, %r1559, %r1564, %r1565 }, [ %r1469 + 0 ];
	// end inline asm
	.loc	1 213 24                        // prefix_prefill.py:213:24
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2824, %f2825, %f2826, %f2827 }, { %r1470, %r1471, %r1472, %r1473 }, { %r1474, %r1475 }, { %f2824, %f2825, %f2826, %f2827 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2832, %f2833, %f2834, %f2835 }, { %r1470, %r1471, %r1472, %r1473 }, { %r1480, %r1481 }, { %f2832, %f2833, %f2834, %f2835 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2840, %f2841, %f2842, %f2843 }, { %r1470, %r1471, %r1472, %r1473 }, { %r1486, %r1487 }, { %f2840, %f2841, %f2842, %f2843 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2848, %f2849, %f2850, %f2851 }, { %r1470, %r1471, %r1472, %r1473 }, { %r1492, %r1493 }, { %f2848, %f2849, %f2850, %f2851 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2856, %f2857, %f2858, %f2859 }, { %r1470, %r1471, %r1472, %r1473 }, { %r1498, %r1499 }, { %f2856, %f2857, %f2858, %f2859 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2864, %f2865, %f2866, %f2867 }, { %r1470, %r1471, %r1472, %r1473 }, { %r1504, %r1505 }, { %f2864, %f2865, %f2866, %f2867 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2872, %f2873, %f2874, %f2875 }, { %r1470, %r1471, %r1472, %r1473 }, { %r1510, %r1511 }, { %f2872, %f2873, %f2874, %f2875 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2880, %f2881, %f2882, %f2883 }, { %r1470, %r1471, %r1472, %r1473 }, { %r1516, %r1517 }, { %f2880, %f2881, %f2882, %f2883 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2888, %f2889, %f2890, %f2891 }, { %r1470, %r1471, %r1472, %r1473 }, { %r1522, %r1523 }, { %f2888, %f2889, %f2890, %f2891 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2896, %f2897, %f2898, %f2899 }, { %r1470, %r1471, %r1472, %r1473 }, { %r1528, %r1529 }, { %f2896, %f2897, %f2898, %f2899 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2904, %f2905, %f2906, %f2907 }, { %r1470, %r1471, %r1472, %r1473 }, { %r1534, %r1535 }, { %f2904, %f2905, %f2906, %f2907 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2912, %f2913, %f2914, %f2915 }, { %r1470, %r1471, %r1472, %r1473 }, { %r1540, %r1541 }, { %f2912, %f2913, %f2914, %f2915 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2920, %f2921, %f2922, %f2923 }, { %r1470, %r1471, %r1472, %r1473 }, { %r1546, %r1547 }, { %f2920, %f2921, %f2922, %f2923 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2928, %f2929, %f2930, %f2931 }, { %r1470, %r1471, %r1472, %r1473 }, { %r1552, %r1553 }, { %f2928, %f2929, %f2930, %f2931 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2936, %f2937, %f2938, %f2939 }, { %r1470, %r1471, %r1472, %r1473 }, { %r1558, %r1559 }, { %f2936, %f2937, %f2938, %f2939 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2944, %f2945, %f2946, %f2947 }, { %r1470, %r1471, %r1472, %r1473 }, { %r1564, %r1565 }, { %f2944, %f2945, %f2946, %f2947 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2952, %f2953, %f2954, %f2955 }, { %r1566, %r1567, %r1568, %r1569 }, { %r1474, %r1475 }, { %f2952, %f2953, %f2954, %f2955 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2960, %f2961, %f2962, %f2963 }, { %r1566, %r1567, %r1568, %r1569 }, { %r1480, %r1481 }, { %f2960, %f2961, %f2962, %f2963 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2968, %f2969, %f2970, %f2971 }, { %r1566, %r1567, %r1568, %r1569 }, { %r1486, %r1487 }, { %f2968, %f2969, %f2970, %f2971 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2976, %f2977, %f2978, %f2979 }, { %r1566, %r1567, %r1568, %r1569 }, { %r1492, %r1493 }, { %f2976, %f2977, %f2978, %f2979 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2984, %f2985, %f2986, %f2987 }, { %r1566, %r1567, %r1568, %r1569 }, { %r1498, %r1499 }, { %f2984, %f2985, %f2986, %f2987 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f2992, %f2993, %f2994, %f2995 }, { %r1566, %r1567, %r1568, %r1569 }, { %r1504, %r1505 }, { %f2992, %f2993, %f2994, %f2995 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3000, %f3001, %f3002, %f3003 }, { %r1566, %r1567, %r1568, %r1569 }, { %r1510, %r1511 }, { %f3000, %f3001, %f3002, %f3003 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3008, %f3009, %f3010, %f3011 }, { %r1566, %r1567, %r1568, %r1569 }, { %r1516, %r1517 }, { %f3008, %f3009, %f3010, %f3011 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3016, %f3017, %f3018, %f3019 }, { %r1566, %r1567, %r1568, %r1569 }, { %r1522, %r1523 }, { %f3016, %f3017, %f3018, %f3019 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3024, %f3025, %f3026, %f3027 }, { %r1566, %r1567, %r1568, %r1569 }, { %r1528, %r1529 }, { %f3024, %f3025, %f3026, %f3027 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3032, %f3033, %f3034, %f3035 }, { %r1566, %r1567, %r1568, %r1569 }, { %r1534, %r1535 }, { %f3032, %f3033, %f3034, %f3035 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3040, %f3041, %f3042, %f3043 }, { %r1566, %r1567, %r1568, %r1569 }, { %r1540, %r1541 }, { %f3040, %f3041, %f3042, %f3043 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3048, %f3049, %f3050, %f3051 }, { %r1566, %r1567, %r1568, %r1569 }, { %r1546, %r1547 }, { %f3048, %f3049, %f3050, %f3051 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3056, %f3057, %f3058, %f3059 }, { %r1566, %r1567, %r1568, %r1569 }, { %r1552, %r1553 }, { %f3056, %f3057, %f3058, %f3059 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3064, %f3065, %f3066, %f3067 }, { %r1566, %r1567, %r1568, %r1569 }, { %r1558, %r1559 }, { %f3064, %f3065, %f3066, %f3067 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3072, %f3073, %f3074, %f3075 }, { %r1566, %r1567, %r1568, %r1569 }, { %r1564, %r1565 }, { %f3072, %f3073, %f3074, %f3075 };
	// end inline asm
	.loc	1 138 21                        // prefix_prefill.py:138:21
	add.s64 	%rd199, %rd550, 4;
	// begin inline asm
	mov.u32 %r1662, 0x0;
	@%p546 ld.global.b32 { %r1662 }, [ %rd199 + 0 ];
	// end inline asm
	.loc	1 142 26                        // prefix_prefill.py:142:26
	mul.lo.s32 	%r1671, %r1662, %r672;
	.loc	1 144 24                        // prefix_prefill.py:144:24
	add.s32 	%r289, %r154, 16;
	add.s32 	%r290, %r154, 17;
	add.s32 	%r291, %r154, 24;
	add.s32 	%r292, %r154, 25;
	add.s32 	%r293, %r1671, %r115;
	add.s32 	%r294, %r1671, %r116;
	.loc	1 148 31                        // prefix_prefill.py:148:31
	mul.lo.s32 	%r1672, %r1662, %r673;
	add.s32 	%r1673, %r1672, %r78;
	add.s32 	%r1674, %r1672, %r79;
	.loc	1 151 17                        // prefix_prefill.py:151:17
	add.s32 	%r295, %r1673, %r21;
	add.s32 	%r303, %r1674, %r21;
	.loc	1 153 34                        // prefix_prefill.py:153:34
	add.s32 	%r311, %r7326, 32;
	setp.le.s32 	%p139, %r311, %r5;
	mul.wide.s32 	%rd544, %r293, 2;
	mul.wide.s32 	%rd545, %r294, 2;
	.loc	1 153 11                        // prefix_prefill.py:153:11
	@%p139 bra 	$L__BB0_14;
// %bb.13:                              //   in Loop: Header=BB0_2 Depth=1
	.loc	1 144 24                        // prefix_prefill.py:144:24
	add.s32 	%r1700, %r7325, 24;
	.loc	1 158 50                        // prefix_prefill.py:158:50
	add.s32 	%r1701, %r7325, 16;
	setp.lt.s32 	%p142, %r1701, %r5;
	setp.lt.s32 	%p147, %r1700, %r5;
	.loc	1 156 26                        // prefix_prefill.py:156:26
	add.s64 	%rd204, %rd110, %rd544;
	add.s64 	%rd205, %rd110, %rd545;
	mov.b32 	%r1687, 0;
	.loc	1 156 16                        // prefix_prefill.py:156:16
	// begin inline asm
	mov.u32 %r7349, 0x0;
	mov.u32 %r7350, 0x0;
	mov.u32 %r7347, 0x0;
	mov.u32 %r7348, 0x0;
	@%p142 ld.global.v4.b32 { %r7349, %r7350, %r7347, %r7348 }, [ %rd204 + 0 ];
	@!%p142 mov.u32 %r7349, %r1687;
	@!%p142 mov.u32 %r7350, %r1687;
	@!%p142 mov.u32 %r7347, %r1687;
	@!%p142 mov.u32 %r7348, %r1687;
	// end inline asm
	// begin inline asm
	mov.u32 %r7343, 0x0;
	mov.u32 %r7344, 0x0;
	mov.u32 %r7345, 0x0;
	mov.u32 %r7346, 0x0;
	@%p147 ld.global.v4.b32 { %r7343, %r7344, %r7345, %r7346 }, [ %rd205 + 0 ];
	@!%p147 mov.u32 %r7343, %r1687;
	@!%p147 mov.u32 %r7344, %r1687;
	@!%p147 mov.u32 %r7345, %r1687;
	@!%p147 mov.u32 %r7346, %r1687;
	// end inline asm
	.loc	1 153 11                        // prefix_prefill.py:153:11
	bra.uni 	$L__BB0_15;
$L__BB0_14:                             //   in Loop: Header=BB0_2 Depth=1
	.loc	1 161 39                        // prefix_prefill.py:161:39
	add.s64 	%rd200, %rd110, %rd544;
	add.s64 	%rd201, %rd110, %rd545;
	.loc	1 161 29                        // prefix_prefill.py:161:29
	// begin inline asm
	mov.u32 %r7349, 0x0;
	mov.u32 %r7350, 0x0;
	mov.u32 %r7347, 0x0;
	mov.u32 %r7348, 0x0;
	@%p546 ld.global.v4.b32 { %r7349, %r7350, %r7347, %r7348 }, [ %rd200 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r7343, 0x0;
	mov.u32 %r7344, 0x0;
	mov.u32 %r7345, 0x0;
	mov.u32 %r7346, 0x0;
	@%p546 ld.global.v4.b32 { %r7343, %r7344, %r7345, %r7346 }, [ %rd201 + 0 ];
	// end inline asm
$L__BB0_15:                             //   in Loop: Header=BB0_2 Depth=1
	.loc	1 0 0                           // prefix_prefill.py:0:0
	mov.b32 	%f2816, %r1389;
	mov.b32 	%f2817, %r1385;
	mov.b32 	%f2818, %r1381;
	mov.b32 	%f2819, %r1377;
	.loc	1 153 11                        // prefix_prefill.py:153:11
	bar.sync 	0;
	st.shared.v4.b32 	[%r80], {%r7349, %r7350, %r7347, %r7348};
	st.shared.v4.b32 	[%r80+2048], {%r7343, %r7344, %r7345, %r7346};
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1746, %r1747, %r1752, %r1753 }, [ %r1126 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1770, %r1771, %r1776, %r1777 }, [ %r1131 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1794, %r1795, %r1800, %r1801 }, [ %r1136 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1818, %r1819, %r1824, %r1825 }, [ %r1141 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1842, %r1843, %r1848, %r1849 }, [ %r1146 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1866, %r1867, %r1872, %r1873 }, [ %r1151 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1890, %r1891, %r1896, %r1897 }, [ %r1156 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r1914, %r1915, %r1920, %r1921 }, [ %r1161 + 0 ];
	// end inline asm
	.loc	1 169 23                        // prefix_prefill.py:169:23
	mov.f32 	%f3112, %f4456;
	mov.f32 	%f3113, %f4456;
	mov.f32 	%f3114, %f4456;
	mov.f32 	%f3115, %f4456;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3112, %f3113, %f3114, %f3115 }, { %r2904, %r2905, %r2906, %r2907 }, { %r1746, %r1747 }, { %f3112, %f3113, %f3114, %f3115 };
	// end inline asm
	mov.f32 	%f3120, %f4456;
	mov.f32 	%f3121, %f4456;
	mov.f32 	%f3122, %f4456;
	mov.f32 	%f3123, %f4456;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3120, %f3121, %f3122, %f3123 }, { %r2904, %r2905, %r2906, %r2907 }, { %r1752, %r1753 }, { %f3120, %f3121, %f3122, %f3123 };
	// end inline asm
	mov.f32 	%f3128, %f4456;
	mov.f32 	%f3129, %f4456;
	mov.f32 	%f3130, %f4456;
	mov.f32 	%f3131, %f4456;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3128, %f3129, %f3130, %f3131 }, { %r2916, %r2917, %r2918, %r2919 }, { %r1746, %r1747 }, { %f3128, %f3129, %f3130, %f3131 };
	// end inline asm
	mov.f32 	%f3139, %f4456;
	mov.f32 	%f3136, %f4456;
	mov.f32 	%f3137, %f4456;
	mov.f32 	%f3138, %f4456;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3136, %f3137, %f3138, %f3139 }, { %r2916, %r2917, %r2918, %r2919 }, { %r1752, %r1753 }, { %f3136, %f3137, %f3138, %f3139 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3112, %f3113, %f3114, %f3115 }, { %r2928, %r2929, %r2930, %r2931 }, { %r1770, %r1771 }, { %f3112, %f3113, %f3114, %f3115 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3120, %f3121, %f3122, %f3123 }, { %r2928, %r2929, %r2930, %r2931 }, { %r1776, %r1777 }, { %f3120, %f3121, %f3122, %f3123 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3128, %f3129, %f3130, %f3131 }, { %r2940, %r2941, %r2942, %r2943 }, { %r1770, %r1771 }, { %f3128, %f3129, %f3130, %f3131 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3136, %f3137, %f3138, %f3139 }, { %r2940, %r2941, %r2942, %r2943 }, { %r1776, %r1777 }, { %f3136, %f3137, %f3138, %f3139 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3112, %f3113, %f3114, %f3115 }, { %r2952, %r2953, %r2954, %r2955 }, { %r1794, %r1795 }, { %f3112, %f3113, %f3114, %f3115 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3120, %f3121, %f3122, %f3123 }, { %r2952, %r2953, %r2954, %r2955 }, { %r1800, %r1801 }, { %f3120, %f3121, %f3122, %f3123 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3128, %f3129, %f3130, %f3131 }, { %r2964, %r2965, %r2966, %r2967 }, { %r1794, %r1795 }, { %f3128, %f3129, %f3130, %f3131 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3136, %f3137, %f3138, %f3139 }, { %r2964, %r2965, %r2966, %r2967 }, { %r1800, %r1801 }, { %f3136, %f3137, %f3138, %f3139 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3112, %f3113, %f3114, %f3115 }, { %r2976, %r2977, %r2978, %r2979 }, { %r1818, %r1819 }, { %f3112, %f3113, %f3114, %f3115 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3120, %f3121, %f3122, %f3123 }, { %r2976, %r2977, %r2978, %r2979 }, { %r1824, %r1825 }, { %f3120, %f3121, %f3122, %f3123 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3128, %f3129, %f3130, %f3131 }, { %r2988, %r2989, %r2990, %r2991 }, { %r1818, %r1819 }, { %f3128, %f3129, %f3130, %f3131 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3136, %f3137, %f3138, %f3139 }, { %r2988, %r2989, %r2990, %r2991 }, { %r1824, %r1825 }, { %f3136, %f3137, %f3138, %f3139 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3112, %f3113, %f3114, %f3115 }, { %r3000, %r3001, %r3002, %r3003 }, { %r1842, %r1843 }, { %f3112, %f3113, %f3114, %f3115 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3120, %f3121, %f3122, %f3123 }, { %r3000, %r3001, %r3002, %r3003 }, { %r1848, %r1849 }, { %f3120, %f3121, %f3122, %f3123 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3128, %f3129, %f3130, %f3131 }, { %r3012, %r3013, %r3014, %r3015 }, { %r1842, %r1843 }, { %f3128, %f3129, %f3130, %f3131 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3136, %f3137, %f3138, %f3139 }, { %r3012, %r3013, %r3014, %r3015 }, { %r1848, %r1849 }, { %f3136, %f3137, %f3138, %f3139 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3112, %f3113, %f3114, %f3115 }, { %r3024, %r3025, %r3026, %r3027 }, { %r1866, %r1867 }, { %f3112, %f3113, %f3114, %f3115 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3120, %f3121, %f3122, %f3123 }, { %r3024, %r3025, %r3026, %r3027 }, { %r1872, %r1873 }, { %f3120, %f3121, %f3122, %f3123 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3128, %f3129, %f3130, %f3131 }, { %r3036, %r3037, %r3038, %r3039 }, { %r1866, %r1867 }, { %f3128, %f3129, %f3130, %f3131 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3136, %f3137, %f3138, %f3139 }, { %r3036, %r3037, %r3038, %r3039 }, { %r1872, %r1873 }, { %f3136, %f3137, %f3138, %f3139 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3112, %f3113, %f3114, %f3115 }, { %r3048, %r3049, %r3050, %r3051 }, { %r1890, %r1891 }, { %f3112, %f3113, %f3114, %f3115 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3120, %f3121, %f3122, %f3123 }, { %r3048, %r3049, %r3050, %r3051 }, { %r1896, %r1897 }, { %f3120, %f3121, %f3122, %f3123 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3128, %f3129, %f3130, %f3131 }, { %r3060, %r3061, %r3062, %r3063 }, { %r1890, %r1891 }, { %f3128, %f3129, %f3130, %f3131 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3136, %f3137, %f3138, %f3139 }, { %r3060, %r3061, %r3062, %r3063 }, { %r1896, %r1897 }, { %f3136, %f3137, %f3138, %f3139 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3112, %f3113, %f3114, %f3115 }, { %r3072, %r3073, %r3074, %r3075 }, { %r1914, %r1915 }, { %f3112, %f3113, %f3114, %f3115 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3120, %f3121, %f3122, %f3123 }, { %r3072, %r3073, %r3074, %r3075 }, { %r1920, %r1921 }, { %f3120, %f3121, %f3122, %f3123 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3128, %f3129, %f3130, %f3131 }, { %r3084, %r3085, %r3086, %r3087 }, { %r1914, %r1915 }, { %f3128, %f3129, %f3130, %f3131 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3136, %f3137, %f3138, %f3139 }, { %r3084, %r3085, %r3086, %r3087 }, { %r1920, %r1921 }, { %f3136, %f3137, %f3138, %f3139 };
	// end inline asm
	.loc	1 170 55                        // prefix_prefill.py:170:55
	setp.lt.s32 	%p153, %r289, %r5;
	setp.lt.s32 	%p154, %r290, %r5;
	setp.lt.s32 	%p155, %r291, %r5;
	setp.lt.s32 	%p156, %r292, %r5;
	.loc	1 171 22                        // prefix_prefill.py:171:22
	selp.f32 	%f3376, %f3112, 0fFF800000, %p153;
	selp.f32 	%f3377, %f3113, 0fFF800000, %p154;
	selp.f32 	%f3378, %f3114, 0fFF800000, %p153;
	selp.f32 	%f3379, %f3115, 0fFF800000, %p154;
	selp.f32 	%f3380, %f3120, 0fFF800000, %p155;
	selp.f32 	%f3381, %f3121, 0fFF800000, %p156;
	selp.f32 	%f3382, %f3122, 0fFF800000, %p155;
	selp.f32 	%f3383, %f3123, 0fFF800000, %p156;
	selp.f32 	%f3384, %f3128, 0fFF800000, %p153;
	selp.f32 	%f3385, %f3129, 0fFF800000, %p154;
	selp.f32 	%f3386, %f3130, 0fFF800000, %p153;
	selp.f32 	%f3387, %f3131, 0fFF800000, %p154;
	selp.f32 	%f3388, %f3136, 0fFF800000, %p155;
	selp.f32 	%f3389, %f3137, 0fFF800000, %p156;
	selp.f32 	%f3390, %f3138, 0fFF800000, %p155;
	selp.f32 	%f3391, %f3139, 0fFF800000, %p156;
	.loc	1 172 14                        // prefix_prefill.py:172:14
	mul.f32 	%f3392, %f2401, %f3376;
	mul.f32 	%f3393, %f2401, %f3377;
	mul.f32 	%f3394, %f2401, %f3378;
	mul.f32 	%f3395, %f2401, %f3379;
	mul.f32 	%f3396, %f2401, %f3380;
	mul.f32 	%f3397, %f2401, %f3381;
	mul.f32 	%f3398, %f2401, %f3382;
	mul.f32 	%f3399, %f2401, %f3383;
	mul.f32 	%f3400, %f2401, %f3384;
	mul.f32 	%f3401, %f2401, %f3385;
	mul.f32 	%f3402, %f2401, %f3386;
	mul.f32 	%f3403, %f2401, %f3387;
	mul.f32 	%f3404, %f2401, %f3388;
	mul.f32 	%f3405, %f2401, %f3389;
	mul.f32 	%f3406, %f2401, %f3390;
	mul.f32 	%f3407, %f2401, %f3391;
$L__tmp5:
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f3408, %f3392, %f3393;
	max.f32 	%f3409, %f3394, %f3395;
	max.f32 	%f3410, %f3408, %f3396;
	max.f32 	%f3411, %f3410, %f3397;
	max.f32 	%f3412, %f3409, %f3398;
	max.f32 	%f3413, %f3412, %f3399;
	max.f32 	%f3414, %f3400, %f3401;
	max.f32 	%f3415, %f3402, %f3403;
	max.f32 	%f3416, %f3414, %f3404;
	max.f32 	%f3417, %f3416, %f3405;
	max.f32 	%f3418, %f3415, %f3406;
	max.f32 	%f3419, %f3418, %f3407;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r1938, %f3411;
	shfl.sync.bfly.b32	%r1939, %r1938, 2, 31, -1;
	mov.b32 	%f3420, %r1939;
	mov.b32 	%r1940, %f3413;
	mov.b32 	%r1941, %f3417;
	mov.b32 	%r1942, %f3419;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f3421, %f3411, %f3420;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r1943, %f3421;
	shfl.sync.bfly.b32	%r1944, %r1943, 1, 31, -1;
	shfl.sync.bfly.b32	%r1945, %r1940, 2, 31, -1;
	mov.b32 	%f3422, %r1945;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f3423, %f3413, %f3422;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r1946, %f3423;
	shfl.sync.bfly.b32	%r1947, %r1946, 1, 31, -1;
	shfl.sync.bfly.b32	%r1948, %r1941, 2, 31, -1;
	mov.b32 	%f3424, %r1948;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f3425, %f3417, %f3424;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r1949, %f3425;
	shfl.sync.bfly.b32	%r1950, %r1949, 1, 31, -1;
	shfl.sync.bfly.b32	%r1951, %r1942, 2, 31, -1;
	mov.b32 	%f3426, %r1951;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f3427, %f3419, %f3426;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r1952, %f3427;
	shfl.sync.bfly.b32	%r1953, %r1952, 1, 31, -1;
	mov.b32 	%f3428, %r1953;
	mov.b32 	%f3429, %r1950;
	mov.b32 	%f3430, %r1947;
	mov.b32 	%f3431, %r1944;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f3432, %f3421, %f3431;
	max.f32 	%f3433, %f3423, %f3430;
	max.f32 	%f3434, %f3425, %f3429;
	max.f32 	%f3435, %f3427, %f3428;
$L__tmp6:
	.loc	1 190 31                        // prefix_prefill.py:190:31
	max.f32 	%f568, %f276, %f3435;
	max.f32 	%f567, %f275, %f3434;
	max.f32 	%f566, %f274, %f3433;
	max.f32 	%f565, %f273, %f3432;
	.loc	1 191 24                        // prefix_prefill.py:191:24
	neg.f32 	%f3436, %f565;
	fma.rn.f32 	%f3437, %f2401, %f3376, %f3436;
	fma.rn.f32 	%f3438, %f2401, %f3377, %f3436;
	neg.f32 	%f3439, %f566;
	fma.rn.f32 	%f3440, %f2401, %f3378, %f3439;
	fma.rn.f32 	%f3441, %f2401, %f3379, %f3439;
	fma.rn.f32 	%f3442, %f2401, %f3380, %f3436;
	fma.rn.f32 	%f3443, %f2401, %f3381, %f3436;
	fma.rn.f32 	%f3444, %f2401, %f3382, %f3439;
	fma.rn.f32 	%f3445, %f2401, %f3383, %f3439;
	neg.f32 	%f3446, %f567;
	fma.rn.f32 	%f3447, %f2401, %f3384, %f3446;
	fma.rn.f32 	%f3448, %f2401, %f3385, %f3446;
	neg.f32 	%f3449, %f568;
	fma.rn.f32 	%f3450, %f2401, %f3386, %f3449;
	fma.rn.f32 	%f3451, %f2401, %f3387, %f3449;
	fma.rn.f32 	%f3452, %f2401, %f3388, %f3446;
	fma.rn.f32 	%f3453, %f2401, %f3389, %f3446;
	fma.rn.f32 	%f3454, %f2401, %f3390, %f3449;
	fma.rn.f32 	%f3455, %f2401, %f3391, %f3449;
	.loc	1 191 19                        // prefix_prefill.py:191:19
	mul.f32 	%f3337, %f3437, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f3336, %f3337;
	// end inline asm
	mul.f32 	%f3339, %f3438, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f3338, %f3339;
	// end inline asm
	mul.f32 	%f3341, %f3440, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f3340, %f3341;
	// end inline asm
	mul.f32 	%f3343, %f3441, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f3342, %f3343;
	// end inline asm
	mul.f32 	%f3345, %f3442, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f3344, %f3345;
	// end inline asm
	mul.f32 	%f3347, %f3443, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f3346, %f3347;
	// end inline asm
	mul.f32 	%f3349, %f3444, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f3348, %f3349;
	// end inline asm
	mul.f32 	%f3351, %f3445, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f3350, %f3351;
	// end inline asm
	mul.f32 	%f3353, %f3447, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f3352, %f3353;
	// end inline asm
	mul.f32 	%f3355, %f3448, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f3354, %f3355;
	// end inline asm
	mul.f32 	%f3357, %f3450, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f3356, %f3357;
	// end inline asm
	mul.f32 	%f3359, %f3451, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f3358, %f3359;
	// end inline asm
	mul.f32 	%f3361, %f3452, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f3360, %f3361;
	// end inline asm
	mul.f32 	%f3363, %f3453, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f3362, %f3363;
	// end inline asm
	mul.f32 	%f3365, %f3454, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f3364, %f3365;
	// end inline asm
	mul.f32 	%f3367, %f3455, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f3366, %f3367;
	// end inline asm
$L__tmp7:
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f3456, %f3336, %f3338;
	add.f32 	%f3457, %f3340, %f3342;
	add.f32 	%f3458, %f3456, %f3344;
	add.f32 	%f3459, %f3458, %f3346;
	add.f32 	%f3460, %f3457, %f3348;
	add.f32 	%f3461, %f3460, %f3350;
	add.f32 	%f3462, %f3352, %f3354;
	add.f32 	%f3463, %f3356, %f3358;
	add.f32 	%f3464, %f3462, %f3360;
	add.f32 	%f3465, %f3464, %f3362;
	add.f32 	%f3466, %f3463, %f3364;
	add.f32 	%f3467, %f3466, %f3366;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r1954, %f3459;
	shfl.sync.bfly.b32	%r1955, %r1954, 2, 31, -1;
	mov.b32 	%f3468, %r1955;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f3469, %f3459, %f3468;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r1956, %f3469;
	shfl.sync.bfly.b32	%r1957, %r1956, 1, 31, -1;
	mov.b32 	%r1958, %f3461;
	shfl.sync.bfly.b32	%r1959, %r1958, 2, 31, -1;
	mov.b32 	%f3470, %r1959;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f3471, %f3461, %f3470;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r1960, %f3471;
	shfl.sync.bfly.b32	%r1961, %r1960, 1, 31, -1;
	mov.b32 	%r1962, %f3465;
	shfl.sync.bfly.b32	%r1963, %r1962, 2, 31, -1;
	mov.b32 	%f3472, %r1963;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f3473, %f3465, %f3472;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r1964, %f3473;
	shfl.sync.bfly.b32	%r1965, %r1964, 1, 31, -1;
	mov.b32 	%r1966, %f3467;
	shfl.sync.bfly.b32	%r1967, %r1966, 2, 31, -1;
	mov.b32 	%f3474, %r1967;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f3475, %f3467, %f3474;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r1968, %f3475;
	shfl.sync.bfly.b32	%r1969, %r1968, 1, 31, -1;
$L__tmp8:
	.loc	1 193 29                        // prefix_prefill.py:193:29
	sub.f32 	%f3480, %f273, %f565;
	sub.f32 	%f3481, %f274, %f566;
	sub.f32 	%f3482, %f275, %f567;
	sub.f32 	%f3483, %f276, %f568;
	.loc	1 193 23                        // prefix_prefill.py:193:23
	mul.f32 	%f3369, %f3480, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f3368, %f3369;
	// end inline asm
	mul.f32 	%f3371, %f3481, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f3370, %f3371;
	// end inline asm
	mul.f32 	%f3373, %f3482, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f3372, %f3373;
	// end inline asm
	mul.f32 	%f3375, %f3483, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f3374, %f3375;
	// end inline asm
	.loc	1 194 20                        // prefix_prefill.py:194:20
	mul.f32 	%f3484, %f2824, %f3368;
	mul.f32 	%f3485, %f2825, %f3368;
	mul.f32 	%f3486, %f2826, %f3370;
	mul.f32 	%f3487, %f2827, %f3370;
	mul.f32 	%f3492, %f2832, %f3368;
	mul.f32 	%f3493, %f2833, %f3368;
	mul.f32 	%f3494, %f2834, %f3370;
	mul.f32 	%f3495, %f2835, %f3370;
	mul.f32 	%f3500, %f2840, %f3368;
	mul.f32 	%f3501, %f2841, %f3368;
	mul.f32 	%f3502, %f2842, %f3370;
	mul.f32 	%f3503, %f2843, %f3370;
	mul.f32 	%f3508, %f2848, %f3368;
	mul.f32 	%f3509, %f2849, %f3368;
	mul.f32 	%f3510, %f2850, %f3370;
	mul.f32 	%f3511, %f2851, %f3370;
	mul.f32 	%f3516, %f2856, %f3368;
	mul.f32 	%f3517, %f2857, %f3368;
	mul.f32 	%f3518, %f2858, %f3370;
	mul.f32 	%f3519, %f2859, %f3370;
	mul.f32 	%f3524, %f2864, %f3368;
	mul.f32 	%f3525, %f2865, %f3368;
	mul.f32 	%f3526, %f2866, %f3370;
	mul.f32 	%f3527, %f2867, %f3370;
	mul.f32 	%f3532, %f2872, %f3368;
	mul.f32 	%f3533, %f2873, %f3368;
	mul.f32 	%f3534, %f2874, %f3370;
	mul.f32 	%f3535, %f2875, %f3370;
	mul.f32 	%f3540, %f2880, %f3368;
	mul.f32 	%f3541, %f2881, %f3368;
	mul.f32 	%f3542, %f2882, %f3370;
	mul.f32 	%f3543, %f2883, %f3370;
	mul.f32 	%f3548, %f2888, %f3368;
	mul.f32 	%f3549, %f2889, %f3368;
	mul.f32 	%f3550, %f2890, %f3370;
	mul.f32 	%f3551, %f2891, %f3370;
	mul.f32 	%f3556, %f2896, %f3368;
	mul.f32 	%f3557, %f2897, %f3368;
	mul.f32 	%f3558, %f2898, %f3370;
	mul.f32 	%f3559, %f2899, %f3370;
	mul.f32 	%f3564, %f2904, %f3368;
	mul.f32 	%f3565, %f2905, %f3368;
	mul.f32 	%f3566, %f2906, %f3370;
	mul.f32 	%f3567, %f2907, %f3370;
	mul.f32 	%f3572, %f2912, %f3368;
	mul.f32 	%f3573, %f2913, %f3368;
	mul.f32 	%f3574, %f2914, %f3370;
	mul.f32 	%f3575, %f2915, %f3370;
	mul.f32 	%f3580, %f2920, %f3368;
	mul.f32 	%f3581, %f2921, %f3368;
	mul.f32 	%f3582, %f2922, %f3370;
	mul.f32 	%f3583, %f2923, %f3370;
	mul.f32 	%f3588, %f2928, %f3368;
	mul.f32 	%f3589, %f2929, %f3368;
	mul.f32 	%f3590, %f2930, %f3370;
	mul.f32 	%f3591, %f2931, %f3370;
	mul.f32 	%f3596, %f2936, %f3368;
	mul.f32 	%f3597, %f2937, %f3368;
	mul.f32 	%f3598, %f2938, %f3370;
	mul.f32 	%f3599, %f2939, %f3370;
	mul.f32 	%f3604, %f2944, %f3368;
	mul.f32 	%f3605, %f2945, %f3368;
	mul.f32 	%f3606, %f2946, %f3370;
	mul.f32 	%f3607, %f2947, %f3370;
	mul.f32 	%f3612, %f2952, %f3372;
	mul.f32 	%f3613, %f2953, %f3372;
	mul.f32 	%f3614, %f2954, %f3374;
	mul.f32 	%f3615, %f2955, %f3374;
	mul.f32 	%f3620, %f2960, %f3372;
	mul.f32 	%f3621, %f2961, %f3372;
	mul.f32 	%f3622, %f2962, %f3374;
	mul.f32 	%f3623, %f2963, %f3374;
	mul.f32 	%f3628, %f2968, %f3372;
	mul.f32 	%f3629, %f2969, %f3372;
	mul.f32 	%f3630, %f2970, %f3374;
	mul.f32 	%f3631, %f2971, %f3374;
	mul.f32 	%f3636, %f2976, %f3372;
	mul.f32 	%f3637, %f2977, %f3372;
	mul.f32 	%f3638, %f2978, %f3374;
	mul.f32 	%f3639, %f2979, %f3374;
	mul.f32 	%f3644, %f2984, %f3372;
	mul.f32 	%f3645, %f2985, %f3372;
	mul.f32 	%f3646, %f2986, %f3374;
	mul.f32 	%f3647, %f2987, %f3374;
	mul.f32 	%f3652, %f2992, %f3372;
	mul.f32 	%f3653, %f2993, %f3372;
	mul.f32 	%f3654, %f2994, %f3374;
	mul.f32 	%f3655, %f2995, %f3374;
	mul.f32 	%f3660, %f3000, %f3372;
	mul.f32 	%f3661, %f3001, %f3372;
	mul.f32 	%f3662, %f3002, %f3374;
	mul.f32 	%f3663, %f3003, %f3374;
	mul.f32 	%f3668, %f3008, %f3372;
	mul.f32 	%f3669, %f3009, %f3372;
	mul.f32 	%f3670, %f3010, %f3374;
	mul.f32 	%f3671, %f3011, %f3374;
	mul.f32 	%f3676, %f3016, %f3372;
	mul.f32 	%f3677, %f3017, %f3372;
	mul.f32 	%f3678, %f3018, %f3374;
	mul.f32 	%f3679, %f3019, %f3374;
	mul.f32 	%f3684, %f3024, %f3372;
	mul.f32 	%f3685, %f3025, %f3372;
	mul.f32 	%f3686, %f3026, %f3374;
	mul.f32 	%f3687, %f3027, %f3374;
	mul.f32 	%f3692, %f3032, %f3372;
	mul.f32 	%f3693, %f3033, %f3372;
	mul.f32 	%f3694, %f3034, %f3374;
	mul.f32 	%f3695, %f3035, %f3374;
	mul.f32 	%f3700, %f3040, %f3372;
	mul.f32 	%f3701, %f3041, %f3372;
	mul.f32 	%f3702, %f3042, %f3374;
	mul.f32 	%f3703, %f3043, %f3374;
	mul.f32 	%f3708, %f3048, %f3372;
	mul.f32 	%f3709, %f3049, %f3372;
	mul.f32 	%f3710, %f3050, %f3374;
	mul.f32 	%f3711, %f3051, %f3374;
	mul.f32 	%f3716, %f3056, %f3372;
	mul.f32 	%f3717, %f3057, %f3372;
	mul.f32 	%f3718, %f3058, %f3374;
	mul.f32 	%f3719, %f3059, %f3374;
	mul.f32 	%f3724, %f3064, %f3372;
	mul.f32 	%f3725, %f3065, %f3372;
	mul.f32 	%f3726, %f3066, %f3374;
	mul.f32 	%f3727, %f3067, %f3374;
	mul.f32 	%f3732, %f3072, %f3372;
	mul.f32 	%f3733, %f3073, %f3372;
	mul.f32 	%f3734, %f3074, %f3374;
	mul.f32 	%f3735, %f3075, %f3374;
	mul.wide.s32 	%rd542, %r295, 2;
	mul.wide.s32 	%rd543, %r303, 2;
	.loc	1 197 11                        // prefix_prefill.py:197:11
	@%p139 bra 	$L__BB0_17;
// %bb.16:                              //   in Loop: Header=BB0_2 Depth=1
	.loc	1 0 0                           // prefix_prefill.py:0:0
	add.s32 	%r296, %r1673, %r70;
	add.s32 	%r297, %r1673, %r71;
	add.s32 	%r298, %r1673, %r72;
	add.s32 	%r299, %r1673, %r73;
	add.s32 	%r300, %r1673, %r74;
	add.s32 	%r301, %r1673, %r75;
	add.s32 	%r302, %r1673, %r76;
	add.s32 	%r304, %r1674, %r70;
	add.s32 	%r305, %r1674, %r71;
	add.s32 	%r306, %r1674, %r72;
	add.s32 	%r307, %r1674, %r73;
	add.s32 	%r308, %r1674, %r74;
	add.s32 	%r309, %r1674, %r75;
	add.s32 	%r310, %r1674, %r76;
	.loc	1 202 28                        // prefix_prefill.py:202:28
	add.s32 	%r1979, %r7324, 16;
	add.s32 	%r1980, %r7324, 17;
	add.s32 	%r1981, %r7324, 18;
	add.s32 	%r1982, %r7324, 19;
	add.s32 	%r1983, %r7324, 20;
	add.s32 	%r1984, %r7324, 21;
	add.s32 	%r1985, %r7324, 22;
	.loc	1 202 50                        // prefix_prefill.py:202:50
	add.s32 	%r1986, %r7324, 23;
	setp.lt.s32 	%p159, %r1979, %r5;
	setp.lt.s32 	%p161, %r1980, %r5;
	setp.lt.s32 	%p163, %r1981, %r5;
	setp.lt.s32 	%p165, %r1982, %r5;
	setp.lt.s32 	%p167, %r1983, %r5;
	setp.lt.s32 	%p169, %r1984, %r5;
	setp.lt.s32 	%p171, %r1985, %r5;
	setp.lt.s32 	%p173, %r1986, %r5;
	.loc	1 200 26                        // prefix_prefill.py:200:26
	add.s64 	%rd212, %rd111, %rd542;
	mul.wide.s32 	%rd229, %r296, 2;
	add.s64 	%rd213, %rd111, %rd229;
	mul.wide.s32 	%rd230, %r297, 2;
	add.s64 	%rd214, %rd111, %rd230;
	mul.wide.s32 	%rd231, %r298, 2;
	add.s64 	%rd215, %rd111, %rd231;
	mul.wide.s32 	%rd232, %r299, 2;
	add.s64 	%rd216, %rd111, %rd232;
	mul.wide.s32 	%rd233, %r300, 2;
	add.s64 	%rd217, %rd111, %rd233;
	mul.wide.s32 	%rd234, %r301, 2;
	add.s64 	%rd218, %rd111, %rd234;
	mul.wide.s32 	%rd235, %r302, 2;
	add.s64 	%rd219, %rd111, %rd235;
	add.s64 	%rd220, %rd111, %rd543;
	mul.wide.s32 	%rd237, %r304, 2;
	add.s64 	%rd221, %rd111, %rd237;
	mul.wide.s32 	%rd238, %r305, 2;
	add.s64 	%rd222, %rd111, %rd238;
	mul.wide.s32 	%rd239, %r306, 2;
	add.s64 	%rd223, %rd111, %rd239;
	mul.wide.s32 	%rd240, %r307, 2;
	add.s64 	%rd224, %rd111, %rd240;
	mul.wide.s32 	%rd241, %r308, 2;
	add.s64 	%rd225, %rd111, %rd241;
	mul.wide.s32 	%rd242, %r309, 2;
	add.s64 	%rd226, %rd111, %rd242;
	mul.wide.s32 	%rd243, %r310, 2;
	add.s64 	%rd227, %rd111, %rd243;
	.loc	1 200 16                        // prefix_prefill.py:200:16
	// begin inline asm
	mov.u16 %rs65, 0x0;
	@%p159 ld.global.b16 { %rs65 }, [ %rd212 + 0 ];
	@!%p159 mov.u16 %rs65, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs67, 0x0;
	@%p161 ld.global.b16 { %rs67 }, [ %rd213 + 0 ];
	@!%p161 mov.u16 %rs67, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs69, 0x0;
	@%p163 ld.global.b16 { %rs69 }, [ %rd214 + 0 ];
	@!%p163 mov.u16 %rs69, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs71, 0x0;
	@%p165 ld.global.b16 { %rs71 }, [ %rd215 + 0 ];
	@!%p165 mov.u16 %rs71, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs73, 0x0;
	@%p167 ld.global.b16 { %rs73 }, [ %rd216 + 0 ];
	@!%p167 mov.u16 %rs73, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs75, 0x0;
	@%p169 ld.global.b16 { %rs75 }, [ %rd217 + 0 ];
	@!%p169 mov.u16 %rs75, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs77, 0x0;
	@%p171 ld.global.b16 { %rs77 }, [ %rd218 + 0 ];
	@!%p171 mov.u16 %rs77, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs79, 0x0;
	@%p173 ld.global.b16 { %rs79 }, [ %rd219 + 0 ];
	@!%p173 mov.u16 %rs79, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs81, 0x0;
	@%p159 ld.global.b16 { %rs81 }, [ %rd220 + 0 ];
	@!%p159 mov.u16 %rs81, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs83, 0x0;
	@%p161 ld.global.b16 { %rs83 }, [ %rd221 + 0 ];
	@!%p161 mov.u16 %rs83, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs85, 0x0;
	@%p163 ld.global.b16 { %rs85 }, [ %rd222 + 0 ];
	@!%p163 mov.u16 %rs85, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs87, 0x0;
	@%p165 ld.global.b16 { %rs87 }, [ %rd223 + 0 ];
	@!%p165 mov.u16 %rs87, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs89, 0x0;
	@%p167 ld.global.b16 { %rs89 }, [ %rd224 + 0 ];
	@!%p167 mov.u16 %rs89, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs91, 0x0;
	@%p169 ld.global.b16 { %rs91 }, [ %rd225 + 0 ];
	@!%p169 mov.u16 %rs91, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs93, 0x0;
	@%p171 ld.global.b16 { %rs93 }, [ %rd226 + 0 ];
	@!%p171 mov.u16 %rs93, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs95, 0x0;
	@%p173 ld.global.b16 { %rs95 }, [ %rd227 + 0 ];
	@!%p173 mov.u16 %rs95, %rs258;
	// end inline asm
	mov.b32 	%r7351, {%rs65, %rs67};
	mov.b32 	%r7352, {%rs69, %rs71};
	mov.b32 	%r7353, {%rs73, %rs75};
	mov.b32 	%r7354, {%rs77, %rs79};
	mov.b32 	%r7355, {%rs81, %rs83};
	mov.b32 	%r7356, {%rs85, %rs87};
	mov.b32 	%r7357, {%rs89, %rs91};
	mov.b32 	%r7358, {%rs93, %rs95};
	.loc	1 197 11                        // prefix_prefill.py:197:11
	bra.uni 	$L__BB0_18;
$L__BB0_17:                             //   in Loop: Header=BB0_2 Depth=1
	.loc	1 205 39                        // prefix_prefill.py:205:39
	add.s64 	%rd208, %rd111, %rd542;
	add.s64 	%rd209, %rd111, %rd543;
	.loc	1 205 29                        // prefix_prefill.py:205:29
	// begin inline asm
	mov.u32 %r7351, 0x0;
	mov.u32 %r7352, 0x0;
	mov.u32 %r7353, 0x0;
	mov.u32 %r7354, 0x0;
	@%p546 ld.global.v4.b32 { %r7351, %r7352, %r7353, %r7354 }, [ %rd208 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r7355, 0x0;
	mov.u32 %r7356, 0x0;
	mov.u32 %r7357, 0x0;
	mov.u32 %r7358, 0x0;
	@%p546 ld.global.v4.b32 { %r7355, %r7356, %r7357, %r7358 }, [ %rd209 + 0 ];
	// end inline asm
$L__BB0_18:                             //   in Loop: Header=BB0_2 Depth=1
	.loc	1 0 0                           // prefix_prefill.py:0:0
	add.f32 	%f297, %f2809, %f2819;
	add.f32 	%f298, %f2811, %f2818;
	add.f32 	%f299, %f2813, %f2817;
	add.f32 	%f300, %f2815, %f2816;
	mov.b32 	%f3476, %r1969;
	mov.b32 	%f3477, %r1965;
	mov.b32 	%f3478, %r1961;
	mov.b32 	%f3479, %r1957;
	.loc	1 197 11                        // prefix_prefill.py:197:11
	bar.sync 	0;
	st.shared.v4.b32 	[%r105], {%r7351, %r7352, %r7353, %r7354};
	st.shared.v4.b32 	[%r106], {%r7355, %r7356, %r7357, %r7358};
	.loc	1 211 17                        // prefix_prefill.py:211:17
	mov.b32 	%r1995, %f3336;
	// begin inline asm
	cvt.rn.bf16.f32 %rs97, %r1995;
	// end inline asm
	mov.b32 	%r1996, %f3338;
	// begin inline asm
	cvt.rn.bf16.f32 %rs98, %r1996;
	// end inline asm
	mov.b32 	%r1997, %f3340;
	// begin inline asm
	cvt.rn.bf16.f32 %rs99, %r1997;
	// end inline asm
	mov.b32 	%r1998, %f3342;
	// begin inline asm
	cvt.rn.bf16.f32 %rs100, %r1998;
	// end inline asm
	mov.b32 	%r1999, %f3344;
	// begin inline asm
	cvt.rn.bf16.f32 %rs101, %r1999;
	// end inline asm
	mov.b32 	%r2000, %f3346;
	// begin inline asm
	cvt.rn.bf16.f32 %rs102, %r2000;
	// end inline asm
	mov.b32 	%r2001, %f3348;
	// begin inline asm
	cvt.rn.bf16.f32 %rs103, %r2001;
	// end inline asm
	mov.b32 	%r2002, %f3350;
	// begin inline asm
	cvt.rn.bf16.f32 %rs104, %r2002;
	// end inline asm
	mov.b32 	%r2003, %f3352;
	// begin inline asm
	cvt.rn.bf16.f32 %rs105, %r2003;
	// end inline asm
	mov.b32 	%r2004, %f3354;
	// begin inline asm
	cvt.rn.bf16.f32 %rs106, %r2004;
	// end inline asm
	mov.b32 	%r2005, %f3356;
	// begin inline asm
	cvt.rn.bf16.f32 %rs107, %r2005;
	// end inline asm
	mov.b32 	%r2006, %f3358;
	// begin inline asm
	cvt.rn.bf16.f32 %rs108, %r2006;
	// end inline asm
	mov.b32 	%r2007, %f3360;
	// begin inline asm
	cvt.rn.bf16.f32 %rs109, %r2007;
	// end inline asm
	mov.b32 	%r2008, %f3362;
	// begin inline asm
	cvt.rn.bf16.f32 %rs110, %r2008;
	// end inline asm
	mov.b32 	%r2009, %f3364;
	// begin inline asm
	cvt.rn.bf16.f32 %rs111, %r2009;
	// end inline asm
	mov.b32 	%r2010, %f3366;
	// begin inline asm
	cvt.rn.bf16.f32 %rs112, %r2010;
	// end inline asm
	mov.b32 	%r2051, {%rs97, %rs98};
	mov.b32 	%r2052, {%rs99, %rs100};
	mov.b32 	%r2053, {%rs101, %rs102};
	mov.b32 	%r2054, {%rs103, %rs104};
	mov.b32 	%r2147, {%rs105, %rs106};
	mov.b32 	%r2148, {%rs107, %rs108};
	mov.b32 	%r2149, {%rs109, %rs110};
	mov.b32 	%r2150, {%rs111, %rs112};
	.loc	1 197 11                        // prefix_prefill.py:197:11
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2055, %r2056, %r2061, %r2062 }, [ %r1434 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2067, %r2068, %r2073, %r2074 }, [ %r1439 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2079, %r2080, %r2085, %r2086 }, [ %r1444 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2091, %r2092, %r2097, %r2098 }, [ %r1449 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2103, %r2104, %r2109, %r2110 }, [ %r1454 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2115, %r2116, %r2121, %r2122 }, [ %r1459 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2127, %r2128, %r2133, %r2134 }, [ %r1464 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2139, %r2140, %r2145, %r2146 }, [ %r1469 + 0 ];
	// end inline asm
	.loc	1 213 24                        // prefix_prefill.py:213:24
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3484, %f3485, %f3486, %f3487 }, { %r2051, %r2052, %r2053, %r2054 }, { %r2055, %r2056 }, { %f3484, %f3485, %f3486, %f3487 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3492, %f3493, %f3494, %f3495 }, { %r2051, %r2052, %r2053, %r2054 }, { %r2061, %r2062 }, { %f3492, %f3493, %f3494, %f3495 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3500, %f3501, %f3502, %f3503 }, { %r2051, %r2052, %r2053, %r2054 }, { %r2067, %r2068 }, { %f3500, %f3501, %f3502, %f3503 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3508, %f3509, %f3510, %f3511 }, { %r2051, %r2052, %r2053, %r2054 }, { %r2073, %r2074 }, { %f3508, %f3509, %f3510, %f3511 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3516, %f3517, %f3518, %f3519 }, { %r2051, %r2052, %r2053, %r2054 }, { %r2079, %r2080 }, { %f3516, %f3517, %f3518, %f3519 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3524, %f3525, %f3526, %f3527 }, { %r2051, %r2052, %r2053, %r2054 }, { %r2085, %r2086 }, { %f3524, %f3525, %f3526, %f3527 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3532, %f3533, %f3534, %f3535 }, { %r2051, %r2052, %r2053, %r2054 }, { %r2091, %r2092 }, { %f3532, %f3533, %f3534, %f3535 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3540, %f3541, %f3542, %f3543 }, { %r2051, %r2052, %r2053, %r2054 }, { %r2097, %r2098 }, { %f3540, %f3541, %f3542, %f3543 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3548, %f3549, %f3550, %f3551 }, { %r2051, %r2052, %r2053, %r2054 }, { %r2103, %r2104 }, { %f3548, %f3549, %f3550, %f3551 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3556, %f3557, %f3558, %f3559 }, { %r2051, %r2052, %r2053, %r2054 }, { %r2109, %r2110 }, { %f3556, %f3557, %f3558, %f3559 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3564, %f3565, %f3566, %f3567 }, { %r2051, %r2052, %r2053, %r2054 }, { %r2115, %r2116 }, { %f3564, %f3565, %f3566, %f3567 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3572, %f3573, %f3574, %f3575 }, { %r2051, %r2052, %r2053, %r2054 }, { %r2121, %r2122 }, { %f3572, %f3573, %f3574, %f3575 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3580, %f3581, %f3582, %f3583 }, { %r2051, %r2052, %r2053, %r2054 }, { %r2127, %r2128 }, { %f3580, %f3581, %f3582, %f3583 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3588, %f3589, %f3590, %f3591 }, { %r2051, %r2052, %r2053, %r2054 }, { %r2133, %r2134 }, { %f3588, %f3589, %f3590, %f3591 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3596, %f3597, %f3598, %f3599 }, { %r2051, %r2052, %r2053, %r2054 }, { %r2139, %r2140 }, { %f3596, %f3597, %f3598, %f3599 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3604, %f3605, %f3606, %f3607 }, { %r2051, %r2052, %r2053, %r2054 }, { %r2145, %r2146 }, { %f3604, %f3605, %f3606, %f3607 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3612, %f3613, %f3614, %f3615 }, { %r2147, %r2148, %r2149, %r2150 }, { %r2055, %r2056 }, { %f3612, %f3613, %f3614, %f3615 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3620, %f3621, %f3622, %f3623 }, { %r2147, %r2148, %r2149, %r2150 }, { %r2061, %r2062 }, { %f3620, %f3621, %f3622, %f3623 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3628, %f3629, %f3630, %f3631 }, { %r2147, %r2148, %r2149, %r2150 }, { %r2067, %r2068 }, { %f3628, %f3629, %f3630, %f3631 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3636, %f3637, %f3638, %f3639 }, { %r2147, %r2148, %r2149, %r2150 }, { %r2073, %r2074 }, { %f3636, %f3637, %f3638, %f3639 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3644, %f3645, %f3646, %f3647 }, { %r2147, %r2148, %r2149, %r2150 }, { %r2079, %r2080 }, { %f3644, %f3645, %f3646, %f3647 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3652, %f3653, %f3654, %f3655 }, { %r2147, %r2148, %r2149, %r2150 }, { %r2085, %r2086 }, { %f3652, %f3653, %f3654, %f3655 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3660, %f3661, %f3662, %f3663 }, { %r2147, %r2148, %r2149, %r2150 }, { %r2091, %r2092 }, { %f3660, %f3661, %f3662, %f3663 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3668, %f3669, %f3670, %f3671 }, { %r2147, %r2148, %r2149, %r2150 }, { %r2097, %r2098 }, { %f3668, %f3669, %f3670, %f3671 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3676, %f3677, %f3678, %f3679 }, { %r2147, %r2148, %r2149, %r2150 }, { %r2103, %r2104 }, { %f3676, %f3677, %f3678, %f3679 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3684, %f3685, %f3686, %f3687 }, { %r2147, %r2148, %r2149, %r2150 }, { %r2109, %r2110 }, { %f3684, %f3685, %f3686, %f3687 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3692, %f3693, %f3694, %f3695 }, { %r2147, %r2148, %r2149, %r2150 }, { %r2115, %r2116 }, { %f3692, %f3693, %f3694, %f3695 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3700, %f3701, %f3702, %f3703 }, { %r2147, %r2148, %r2149, %r2150 }, { %r2121, %r2122 }, { %f3700, %f3701, %f3702, %f3703 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3708, %f3709, %f3710, %f3711 }, { %r2147, %r2148, %r2149, %r2150 }, { %r2127, %r2128 }, { %f3708, %f3709, %f3710, %f3711 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3716, %f3717, %f3718, %f3719 }, { %r2147, %r2148, %r2149, %r2150 }, { %r2133, %r2134 }, { %f3716, %f3717, %f3718, %f3719 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3724, %f3725, %f3726, %f3727 }, { %r2147, %r2148, %r2149, %r2150 }, { %r2139, %r2140 }, { %f3724, %f3725, %f3726, %f3727 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3732, %f3733, %f3734, %f3735 }, { %r2147, %r2148, %r2149, %r2150 }, { %r2145, %r2146 }, { %f3732, %f3733, %f3734, %f3735 };
	// end inline asm
	.loc	1 138 21                        // prefix_prefill.py:138:21
	add.s64 	%rd244, %rd550, 8;
	// begin inline asm
	mov.u32 %r2243, 0x0;
	@%p546 ld.global.b32 { %r2243 }, [ %rd244 + 0 ];
	// end inline asm
	.loc	1 142 26                        // prefix_prefill.py:142:26
	mul.lo.s32 	%r2252, %r2243, %r672;
	.loc	1 144 24                        // prefix_prefill.py:144:24
	add.s32 	%r360, %r154, 32;
	add.s32 	%r361, %r154, 33;
	add.s32 	%r362, %r154, 40;
	add.s32 	%r363, %r154, 41;
	add.s32 	%r364, %r2252, %r115;
	add.s32 	%r365, %r2252, %r116;
	.loc	1 148 31                        // prefix_prefill.py:148:31
	mul.lo.s32 	%r2253, %r2243, %r673;
	add.s32 	%r2254, %r2253, %r78;
	add.s32 	%r2255, %r2253, %r79;
	.loc	1 151 17                        // prefix_prefill.py:151:17
	add.s32 	%r366, %r2254, %r21;
	add.s32 	%r374, %r2255, %r21;
	.loc	1 153 34                        // prefix_prefill.py:153:34
	add.s32 	%r382, %r7326, 48;
	setp.le.s32 	%p192, %r382, %r5;
	mul.wide.s32 	%rd540, %r364, 2;
	mul.wide.s32 	%rd541, %r365, 2;
	.loc	1 153 11                        // prefix_prefill.py:153:11
	@%p192 bra 	$L__BB0_20;
// %bb.19:                              //   in Loop: Header=BB0_2 Depth=1
	.loc	1 144 24                        // prefix_prefill.py:144:24
	add.s32 	%r2281, %r7325, 40;
	.loc	1 158 50                        // prefix_prefill.py:158:50
	add.s32 	%r2282, %r7325, 32;
	setp.lt.s32 	%p195, %r2282, %r5;
	setp.lt.s32 	%p200, %r2281, %r5;
	.loc	1 156 26                        // prefix_prefill.py:156:26
	add.s64 	%rd249, %rd110, %rd540;
	add.s64 	%rd250, %rd110, %rd541;
	mov.b32 	%r2268, 0;
	.loc	1 156 16                        // prefix_prefill.py:156:16
	// begin inline asm
	mov.u32 %r7365, 0x0;
	mov.u32 %r7366, 0x0;
	mov.u32 %r7363, 0x0;
	mov.u32 %r7364, 0x0;
	@%p195 ld.global.v4.b32 { %r7365, %r7366, %r7363, %r7364 }, [ %rd249 + 0 ];
	@!%p195 mov.u32 %r7365, %r2268;
	@!%p195 mov.u32 %r7366, %r2268;
	@!%p195 mov.u32 %r7363, %r2268;
	@!%p195 mov.u32 %r7364, %r2268;
	// end inline asm
	// begin inline asm
	mov.u32 %r7359, 0x0;
	mov.u32 %r7360, 0x0;
	mov.u32 %r7361, 0x0;
	mov.u32 %r7362, 0x0;
	@%p200 ld.global.v4.b32 { %r7359, %r7360, %r7361, %r7362 }, [ %rd250 + 0 ];
	@!%p200 mov.u32 %r7359, %r2268;
	@!%p200 mov.u32 %r7360, %r2268;
	@!%p200 mov.u32 %r7361, %r2268;
	@!%p200 mov.u32 %r7362, %r2268;
	// end inline asm
	.loc	1 153 11                        // prefix_prefill.py:153:11
	bra.uni 	$L__BB0_21;
$L__BB0_20:                             //   in Loop: Header=BB0_2 Depth=1
	.loc	1 161 39                        // prefix_prefill.py:161:39
	add.s64 	%rd245, %rd110, %rd540;
	add.s64 	%rd246, %rd110, %rd541;
	.loc	1 161 29                        // prefix_prefill.py:161:29
	// begin inline asm
	mov.u32 %r7365, 0x0;
	mov.u32 %r7366, 0x0;
	mov.u32 %r7363, 0x0;
	mov.u32 %r7364, 0x0;
	@%p546 ld.global.v4.b32 { %r7365, %r7366, %r7363, %r7364 }, [ %rd245 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r7359, 0x0;
	mov.u32 %r7360, 0x0;
	mov.u32 %r7361, 0x0;
	mov.u32 %r7362, 0x0;
	@%p546 ld.global.v4.b32 { %r7359, %r7360, %r7361, %r7362 }, [ %rd246 + 0 ];
	// end inline asm
$L__BB0_21:                             //   in Loop: Header=BB0_2 Depth=1
	.loc	1 0 0                           // prefix_prefill.py:0:0
	fma.rn.f32 	%f561, %f8788, %f2708, %f297;
	fma.rn.f32 	%f562, %f8789, %f2710, %f298;
	fma.rn.f32 	%f563, %f8790, %f2712, %f299;
	fma.rn.f32 	%f564, %f8791, %f2714, %f300;
	add.f32 	%f589, %f3469, %f3479;
	add.f32 	%f590, %f3471, %f3478;
	add.f32 	%f591, %f3473, %f3477;
	add.f32 	%f592, %f3475, %f3476;
	.loc	1 153 11                        // prefix_prefill.py:153:11
	bar.sync 	0;
	st.shared.v4.b32 	[%r80], {%r7365, %r7366, %r7363, %r7364};
	st.shared.v4.b32 	[%r80+2048], {%r7359, %r7360, %r7361, %r7362};
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2327, %r2328, %r2333, %r2334 }, [ %r1126 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2351, %r2352, %r2357, %r2358 }, [ %r1131 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2375, %r2376, %r2381, %r2382 }, [ %r1136 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2399, %r2400, %r2405, %r2406 }, [ %r1141 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2423, %r2424, %r2429, %r2430 }, [ %r1146 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2447, %r2448, %r2453, %r2454 }, [ %r1151 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2471, %r2472, %r2477, %r2478 }, [ %r1156 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2495, %r2496, %r2501, %r2502 }, [ %r1161 + 0 ];
	// end inline asm
	.loc	1 169 23                        // prefix_prefill.py:169:23
	mov.f32 	%f3772, %f4456;
	mov.f32 	%f3773, %f4456;
	mov.f32 	%f3774, %f4456;
	mov.f32 	%f3775, %f4456;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3772, %f3773, %f3774, %f3775 }, { %r2904, %r2905, %r2906, %r2907 }, { %r2327, %r2328 }, { %f3772, %f3773, %f3774, %f3775 };
	// end inline asm
	mov.f32 	%f3780, %f4456;
	mov.f32 	%f3781, %f4456;
	mov.f32 	%f3782, %f4456;
	mov.f32 	%f3783, %f4456;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3780, %f3781, %f3782, %f3783 }, { %r2904, %r2905, %r2906, %r2907 }, { %r2333, %r2334 }, { %f3780, %f3781, %f3782, %f3783 };
	// end inline asm
	mov.f32 	%f3788, %f4456;
	mov.f32 	%f3789, %f4456;
	mov.f32 	%f3790, %f4456;
	mov.f32 	%f3791, %f4456;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3788, %f3789, %f3790, %f3791 }, { %r2916, %r2917, %r2918, %r2919 }, { %r2327, %r2328 }, { %f3788, %f3789, %f3790, %f3791 };
	// end inline asm
	mov.f32 	%f3799, %f4456;
	mov.f32 	%f3796, %f4456;
	mov.f32 	%f3797, %f4456;
	mov.f32 	%f3798, %f4456;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3796, %f3797, %f3798, %f3799 }, { %r2916, %r2917, %r2918, %r2919 }, { %r2333, %r2334 }, { %f3796, %f3797, %f3798, %f3799 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3772, %f3773, %f3774, %f3775 }, { %r2928, %r2929, %r2930, %r2931 }, { %r2351, %r2352 }, { %f3772, %f3773, %f3774, %f3775 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3780, %f3781, %f3782, %f3783 }, { %r2928, %r2929, %r2930, %r2931 }, { %r2357, %r2358 }, { %f3780, %f3781, %f3782, %f3783 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3788, %f3789, %f3790, %f3791 }, { %r2940, %r2941, %r2942, %r2943 }, { %r2351, %r2352 }, { %f3788, %f3789, %f3790, %f3791 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3796, %f3797, %f3798, %f3799 }, { %r2940, %r2941, %r2942, %r2943 }, { %r2357, %r2358 }, { %f3796, %f3797, %f3798, %f3799 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3772, %f3773, %f3774, %f3775 }, { %r2952, %r2953, %r2954, %r2955 }, { %r2375, %r2376 }, { %f3772, %f3773, %f3774, %f3775 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3780, %f3781, %f3782, %f3783 }, { %r2952, %r2953, %r2954, %r2955 }, { %r2381, %r2382 }, { %f3780, %f3781, %f3782, %f3783 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3788, %f3789, %f3790, %f3791 }, { %r2964, %r2965, %r2966, %r2967 }, { %r2375, %r2376 }, { %f3788, %f3789, %f3790, %f3791 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3796, %f3797, %f3798, %f3799 }, { %r2964, %r2965, %r2966, %r2967 }, { %r2381, %r2382 }, { %f3796, %f3797, %f3798, %f3799 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3772, %f3773, %f3774, %f3775 }, { %r2976, %r2977, %r2978, %r2979 }, { %r2399, %r2400 }, { %f3772, %f3773, %f3774, %f3775 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3780, %f3781, %f3782, %f3783 }, { %r2976, %r2977, %r2978, %r2979 }, { %r2405, %r2406 }, { %f3780, %f3781, %f3782, %f3783 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3788, %f3789, %f3790, %f3791 }, { %r2988, %r2989, %r2990, %r2991 }, { %r2399, %r2400 }, { %f3788, %f3789, %f3790, %f3791 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3796, %f3797, %f3798, %f3799 }, { %r2988, %r2989, %r2990, %r2991 }, { %r2405, %r2406 }, { %f3796, %f3797, %f3798, %f3799 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3772, %f3773, %f3774, %f3775 }, { %r3000, %r3001, %r3002, %r3003 }, { %r2423, %r2424 }, { %f3772, %f3773, %f3774, %f3775 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3780, %f3781, %f3782, %f3783 }, { %r3000, %r3001, %r3002, %r3003 }, { %r2429, %r2430 }, { %f3780, %f3781, %f3782, %f3783 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3788, %f3789, %f3790, %f3791 }, { %r3012, %r3013, %r3014, %r3015 }, { %r2423, %r2424 }, { %f3788, %f3789, %f3790, %f3791 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3796, %f3797, %f3798, %f3799 }, { %r3012, %r3013, %r3014, %r3015 }, { %r2429, %r2430 }, { %f3796, %f3797, %f3798, %f3799 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3772, %f3773, %f3774, %f3775 }, { %r3024, %r3025, %r3026, %r3027 }, { %r2447, %r2448 }, { %f3772, %f3773, %f3774, %f3775 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3780, %f3781, %f3782, %f3783 }, { %r3024, %r3025, %r3026, %r3027 }, { %r2453, %r2454 }, { %f3780, %f3781, %f3782, %f3783 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3788, %f3789, %f3790, %f3791 }, { %r3036, %r3037, %r3038, %r3039 }, { %r2447, %r2448 }, { %f3788, %f3789, %f3790, %f3791 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3796, %f3797, %f3798, %f3799 }, { %r3036, %r3037, %r3038, %r3039 }, { %r2453, %r2454 }, { %f3796, %f3797, %f3798, %f3799 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3772, %f3773, %f3774, %f3775 }, { %r3048, %r3049, %r3050, %r3051 }, { %r2471, %r2472 }, { %f3772, %f3773, %f3774, %f3775 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3780, %f3781, %f3782, %f3783 }, { %r3048, %r3049, %r3050, %r3051 }, { %r2477, %r2478 }, { %f3780, %f3781, %f3782, %f3783 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3788, %f3789, %f3790, %f3791 }, { %r3060, %r3061, %r3062, %r3063 }, { %r2471, %r2472 }, { %f3788, %f3789, %f3790, %f3791 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3796, %f3797, %f3798, %f3799 }, { %r3060, %r3061, %r3062, %r3063 }, { %r2477, %r2478 }, { %f3796, %f3797, %f3798, %f3799 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3772, %f3773, %f3774, %f3775 }, { %r3072, %r3073, %r3074, %r3075 }, { %r2495, %r2496 }, { %f3772, %f3773, %f3774, %f3775 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3780, %f3781, %f3782, %f3783 }, { %r3072, %r3073, %r3074, %r3075 }, { %r2501, %r2502 }, { %f3780, %f3781, %f3782, %f3783 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3788, %f3789, %f3790, %f3791 }, { %r3084, %r3085, %r3086, %r3087 }, { %r2495, %r2496 }, { %f3788, %f3789, %f3790, %f3791 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f3796, %f3797, %f3798, %f3799 }, { %r3084, %r3085, %r3086, %r3087 }, { %r2501, %r2502 }, { %f3796, %f3797, %f3798, %f3799 };
	// end inline asm
	.loc	1 170 55                        // prefix_prefill.py:170:55
	setp.lt.s32 	%p206, %r360, %r5;
	setp.lt.s32 	%p207, %r361, %r5;
	setp.lt.s32 	%p208, %r362, %r5;
	setp.lt.s32 	%p209, %r363, %r5;
	.loc	1 171 22                        // prefix_prefill.py:171:22
	selp.f32 	%f4036, %f3772, 0fFF800000, %p206;
	selp.f32 	%f4037, %f3773, 0fFF800000, %p207;
	selp.f32 	%f4038, %f3774, 0fFF800000, %p206;
	selp.f32 	%f4039, %f3775, 0fFF800000, %p207;
	selp.f32 	%f4040, %f3780, 0fFF800000, %p208;
	selp.f32 	%f4041, %f3781, 0fFF800000, %p209;
	selp.f32 	%f4042, %f3782, 0fFF800000, %p208;
	selp.f32 	%f4043, %f3783, 0fFF800000, %p209;
	selp.f32 	%f4044, %f3788, 0fFF800000, %p206;
	selp.f32 	%f4045, %f3789, 0fFF800000, %p207;
	selp.f32 	%f4046, %f3790, 0fFF800000, %p206;
	selp.f32 	%f4047, %f3791, 0fFF800000, %p207;
	selp.f32 	%f4048, %f3796, 0fFF800000, %p208;
	selp.f32 	%f4049, %f3797, 0fFF800000, %p209;
	selp.f32 	%f4050, %f3798, 0fFF800000, %p208;
	selp.f32 	%f4051, %f3799, 0fFF800000, %p209;
	.loc	1 172 14                        // prefix_prefill.py:172:14
	mul.f32 	%f4052, %f2401, %f4036;
	mul.f32 	%f4053, %f2401, %f4037;
	mul.f32 	%f4054, %f2401, %f4038;
	mul.f32 	%f4055, %f2401, %f4039;
	mul.f32 	%f4056, %f2401, %f4040;
	mul.f32 	%f4057, %f2401, %f4041;
	mul.f32 	%f4058, %f2401, %f4042;
	mul.f32 	%f4059, %f2401, %f4043;
	mul.f32 	%f4060, %f2401, %f4044;
	mul.f32 	%f4061, %f2401, %f4045;
	mul.f32 	%f4062, %f2401, %f4046;
	mul.f32 	%f4063, %f2401, %f4047;
	mul.f32 	%f4064, %f2401, %f4048;
	mul.f32 	%f4065, %f2401, %f4049;
	mul.f32 	%f4066, %f2401, %f4050;
	mul.f32 	%f4067, %f2401, %f4051;
$L__tmp9:
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f4068, %f4052, %f4053;
	max.f32 	%f4069, %f4054, %f4055;
	max.f32 	%f4070, %f4068, %f4056;
	max.f32 	%f4071, %f4070, %f4057;
	max.f32 	%f4072, %f4069, %f4058;
	max.f32 	%f4073, %f4072, %f4059;
	max.f32 	%f4074, %f4060, %f4061;
	max.f32 	%f4075, %f4062, %f4063;
	max.f32 	%f4076, %f4074, %f4064;
	max.f32 	%f4077, %f4076, %f4065;
	max.f32 	%f4078, %f4075, %f4066;
	max.f32 	%f4079, %f4078, %f4067;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r2519, %f4071;
	shfl.sync.bfly.b32	%r2520, %r2519, 2, 31, -1;
	mov.b32 	%f4080, %r2520;
	mov.b32 	%r2521, %f4073;
	mov.b32 	%r2522, %f4077;
	mov.b32 	%r2523, %f4079;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f4081, %f4071, %f4080;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r2524, %f4081;
	shfl.sync.bfly.b32	%r2525, %r2524, 1, 31, -1;
	shfl.sync.bfly.b32	%r2526, %r2521, 2, 31, -1;
	mov.b32 	%f4082, %r2526;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f4083, %f4073, %f4082;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r2527, %f4083;
	shfl.sync.bfly.b32	%r2528, %r2527, 1, 31, -1;
	shfl.sync.bfly.b32	%r2529, %r2522, 2, 31, -1;
	mov.b32 	%f4084, %r2529;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f4085, %f4077, %f4084;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r2530, %f4085;
	shfl.sync.bfly.b32	%r2531, %r2530, 1, 31, -1;
	shfl.sync.bfly.b32	%r2532, %r2523, 2, 31, -1;
	mov.b32 	%f4086, %r2532;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f4087, %f4079, %f4086;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r2533, %f4087;
	shfl.sync.bfly.b32	%r2534, %r2533, 1, 31, -1;
	mov.b32 	%f4088, %r2534;
	mov.b32 	%f4089, %r2531;
	mov.b32 	%f4090, %r2528;
	mov.b32 	%f4091, %r2525;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f4092, %f4081, %f4091;
	max.f32 	%f4093, %f4083, %f4090;
	max.f32 	%f4094, %f4085, %f4089;
	max.f32 	%f4095, %f4087, %f4088;
$L__tmp10:
	.loc	1 190 31                        // prefix_prefill.py:190:31
	max.f32 	%f860, %f568, %f4095;
	max.f32 	%f859, %f567, %f4094;
	max.f32 	%f858, %f566, %f4093;
	max.f32 	%f857, %f565, %f4092;
	.loc	1 191 24                        // prefix_prefill.py:191:24
	neg.f32 	%f4096, %f857;
	fma.rn.f32 	%f4097, %f2401, %f4036, %f4096;
	fma.rn.f32 	%f4098, %f2401, %f4037, %f4096;
	neg.f32 	%f4099, %f858;
	fma.rn.f32 	%f4100, %f2401, %f4038, %f4099;
	fma.rn.f32 	%f4101, %f2401, %f4039, %f4099;
	fma.rn.f32 	%f4102, %f2401, %f4040, %f4096;
	fma.rn.f32 	%f4103, %f2401, %f4041, %f4096;
	fma.rn.f32 	%f4104, %f2401, %f4042, %f4099;
	fma.rn.f32 	%f4105, %f2401, %f4043, %f4099;
	neg.f32 	%f4106, %f859;
	fma.rn.f32 	%f4107, %f2401, %f4044, %f4106;
	fma.rn.f32 	%f4108, %f2401, %f4045, %f4106;
	neg.f32 	%f4109, %f860;
	fma.rn.f32 	%f4110, %f2401, %f4046, %f4109;
	fma.rn.f32 	%f4111, %f2401, %f4047, %f4109;
	fma.rn.f32 	%f4112, %f2401, %f4048, %f4106;
	fma.rn.f32 	%f4113, %f2401, %f4049, %f4106;
	fma.rn.f32 	%f4114, %f2401, %f4050, %f4109;
	fma.rn.f32 	%f4115, %f2401, %f4051, %f4109;
	.loc	1 191 19                        // prefix_prefill.py:191:19
	mul.f32 	%f3997, %f4097, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f3996, %f3997;
	// end inline asm
	mul.f32 	%f3999, %f4098, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f3998, %f3999;
	// end inline asm
	mul.f32 	%f4001, %f4100, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4000, %f4001;
	// end inline asm
	mul.f32 	%f4003, %f4101, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4002, %f4003;
	// end inline asm
	mul.f32 	%f4005, %f4102, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4004, %f4005;
	// end inline asm
	mul.f32 	%f4007, %f4103, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4006, %f4007;
	// end inline asm
	mul.f32 	%f4009, %f4104, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4008, %f4009;
	// end inline asm
	mul.f32 	%f4011, %f4105, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4010, %f4011;
	// end inline asm
	mul.f32 	%f4013, %f4107, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4012, %f4013;
	// end inline asm
	mul.f32 	%f4015, %f4108, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4014, %f4015;
	// end inline asm
	mul.f32 	%f4017, %f4110, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4016, %f4017;
	// end inline asm
	mul.f32 	%f4019, %f4111, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4018, %f4019;
	// end inline asm
	mul.f32 	%f4021, %f4112, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4020, %f4021;
	// end inline asm
	mul.f32 	%f4023, %f4113, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4022, %f4023;
	// end inline asm
	mul.f32 	%f4025, %f4114, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4024, %f4025;
	// end inline asm
	mul.f32 	%f4027, %f4115, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4026, %f4027;
	// end inline asm
$L__tmp11:
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f4116, %f3996, %f3998;
	add.f32 	%f4117, %f4000, %f4002;
	add.f32 	%f4118, %f4116, %f4004;
	add.f32 	%f4119, %f4118, %f4006;
	add.f32 	%f4120, %f4117, %f4008;
	add.f32 	%f4121, %f4120, %f4010;
	add.f32 	%f4122, %f4012, %f4014;
	add.f32 	%f4123, %f4016, %f4018;
	add.f32 	%f4124, %f4122, %f4020;
	add.f32 	%f4125, %f4124, %f4022;
	add.f32 	%f4126, %f4123, %f4024;
	add.f32 	%f4127, %f4126, %f4026;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r2535, %f4119;
	shfl.sync.bfly.b32	%r2536, %r2535, 2, 31, -1;
	mov.b32 	%f4128, %r2536;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f4129, %f4119, %f4128;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r2537, %f4129;
	shfl.sync.bfly.b32	%r2538, %r2537, 1, 31, -1;
	mov.b32 	%r2539, %f4121;
	shfl.sync.bfly.b32	%r2540, %r2539, 2, 31, -1;
	mov.b32 	%f4130, %r2540;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f4131, %f4121, %f4130;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r2541, %f4131;
	shfl.sync.bfly.b32	%r2542, %r2541, 1, 31, -1;
	mov.b32 	%r2543, %f4125;
	shfl.sync.bfly.b32	%r2544, %r2543, 2, 31, -1;
	mov.b32 	%f4132, %r2544;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f4133, %f4125, %f4132;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r2545, %f4133;
	shfl.sync.bfly.b32	%r2546, %r2545, 1, 31, -1;
	mov.b32 	%r2547, %f4127;
	shfl.sync.bfly.b32	%r2548, %r2547, 2, 31, -1;
	mov.b32 	%f4134, %r2548;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f4135, %f4127, %f4134;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r2549, %f4135;
	shfl.sync.bfly.b32	%r2550, %r2549, 1, 31, -1;
	mov.b32 	%f4136, %r2550;
	mov.b32 	%f4137, %r2546;
	mov.b32 	%f4138, %r2542;
	mov.b32 	%f4139, %r2538;
$L__tmp12:
	.loc	1 193 29                        // prefix_prefill.py:193:29
	sub.f32 	%f4140, %f565, %f857;
	sub.f32 	%f4141, %f566, %f858;
	sub.f32 	%f4142, %f567, %f859;
	sub.f32 	%f4143, %f568, %f860;
	.loc	1 193 23                        // prefix_prefill.py:193:23
	mul.f32 	%f4029, %f4140, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4028, %f4029;
	// end inline asm
	mul.f32 	%f4031, %f4141, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4030, %f4031;
	// end inline asm
	mul.f32 	%f4033, %f4142, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4032, %f4033;
	// end inline asm
	mul.f32 	%f4035, %f4143, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4034, %f4035;
	// end inline asm
	.loc	1 194 20                        // prefix_prefill.py:194:20
	mul.f32 	%f4144, %f3484, %f4028;
	mul.f32 	%f4145, %f3485, %f4028;
	mul.f32 	%f4146, %f3486, %f4030;
	mul.f32 	%f4147, %f3487, %f4030;
	mul.f32 	%f4152, %f3492, %f4028;
	mul.f32 	%f4153, %f3493, %f4028;
	mul.f32 	%f4154, %f3494, %f4030;
	mul.f32 	%f4155, %f3495, %f4030;
	mul.f32 	%f4160, %f3500, %f4028;
	mul.f32 	%f4161, %f3501, %f4028;
	mul.f32 	%f4162, %f3502, %f4030;
	mul.f32 	%f4163, %f3503, %f4030;
	mul.f32 	%f4168, %f3508, %f4028;
	mul.f32 	%f4169, %f3509, %f4028;
	mul.f32 	%f4170, %f3510, %f4030;
	mul.f32 	%f4171, %f3511, %f4030;
	mul.f32 	%f4176, %f3516, %f4028;
	mul.f32 	%f4177, %f3517, %f4028;
	mul.f32 	%f4178, %f3518, %f4030;
	mul.f32 	%f4179, %f3519, %f4030;
	mul.f32 	%f4184, %f3524, %f4028;
	mul.f32 	%f4185, %f3525, %f4028;
	mul.f32 	%f4186, %f3526, %f4030;
	mul.f32 	%f4187, %f3527, %f4030;
	mul.f32 	%f4192, %f3532, %f4028;
	mul.f32 	%f4193, %f3533, %f4028;
	mul.f32 	%f4194, %f3534, %f4030;
	mul.f32 	%f4195, %f3535, %f4030;
	mul.f32 	%f4200, %f3540, %f4028;
	mul.f32 	%f4201, %f3541, %f4028;
	mul.f32 	%f4202, %f3542, %f4030;
	mul.f32 	%f4203, %f3543, %f4030;
	mul.f32 	%f4208, %f3548, %f4028;
	mul.f32 	%f4209, %f3549, %f4028;
	mul.f32 	%f4210, %f3550, %f4030;
	mul.f32 	%f4211, %f3551, %f4030;
	mul.f32 	%f4216, %f3556, %f4028;
	mul.f32 	%f4217, %f3557, %f4028;
	mul.f32 	%f4218, %f3558, %f4030;
	mul.f32 	%f4219, %f3559, %f4030;
	mul.f32 	%f4224, %f3564, %f4028;
	mul.f32 	%f4225, %f3565, %f4028;
	mul.f32 	%f4226, %f3566, %f4030;
	mul.f32 	%f4227, %f3567, %f4030;
	mul.f32 	%f4232, %f3572, %f4028;
	mul.f32 	%f4233, %f3573, %f4028;
	mul.f32 	%f4234, %f3574, %f4030;
	mul.f32 	%f4235, %f3575, %f4030;
	mul.f32 	%f4240, %f3580, %f4028;
	mul.f32 	%f4241, %f3581, %f4028;
	mul.f32 	%f4242, %f3582, %f4030;
	mul.f32 	%f4243, %f3583, %f4030;
	mul.f32 	%f4248, %f3588, %f4028;
	mul.f32 	%f4249, %f3589, %f4028;
	mul.f32 	%f4250, %f3590, %f4030;
	mul.f32 	%f4251, %f3591, %f4030;
	mul.f32 	%f4256, %f3596, %f4028;
	mul.f32 	%f4257, %f3597, %f4028;
	mul.f32 	%f4258, %f3598, %f4030;
	mul.f32 	%f4259, %f3599, %f4030;
	mul.f32 	%f4264, %f3604, %f4028;
	mul.f32 	%f4265, %f3605, %f4028;
	mul.f32 	%f4266, %f3606, %f4030;
	mul.f32 	%f4267, %f3607, %f4030;
	mul.f32 	%f4272, %f3612, %f4032;
	mul.f32 	%f4273, %f3613, %f4032;
	mul.f32 	%f4274, %f3614, %f4034;
	mul.f32 	%f4275, %f3615, %f4034;
	mul.f32 	%f4280, %f3620, %f4032;
	mul.f32 	%f4281, %f3621, %f4032;
	mul.f32 	%f4282, %f3622, %f4034;
	mul.f32 	%f4283, %f3623, %f4034;
	mul.f32 	%f4288, %f3628, %f4032;
	mul.f32 	%f4289, %f3629, %f4032;
	mul.f32 	%f4290, %f3630, %f4034;
	mul.f32 	%f4291, %f3631, %f4034;
	mul.f32 	%f4296, %f3636, %f4032;
	mul.f32 	%f4297, %f3637, %f4032;
	mul.f32 	%f4298, %f3638, %f4034;
	mul.f32 	%f4299, %f3639, %f4034;
	mul.f32 	%f4304, %f3644, %f4032;
	mul.f32 	%f4305, %f3645, %f4032;
	mul.f32 	%f4306, %f3646, %f4034;
	mul.f32 	%f4307, %f3647, %f4034;
	mul.f32 	%f4312, %f3652, %f4032;
	mul.f32 	%f4313, %f3653, %f4032;
	mul.f32 	%f4314, %f3654, %f4034;
	mul.f32 	%f4315, %f3655, %f4034;
	mul.f32 	%f4320, %f3660, %f4032;
	mul.f32 	%f4321, %f3661, %f4032;
	mul.f32 	%f4322, %f3662, %f4034;
	mul.f32 	%f4323, %f3663, %f4034;
	mul.f32 	%f4328, %f3668, %f4032;
	mul.f32 	%f4329, %f3669, %f4032;
	mul.f32 	%f4330, %f3670, %f4034;
	mul.f32 	%f4331, %f3671, %f4034;
	mul.f32 	%f4336, %f3676, %f4032;
	mul.f32 	%f4337, %f3677, %f4032;
	mul.f32 	%f4338, %f3678, %f4034;
	mul.f32 	%f4339, %f3679, %f4034;
	mul.f32 	%f4344, %f3684, %f4032;
	mul.f32 	%f4345, %f3685, %f4032;
	mul.f32 	%f4346, %f3686, %f4034;
	mul.f32 	%f4347, %f3687, %f4034;
	mul.f32 	%f4352, %f3692, %f4032;
	mul.f32 	%f4353, %f3693, %f4032;
	mul.f32 	%f4354, %f3694, %f4034;
	mul.f32 	%f4355, %f3695, %f4034;
	mul.f32 	%f4360, %f3700, %f4032;
	mul.f32 	%f4361, %f3701, %f4032;
	mul.f32 	%f4362, %f3702, %f4034;
	mul.f32 	%f4363, %f3703, %f4034;
	mul.f32 	%f4368, %f3708, %f4032;
	mul.f32 	%f4369, %f3709, %f4032;
	mul.f32 	%f4370, %f3710, %f4034;
	mul.f32 	%f4371, %f3711, %f4034;
	mul.f32 	%f4376, %f3716, %f4032;
	mul.f32 	%f4377, %f3717, %f4032;
	mul.f32 	%f4378, %f3718, %f4034;
	mul.f32 	%f4379, %f3719, %f4034;
	mul.f32 	%f4384, %f3724, %f4032;
	mul.f32 	%f4385, %f3725, %f4032;
	mul.f32 	%f4386, %f3726, %f4034;
	mul.f32 	%f4387, %f3727, %f4034;
	mul.f32 	%f4392, %f3732, %f4032;
	mul.f32 	%f4393, %f3733, %f4032;
	mul.f32 	%f4394, %f3734, %f4034;
	mul.f32 	%f4395, %f3735, %f4034;
	mul.wide.s32 	%rd538, %r366, 2;
	mul.wide.s32 	%rd539, %r374, 2;
	.loc	1 197 11                        // prefix_prefill.py:197:11
	@%p192 bra 	$L__BB0_23;
// %bb.22:                              //   in Loop: Header=BB0_2 Depth=1
	.loc	1 0 0                           // prefix_prefill.py:0:0
	add.s32 	%r367, %r2254, %r70;
	add.s32 	%r368, %r2254, %r71;
	add.s32 	%r369, %r2254, %r72;
	add.s32 	%r370, %r2254, %r73;
	add.s32 	%r371, %r2254, %r74;
	add.s32 	%r372, %r2254, %r75;
	add.s32 	%r373, %r2254, %r76;
	add.s32 	%r375, %r2255, %r70;
	add.s32 	%r376, %r2255, %r71;
	add.s32 	%r377, %r2255, %r72;
	add.s32 	%r378, %r2255, %r73;
	add.s32 	%r379, %r2255, %r74;
	add.s32 	%r380, %r2255, %r75;
	add.s32 	%r381, %r2255, %r76;
	.loc	1 202 28                        // prefix_prefill.py:202:28
	add.s32 	%r2560, %r7324, 32;
	add.s32 	%r2561, %r7324, 33;
	add.s32 	%r2562, %r7324, 34;
	add.s32 	%r2563, %r7324, 35;
	add.s32 	%r2564, %r7324, 36;
	add.s32 	%r2565, %r7324, 37;
	add.s32 	%r2566, %r7324, 38;
	.loc	1 202 50                        // prefix_prefill.py:202:50
	add.s32 	%r2567, %r7324, 39;
	setp.lt.s32 	%p212, %r2560, %r5;
	setp.lt.s32 	%p214, %r2561, %r5;
	setp.lt.s32 	%p216, %r2562, %r5;
	setp.lt.s32 	%p218, %r2563, %r5;
	setp.lt.s32 	%p220, %r2564, %r5;
	setp.lt.s32 	%p222, %r2565, %r5;
	setp.lt.s32 	%p224, %r2566, %r5;
	setp.lt.s32 	%p226, %r2567, %r5;
	.loc	1 200 26                        // prefix_prefill.py:200:26
	add.s64 	%rd257, %rd111, %rd538;
	mul.wide.s32 	%rd274, %r367, 2;
	add.s64 	%rd258, %rd111, %rd274;
	mul.wide.s32 	%rd275, %r368, 2;
	add.s64 	%rd259, %rd111, %rd275;
	mul.wide.s32 	%rd276, %r369, 2;
	add.s64 	%rd260, %rd111, %rd276;
	mul.wide.s32 	%rd277, %r370, 2;
	add.s64 	%rd261, %rd111, %rd277;
	mul.wide.s32 	%rd278, %r371, 2;
	add.s64 	%rd262, %rd111, %rd278;
	mul.wide.s32 	%rd279, %r372, 2;
	add.s64 	%rd263, %rd111, %rd279;
	mul.wide.s32 	%rd280, %r373, 2;
	add.s64 	%rd264, %rd111, %rd280;
	add.s64 	%rd265, %rd111, %rd539;
	mul.wide.s32 	%rd282, %r375, 2;
	add.s64 	%rd266, %rd111, %rd282;
	mul.wide.s32 	%rd283, %r376, 2;
	add.s64 	%rd267, %rd111, %rd283;
	mul.wide.s32 	%rd284, %r377, 2;
	add.s64 	%rd268, %rd111, %rd284;
	mul.wide.s32 	%rd285, %r378, 2;
	add.s64 	%rd269, %rd111, %rd285;
	mul.wide.s32 	%rd286, %r379, 2;
	add.s64 	%rd270, %rd111, %rd286;
	mul.wide.s32 	%rd287, %r380, 2;
	add.s64 	%rd271, %rd111, %rd287;
	mul.wide.s32 	%rd288, %r381, 2;
	add.s64 	%rd272, %rd111, %rd288;
	.loc	1 200 16                        // prefix_prefill.py:200:16
	// begin inline asm
	mov.u16 %rs129, 0x0;
	@%p212 ld.global.b16 { %rs129 }, [ %rd257 + 0 ];
	@!%p212 mov.u16 %rs129, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs131, 0x0;
	@%p214 ld.global.b16 { %rs131 }, [ %rd258 + 0 ];
	@!%p214 mov.u16 %rs131, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs133, 0x0;
	@%p216 ld.global.b16 { %rs133 }, [ %rd259 + 0 ];
	@!%p216 mov.u16 %rs133, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs135, 0x0;
	@%p218 ld.global.b16 { %rs135 }, [ %rd260 + 0 ];
	@!%p218 mov.u16 %rs135, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs137, 0x0;
	@%p220 ld.global.b16 { %rs137 }, [ %rd261 + 0 ];
	@!%p220 mov.u16 %rs137, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs139, 0x0;
	@%p222 ld.global.b16 { %rs139 }, [ %rd262 + 0 ];
	@!%p222 mov.u16 %rs139, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs141, 0x0;
	@%p224 ld.global.b16 { %rs141 }, [ %rd263 + 0 ];
	@!%p224 mov.u16 %rs141, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs143, 0x0;
	@%p226 ld.global.b16 { %rs143 }, [ %rd264 + 0 ];
	@!%p226 mov.u16 %rs143, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs145, 0x0;
	@%p212 ld.global.b16 { %rs145 }, [ %rd265 + 0 ];
	@!%p212 mov.u16 %rs145, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs147, 0x0;
	@%p214 ld.global.b16 { %rs147 }, [ %rd266 + 0 ];
	@!%p214 mov.u16 %rs147, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs149, 0x0;
	@%p216 ld.global.b16 { %rs149 }, [ %rd267 + 0 ];
	@!%p216 mov.u16 %rs149, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs151, 0x0;
	@%p218 ld.global.b16 { %rs151 }, [ %rd268 + 0 ];
	@!%p218 mov.u16 %rs151, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs153, 0x0;
	@%p220 ld.global.b16 { %rs153 }, [ %rd269 + 0 ];
	@!%p220 mov.u16 %rs153, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs155, 0x0;
	@%p222 ld.global.b16 { %rs155 }, [ %rd270 + 0 ];
	@!%p222 mov.u16 %rs155, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs157, 0x0;
	@%p224 ld.global.b16 { %rs157 }, [ %rd271 + 0 ];
	@!%p224 mov.u16 %rs157, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs159, 0x0;
	@%p226 ld.global.b16 { %rs159 }, [ %rd272 + 0 ];
	@!%p226 mov.u16 %rs159, %rs258;
	// end inline asm
	mov.b32 	%r7367, {%rs129, %rs131};
	mov.b32 	%r7368, {%rs133, %rs135};
	mov.b32 	%r7369, {%rs137, %rs139};
	mov.b32 	%r7370, {%rs141, %rs143};
	mov.b32 	%r7371, {%rs145, %rs147};
	mov.b32 	%r7372, {%rs149, %rs151};
	mov.b32 	%r7373, {%rs153, %rs155};
	mov.b32 	%r7374, {%rs157, %rs159};
	.loc	1 197 11                        // prefix_prefill.py:197:11
	bra.uni 	$L__BB0_24;
$L__BB0_23:                             //   in Loop: Header=BB0_2 Depth=1
	.loc	1 205 39                        // prefix_prefill.py:205:39
	add.s64 	%rd253, %rd111, %rd538;
	add.s64 	%rd254, %rd111, %rd539;
	.loc	1 205 29                        // prefix_prefill.py:205:29
	// begin inline asm
	mov.u32 %r7367, 0x0;
	mov.u32 %r7368, 0x0;
	mov.u32 %r7369, 0x0;
	mov.u32 %r7370, 0x0;
	@%p546 ld.global.v4.b32 { %r7367, %r7368, %r7369, %r7370 }, [ %rd253 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r7371, 0x0;
	mov.u32 %r7372, 0x0;
	mov.u32 %r7373, 0x0;
	mov.u32 %r7374, 0x0;
	@%p546 ld.global.v4.b32 { %r7371, %r7372, %r7373, %r7374 }, [ %rd254 + 0 ];
	// end inline asm
$L__BB0_24:                             //   in Loop: Header=BB0_2 Depth=1
	.loc	1 0 0                           // prefix_prefill.py:0:0
	fma.rn.f32 	%f853, %f561, %f3368, %f589;
	fma.rn.f32 	%f854, %f562, %f3370, %f590;
	fma.rn.f32 	%f855, %f563, %f3372, %f591;
	fma.rn.f32 	%f856, %f564, %f3374, %f592;
	add.f32 	%f881, %f4129, %f4139;
	add.f32 	%f882, %f4131, %f4138;
	add.f32 	%f883, %f4133, %f4137;
	add.f32 	%f884, %f4135, %f4136;
	.loc	1 197 11                        // prefix_prefill.py:197:11
	bar.sync 	0;
	st.shared.v4.b32 	[%r105], {%r7367, %r7368, %r7369, %r7370};
	st.shared.v4.b32 	[%r106], {%r7371, %r7372, %r7373, %r7374};
	.loc	1 211 17                        // prefix_prefill.py:211:17
	mov.b32 	%r2576, %f3996;
	// begin inline asm
	cvt.rn.bf16.f32 %rs161, %r2576;
	// end inline asm
	mov.b32 	%r2577, %f3998;
	// begin inline asm
	cvt.rn.bf16.f32 %rs162, %r2577;
	// end inline asm
	mov.b32 	%r2578, %f4000;
	// begin inline asm
	cvt.rn.bf16.f32 %rs163, %r2578;
	// end inline asm
	mov.b32 	%r2579, %f4002;
	// begin inline asm
	cvt.rn.bf16.f32 %rs164, %r2579;
	// end inline asm
	mov.b32 	%r2580, %f4004;
	// begin inline asm
	cvt.rn.bf16.f32 %rs165, %r2580;
	// end inline asm
	mov.b32 	%r2581, %f4006;
	// begin inline asm
	cvt.rn.bf16.f32 %rs166, %r2581;
	// end inline asm
	mov.b32 	%r2582, %f4008;
	// begin inline asm
	cvt.rn.bf16.f32 %rs167, %r2582;
	// end inline asm
	mov.b32 	%r2583, %f4010;
	// begin inline asm
	cvt.rn.bf16.f32 %rs168, %r2583;
	// end inline asm
	mov.b32 	%r2584, %f4012;
	// begin inline asm
	cvt.rn.bf16.f32 %rs169, %r2584;
	// end inline asm
	mov.b32 	%r2585, %f4014;
	// begin inline asm
	cvt.rn.bf16.f32 %rs170, %r2585;
	// end inline asm
	mov.b32 	%r2586, %f4016;
	// begin inline asm
	cvt.rn.bf16.f32 %rs171, %r2586;
	// end inline asm
	mov.b32 	%r2587, %f4018;
	// begin inline asm
	cvt.rn.bf16.f32 %rs172, %r2587;
	// end inline asm
	mov.b32 	%r2588, %f4020;
	// begin inline asm
	cvt.rn.bf16.f32 %rs173, %r2588;
	// end inline asm
	mov.b32 	%r2589, %f4022;
	// begin inline asm
	cvt.rn.bf16.f32 %rs174, %r2589;
	// end inline asm
	mov.b32 	%r2590, %f4024;
	// begin inline asm
	cvt.rn.bf16.f32 %rs175, %r2590;
	// end inline asm
	mov.b32 	%r2591, %f4026;
	// begin inline asm
	cvt.rn.bf16.f32 %rs176, %r2591;
	// end inline asm
	mov.b32 	%r2632, {%rs161, %rs162};
	mov.b32 	%r2633, {%rs163, %rs164};
	mov.b32 	%r2634, {%rs165, %rs166};
	mov.b32 	%r2635, {%rs167, %rs168};
	mov.b32 	%r2728, {%rs169, %rs170};
	mov.b32 	%r2729, {%rs171, %rs172};
	mov.b32 	%r2730, {%rs173, %rs174};
	mov.b32 	%r2731, {%rs175, %rs176};
	.loc	1 197 11                        // prefix_prefill.py:197:11
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2636, %r2637, %r2642, %r2643 }, [ %r1434 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2648, %r2649, %r2654, %r2655 }, [ %r1439 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2660, %r2661, %r2666, %r2667 }, [ %r1444 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2672, %r2673, %r2678, %r2679 }, [ %r1449 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2684, %r2685, %r2690, %r2691 }, [ %r1454 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2696, %r2697, %r2702, %r2703 }, [ %r1459 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2708, %r2709, %r2714, %r2715 }, [ %r1464 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2720, %r2721, %r2726, %r2727 }, [ %r1469 + 0 ];
	// end inline asm
	.loc	1 213 24                        // prefix_prefill.py:213:24
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4144, %f4145, %f4146, %f4147 }, { %r2632, %r2633, %r2634, %r2635 }, { %r2636, %r2637 }, { %f4144, %f4145, %f4146, %f4147 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4152, %f4153, %f4154, %f4155 }, { %r2632, %r2633, %r2634, %r2635 }, { %r2642, %r2643 }, { %f4152, %f4153, %f4154, %f4155 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4160, %f4161, %f4162, %f4163 }, { %r2632, %r2633, %r2634, %r2635 }, { %r2648, %r2649 }, { %f4160, %f4161, %f4162, %f4163 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4168, %f4169, %f4170, %f4171 }, { %r2632, %r2633, %r2634, %r2635 }, { %r2654, %r2655 }, { %f4168, %f4169, %f4170, %f4171 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4176, %f4177, %f4178, %f4179 }, { %r2632, %r2633, %r2634, %r2635 }, { %r2660, %r2661 }, { %f4176, %f4177, %f4178, %f4179 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4184, %f4185, %f4186, %f4187 }, { %r2632, %r2633, %r2634, %r2635 }, { %r2666, %r2667 }, { %f4184, %f4185, %f4186, %f4187 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4192, %f4193, %f4194, %f4195 }, { %r2632, %r2633, %r2634, %r2635 }, { %r2672, %r2673 }, { %f4192, %f4193, %f4194, %f4195 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4200, %f4201, %f4202, %f4203 }, { %r2632, %r2633, %r2634, %r2635 }, { %r2678, %r2679 }, { %f4200, %f4201, %f4202, %f4203 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4208, %f4209, %f4210, %f4211 }, { %r2632, %r2633, %r2634, %r2635 }, { %r2684, %r2685 }, { %f4208, %f4209, %f4210, %f4211 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4216, %f4217, %f4218, %f4219 }, { %r2632, %r2633, %r2634, %r2635 }, { %r2690, %r2691 }, { %f4216, %f4217, %f4218, %f4219 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4224, %f4225, %f4226, %f4227 }, { %r2632, %r2633, %r2634, %r2635 }, { %r2696, %r2697 }, { %f4224, %f4225, %f4226, %f4227 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4232, %f4233, %f4234, %f4235 }, { %r2632, %r2633, %r2634, %r2635 }, { %r2702, %r2703 }, { %f4232, %f4233, %f4234, %f4235 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4240, %f4241, %f4242, %f4243 }, { %r2632, %r2633, %r2634, %r2635 }, { %r2708, %r2709 }, { %f4240, %f4241, %f4242, %f4243 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4248, %f4249, %f4250, %f4251 }, { %r2632, %r2633, %r2634, %r2635 }, { %r2714, %r2715 }, { %f4248, %f4249, %f4250, %f4251 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4256, %f4257, %f4258, %f4259 }, { %r2632, %r2633, %r2634, %r2635 }, { %r2720, %r2721 }, { %f4256, %f4257, %f4258, %f4259 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4264, %f4265, %f4266, %f4267 }, { %r2632, %r2633, %r2634, %r2635 }, { %r2726, %r2727 }, { %f4264, %f4265, %f4266, %f4267 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4272, %f4273, %f4274, %f4275 }, { %r2728, %r2729, %r2730, %r2731 }, { %r2636, %r2637 }, { %f4272, %f4273, %f4274, %f4275 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4280, %f4281, %f4282, %f4283 }, { %r2728, %r2729, %r2730, %r2731 }, { %r2642, %r2643 }, { %f4280, %f4281, %f4282, %f4283 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4288, %f4289, %f4290, %f4291 }, { %r2728, %r2729, %r2730, %r2731 }, { %r2648, %r2649 }, { %f4288, %f4289, %f4290, %f4291 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4296, %f4297, %f4298, %f4299 }, { %r2728, %r2729, %r2730, %r2731 }, { %r2654, %r2655 }, { %f4296, %f4297, %f4298, %f4299 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4304, %f4305, %f4306, %f4307 }, { %r2728, %r2729, %r2730, %r2731 }, { %r2660, %r2661 }, { %f4304, %f4305, %f4306, %f4307 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4312, %f4313, %f4314, %f4315 }, { %r2728, %r2729, %r2730, %r2731 }, { %r2666, %r2667 }, { %f4312, %f4313, %f4314, %f4315 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4320, %f4321, %f4322, %f4323 }, { %r2728, %r2729, %r2730, %r2731 }, { %r2672, %r2673 }, { %f4320, %f4321, %f4322, %f4323 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4328, %f4329, %f4330, %f4331 }, { %r2728, %r2729, %r2730, %r2731 }, { %r2678, %r2679 }, { %f4328, %f4329, %f4330, %f4331 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4336, %f4337, %f4338, %f4339 }, { %r2728, %r2729, %r2730, %r2731 }, { %r2684, %r2685 }, { %f4336, %f4337, %f4338, %f4339 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4344, %f4345, %f4346, %f4347 }, { %r2728, %r2729, %r2730, %r2731 }, { %r2690, %r2691 }, { %f4344, %f4345, %f4346, %f4347 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4352, %f4353, %f4354, %f4355 }, { %r2728, %r2729, %r2730, %r2731 }, { %r2696, %r2697 }, { %f4352, %f4353, %f4354, %f4355 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4360, %f4361, %f4362, %f4363 }, { %r2728, %r2729, %r2730, %r2731 }, { %r2702, %r2703 }, { %f4360, %f4361, %f4362, %f4363 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4368, %f4369, %f4370, %f4371 }, { %r2728, %r2729, %r2730, %r2731 }, { %r2708, %r2709 }, { %f4368, %f4369, %f4370, %f4371 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4376, %f4377, %f4378, %f4379 }, { %r2728, %r2729, %r2730, %r2731 }, { %r2714, %r2715 }, { %f4376, %f4377, %f4378, %f4379 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4384, %f4385, %f4386, %f4387 }, { %r2728, %r2729, %r2730, %r2731 }, { %r2720, %r2721 }, { %f4384, %f4385, %f4386, %f4387 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4392, %f4393, %f4394, %f4395 }, { %r2728, %r2729, %r2730, %r2731 }, { %r2726, %r2727 }, { %f4392, %f4393, %f4394, %f4395 };
	// end inline asm
	.loc	1 138 21                        // prefix_prefill.py:138:21
	add.s64 	%rd289, %rd550, 12;
	// begin inline asm
	mov.u32 %r2824, 0x0;
	@%p546 ld.global.b32 { %r2824 }, [ %rd289 + 0 ];
	// end inline asm
	.loc	1 142 26                        // prefix_prefill.py:142:26
	mul.lo.s32 	%r2833, %r2824, %r672;
	.loc	1 144 24                        // prefix_prefill.py:144:24
	add.s32 	%r431, %r154, 48;
	add.s32 	%r432, %r154, 49;
	add.s32 	%r433, %r154, 56;
	add.s32 	%r434, %r154, 57;
	add.s32 	%r435, %r2833, %r115;
	add.s32 	%r436, %r2833, %r116;
	.loc	1 148 31                        // prefix_prefill.py:148:31
	mul.lo.s32 	%r2834, %r2824, %r673;
	add.s32 	%r2835, %r2834, %r78;
	add.s32 	%r2836, %r2834, %r79;
	.loc	1 151 17                        // prefix_prefill.py:151:17
	add.s32 	%r437, %r2835, %r21;
	add.s32 	%r445, %r2836, %r21;
	.loc	1 153 21                        // prefix_prefill.py:153:21
	add.s32 	%r7326, %r7326, 64;
	.loc	1 153 34                        // prefix_prefill.py:153:34
	setp.le.s32 	%p245, %r7326, %r5;
	mul.wide.s32 	%rd536, %r435, 2;
	mul.wide.s32 	%rd537, %r436, 2;
	.loc	1 153 11                        // prefix_prefill.py:153:11
	@%p245 bra 	$L__BB0_26;
// %bb.25:                              //   in Loop: Header=BB0_2 Depth=1
	.loc	1 144 24                        // prefix_prefill.py:144:24
	add.s32 	%r2862, %r7325, 56;
	.loc	1 158 50                        // prefix_prefill.py:158:50
	add.s32 	%r2863, %r7325, 48;
	setp.lt.s32 	%p248, %r2863, %r5;
	setp.lt.s32 	%p253, %r2862, %r5;
	.loc	1 156 26                        // prefix_prefill.py:156:26
	add.s64 	%rd294, %rd110, %rd536;
	add.s64 	%rd295, %rd110, %rd537;
	mov.b32 	%r2849, 0;
	.loc	1 156 16                        // prefix_prefill.py:156:16
	// begin inline asm
	mov.u32 %r7381, 0x0;
	mov.u32 %r7382, 0x0;
	mov.u32 %r7379, 0x0;
	mov.u32 %r7380, 0x0;
	@%p248 ld.global.v4.b32 { %r7381, %r7382, %r7379, %r7380 }, [ %rd294 + 0 ];
	@!%p248 mov.u32 %r7381, %r2849;
	@!%p248 mov.u32 %r7382, %r2849;
	@!%p248 mov.u32 %r7379, %r2849;
	@!%p248 mov.u32 %r7380, %r2849;
	// end inline asm
	// begin inline asm
	mov.u32 %r7375, 0x0;
	mov.u32 %r7376, 0x0;
	mov.u32 %r7377, 0x0;
	mov.u32 %r7378, 0x0;
	@%p253 ld.global.v4.b32 { %r7375, %r7376, %r7377, %r7378 }, [ %rd295 + 0 ];
	@!%p253 mov.u32 %r7375, %r2849;
	@!%p253 mov.u32 %r7376, %r2849;
	@!%p253 mov.u32 %r7377, %r2849;
	@!%p253 mov.u32 %r7378, %r2849;
	// end inline asm
	.loc	1 153 11                        // prefix_prefill.py:153:11
	bra.uni 	$L__BB0_27;
$L__BB0_26:                             //   in Loop: Header=BB0_2 Depth=1
	.loc	1 161 39                        // prefix_prefill.py:161:39
	add.s64 	%rd290, %rd110, %rd536;
	add.s64 	%rd291, %rd110, %rd537;
	.loc	1 161 29                        // prefix_prefill.py:161:29
	// begin inline asm
	mov.u32 %r7381, 0x0;
	mov.u32 %r7382, 0x0;
	mov.u32 %r7379, 0x0;
	mov.u32 %r7380, 0x0;
	@%p546 ld.global.v4.b32 { %r7381, %r7382, %r7379, %r7380 }, [ %rd290 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r7375, 0x0;
	mov.u32 %r7376, 0x0;
	mov.u32 %r7377, 0x0;
	mov.u32 %r7378, 0x0;
	@%p546 ld.global.v4.b32 { %r7375, %r7376, %r7377, %r7378 }, [ %rd291 + 0 ];
	// end inline asm
$L__BB0_27:                             //   in Loop: Header=BB0_2 Depth=1
	.loc	1 0 0                           // prefix_prefill.py:0:0
	fma.rn.f32 	%f1145, %f853, %f4028, %f881;
	fma.rn.f32 	%f1146, %f854, %f4030, %f882;
	fma.rn.f32 	%f1147, %f855, %f4032, %f883;
	fma.rn.f32 	%f1148, %f856, %f4034, %f884;
	.loc	1 153 11                        // prefix_prefill.py:153:11
	bar.sync 	0;
	st.shared.v4.b32 	[%r80], {%r7381, %r7382, %r7379, %r7380};
	st.shared.v4.b32 	[%r80+2048], {%r7375, %r7376, %r7377, %r7378};
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2908, %r2909, %r2914, %r2915 }, [ %r1126 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2932, %r2933, %r2938, %r2939 }, [ %r1131 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2956, %r2957, %r2962, %r2963 }, [ %r1136 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r2980, %r2981, %r2986, %r2987 }, [ %r1141 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3004, %r3005, %r3010, %r3011 }, [ %r1146 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3028, %r3029, %r3034, %r3035 }, [ %r1151 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3052, %r3053, %r3058, %r3059 }, [ %r1156 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3076, %r3077, %r3082, %r3083 }, [ %r1161 + 0 ];
	// end inline asm
	.loc	1 169 23                        // prefix_prefill.py:169:23
	mov.f32 	%f4432, %f4456;
	mov.f32 	%f4433, %f4456;
	mov.f32 	%f4434, %f4456;
	mov.f32 	%f4435, %f4456;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4432, %f4433, %f4434, %f4435 }, { %r2904, %r2905, %r2906, %r2907 }, { %r2908, %r2909 }, { %f4432, %f4433, %f4434, %f4435 };
	// end inline asm
	mov.f32 	%f4440, %f4456;
	mov.f32 	%f4441, %f4456;
	mov.f32 	%f4442, %f4456;
	mov.f32 	%f4443, %f4456;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4440, %f4441, %f4442, %f4443 }, { %r2904, %r2905, %r2906, %r2907 }, { %r2914, %r2915 }, { %f4440, %f4441, %f4442, %f4443 };
	// end inline asm
	mov.f32 	%f4448, %f4456;
	mov.f32 	%f4449, %f4456;
	mov.f32 	%f4450, %f4456;
	mov.f32 	%f4451, %f4456;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4448, %f4449, %f4450, %f4451 }, { %r2916, %r2917, %r2918, %r2919 }, { %r2908, %r2909 }, { %f4448, %f4449, %f4450, %f4451 };
	// end inline asm
	mov.f32 	%f4457, %f4456;
	mov.f32 	%f4458, %f4456;
	mov.f32 	%f4459, %f4456;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4456, %f4457, %f4458, %f4459 }, { %r2916, %r2917, %r2918, %r2919 }, { %r2914, %r2915 }, { %f4456, %f4457, %f4458, %f4459 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4432, %f4433, %f4434, %f4435 }, { %r2928, %r2929, %r2930, %r2931 }, { %r2932, %r2933 }, { %f4432, %f4433, %f4434, %f4435 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4440, %f4441, %f4442, %f4443 }, { %r2928, %r2929, %r2930, %r2931 }, { %r2938, %r2939 }, { %f4440, %f4441, %f4442, %f4443 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4448, %f4449, %f4450, %f4451 }, { %r2940, %r2941, %r2942, %r2943 }, { %r2932, %r2933 }, { %f4448, %f4449, %f4450, %f4451 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4456, %f4457, %f4458, %f4459 }, { %r2940, %r2941, %r2942, %r2943 }, { %r2938, %r2939 }, { %f4456, %f4457, %f4458, %f4459 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4432, %f4433, %f4434, %f4435 }, { %r2952, %r2953, %r2954, %r2955 }, { %r2956, %r2957 }, { %f4432, %f4433, %f4434, %f4435 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4440, %f4441, %f4442, %f4443 }, { %r2952, %r2953, %r2954, %r2955 }, { %r2962, %r2963 }, { %f4440, %f4441, %f4442, %f4443 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4448, %f4449, %f4450, %f4451 }, { %r2964, %r2965, %r2966, %r2967 }, { %r2956, %r2957 }, { %f4448, %f4449, %f4450, %f4451 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4456, %f4457, %f4458, %f4459 }, { %r2964, %r2965, %r2966, %r2967 }, { %r2962, %r2963 }, { %f4456, %f4457, %f4458, %f4459 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4432, %f4433, %f4434, %f4435 }, { %r2976, %r2977, %r2978, %r2979 }, { %r2980, %r2981 }, { %f4432, %f4433, %f4434, %f4435 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4440, %f4441, %f4442, %f4443 }, { %r2976, %r2977, %r2978, %r2979 }, { %r2986, %r2987 }, { %f4440, %f4441, %f4442, %f4443 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4448, %f4449, %f4450, %f4451 }, { %r2988, %r2989, %r2990, %r2991 }, { %r2980, %r2981 }, { %f4448, %f4449, %f4450, %f4451 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4456, %f4457, %f4458, %f4459 }, { %r2988, %r2989, %r2990, %r2991 }, { %r2986, %r2987 }, { %f4456, %f4457, %f4458, %f4459 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4432, %f4433, %f4434, %f4435 }, { %r3000, %r3001, %r3002, %r3003 }, { %r3004, %r3005 }, { %f4432, %f4433, %f4434, %f4435 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4440, %f4441, %f4442, %f4443 }, { %r3000, %r3001, %r3002, %r3003 }, { %r3010, %r3011 }, { %f4440, %f4441, %f4442, %f4443 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4448, %f4449, %f4450, %f4451 }, { %r3012, %r3013, %r3014, %r3015 }, { %r3004, %r3005 }, { %f4448, %f4449, %f4450, %f4451 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4456, %f4457, %f4458, %f4459 }, { %r3012, %r3013, %r3014, %r3015 }, { %r3010, %r3011 }, { %f4456, %f4457, %f4458, %f4459 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4432, %f4433, %f4434, %f4435 }, { %r3024, %r3025, %r3026, %r3027 }, { %r3028, %r3029 }, { %f4432, %f4433, %f4434, %f4435 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4440, %f4441, %f4442, %f4443 }, { %r3024, %r3025, %r3026, %r3027 }, { %r3034, %r3035 }, { %f4440, %f4441, %f4442, %f4443 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4448, %f4449, %f4450, %f4451 }, { %r3036, %r3037, %r3038, %r3039 }, { %r3028, %r3029 }, { %f4448, %f4449, %f4450, %f4451 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4456, %f4457, %f4458, %f4459 }, { %r3036, %r3037, %r3038, %r3039 }, { %r3034, %r3035 }, { %f4456, %f4457, %f4458, %f4459 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4432, %f4433, %f4434, %f4435 }, { %r3048, %r3049, %r3050, %r3051 }, { %r3052, %r3053 }, { %f4432, %f4433, %f4434, %f4435 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4440, %f4441, %f4442, %f4443 }, { %r3048, %r3049, %r3050, %r3051 }, { %r3058, %r3059 }, { %f4440, %f4441, %f4442, %f4443 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4448, %f4449, %f4450, %f4451 }, { %r3060, %r3061, %r3062, %r3063 }, { %r3052, %r3053 }, { %f4448, %f4449, %f4450, %f4451 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4456, %f4457, %f4458, %f4459 }, { %r3060, %r3061, %r3062, %r3063 }, { %r3058, %r3059 }, { %f4456, %f4457, %f4458, %f4459 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4432, %f4433, %f4434, %f4435 }, { %r3072, %r3073, %r3074, %r3075 }, { %r3076, %r3077 }, { %f4432, %f4433, %f4434, %f4435 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4440, %f4441, %f4442, %f4443 }, { %r3072, %r3073, %r3074, %r3075 }, { %r3082, %r3083 }, { %f4440, %f4441, %f4442, %f4443 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4448, %f4449, %f4450, %f4451 }, { %r3084, %r3085, %r3086, %r3087 }, { %r3076, %r3077 }, { %f4448, %f4449, %f4450, %f4451 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f4456, %f4457, %f4458, %f4459 }, { %r3084, %r3085, %r3086, %r3087 }, { %r3082, %r3083 }, { %f4456, %f4457, %f4458, %f4459 };
	// end inline asm
	.loc	1 170 55                        // prefix_prefill.py:170:55
	setp.lt.s32 	%p259, %r431, %r5;
	setp.lt.s32 	%p260, %r432, %r5;
	setp.lt.s32 	%p261, %r433, %r5;
	setp.lt.s32 	%p262, %r434, %r5;
	.loc	1 171 22                        // prefix_prefill.py:171:22
	selp.f32 	%f4696, %f4432, 0fFF800000, %p259;
	selp.f32 	%f4697, %f4433, 0fFF800000, %p260;
	selp.f32 	%f4698, %f4434, 0fFF800000, %p259;
	selp.f32 	%f4699, %f4435, 0fFF800000, %p260;
	selp.f32 	%f4700, %f4440, 0fFF800000, %p261;
	selp.f32 	%f4701, %f4441, 0fFF800000, %p262;
	selp.f32 	%f4702, %f4442, 0fFF800000, %p261;
	selp.f32 	%f4703, %f4443, 0fFF800000, %p262;
	selp.f32 	%f4704, %f4448, 0fFF800000, %p259;
	selp.f32 	%f4705, %f4449, 0fFF800000, %p260;
	selp.f32 	%f4706, %f4450, 0fFF800000, %p259;
	selp.f32 	%f4707, %f4451, 0fFF800000, %p260;
	selp.f32 	%f4708, %f4456, 0fFF800000, %p261;
	selp.f32 	%f4709, %f4457, 0fFF800000, %p262;
	selp.f32 	%f4710, %f4458, 0fFF800000, %p261;
	selp.f32 	%f4711, %f4459, 0fFF800000, %p262;
	.loc	1 172 14                        // prefix_prefill.py:172:14
	mul.f32 	%f4712, %f2401, %f4696;
	mul.f32 	%f4713, %f2401, %f4697;
	mul.f32 	%f4714, %f2401, %f4698;
	mul.f32 	%f4715, %f2401, %f4699;
	mul.f32 	%f4716, %f2401, %f4700;
	mul.f32 	%f4717, %f2401, %f4701;
	mul.f32 	%f4718, %f2401, %f4702;
	mul.f32 	%f4719, %f2401, %f4703;
	mul.f32 	%f4720, %f2401, %f4704;
	mul.f32 	%f4721, %f2401, %f4705;
	mul.f32 	%f4722, %f2401, %f4706;
	mul.f32 	%f4723, %f2401, %f4707;
	mul.f32 	%f4724, %f2401, %f4708;
	mul.f32 	%f4725, %f2401, %f4709;
	mul.f32 	%f4726, %f2401, %f4710;
	mul.f32 	%f4727, %f2401, %f4711;
$L__tmp13:
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f4728, %f4712, %f4713;
	max.f32 	%f4729, %f4714, %f4715;
	max.f32 	%f4730, %f4728, %f4716;
	max.f32 	%f4731, %f4730, %f4717;
	max.f32 	%f4732, %f4729, %f4718;
	max.f32 	%f4733, %f4732, %f4719;
	max.f32 	%f4734, %f4720, %f4721;
	max.f32 	%f4735, %f4722, %f4723;
	max.f32 	%f4736, %f4734, %f4724;
	max.f32 	%f4737, %f4736, %f4725;
	max.f32 	%f4738, %f4735, %f4726;
	max.f32 	%f4739, %f4738, %f4727;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r3100, %f4731;
	shfl.sync.bfly.b32	%r3101, %r3100, 2, 31, -1;
	mov.b32 	%f4740, %r3101;
	mov.b32 	%r3102, %f4733;
	mov.b32 	%r3103, %f4737;
	mov.b32 	%r3104, %f4739;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f4741, %f4731, %f4740;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r3105, %f4741;
	shfl.sync.bfly.b32	%r3106, %r3105, 1, 31, -1;
	shfl.sync.bfly.b32	%r3107, %r3102, 2, 31, -1;
	mov.b32 	%f4742, %r3107;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f4743, %f4733, %f4742;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r3108, %f4743;
	shfl.sync.bfly.b32	%r3109, %r3108, 1, 31, -1;
	shfl.sync.bfly.b32	%r3110, %r3103, 2, 31, -1;
	mov.b32 	%f4744, %r3110;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f4745, %f4737, %f4744;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r3111, %f4745;
	shfl.sync.bfly.b32	%r3112, %r3111, 1, 31, -1;
	shfl.sync.bfly.b32	%r3113, %r3104, 2, 31, -1;
	mov.b32 	%f4746, %r3113;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f4747, %f4739, %f4746;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r3114, %f4747;
	shfl.sync.bfly.b32	%r3115, %r3114, 1, 31, -1;
	mov.b32 	%f4748, %r3115;
	mov.b32 	%f4749, %r3112;
	mov.b32 	%f4750, %r3109;
	mov.b32 	%f4751, %r3106;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f4752, %f4741, %f4751;
	max.f32 	%f4753, %f4743, %f4750;
	max.f32 	%f4754, %f4745, %f4749;
	max.f32 	%f4755, %f4747, %f4748;
$L__tmp14:
	.loc	1 190 31                        // prefix_prefill.py:190:31
	max.f32 	%f8519, %f860, %f4755;
	max.f32 	%f8518, %f859, %f4754;
	max.f32 	%f8517, %f858, %f4753;
	max.f32 	%f8516, %f857, %f4752;
	.loc	1 191 24                        // prefix_prefill.py:191:24
	neg.f32 	%f4756, %f8516;
	fma.rn.f32 	%f4757, %f2401, %f4696, %f4756;
	fma.rn.f32 	%f4758, %f2401, %f4697, %f4756;
	neg.f32 	%f4759, %f8517;
	fma.rn.f32 	%f4760, %f2401, %f4698, %f4759;
	fma.rn.f32 	%f4761, %f2401, %f4699, %f4759;
	fma.rn.f32 	%f4762, %f2401, %f4700, %f4756;
	fma.rn.f32 	%f4763, %f2401, %f4701, %f4756;
	fma.rn.f32 	%f4764, %f2401, %f4702, %f4759;
	fma.rn.f32 	%f4765, %f2401, %f4703, %f4759;
	neg.f32 	%f4766, %f8518;
	fma.rn.f32 	%f4767, %f2401, %f4704, %f4766;
	fma.rn.f32 	%f4768, %f2401, %f4705, %f4766;
	neg.f32 	%f4769, %f8519;
	fma.rn.f32 	%f4770, %f2401, %f4706, %f4769;
	fma.rn.f32 	%f4771, %f2401, %f4707, %f4769;
	fma.rn.f32 	%f4772, %f2401, %f4708, %f4766;
	fma.rn.f32 	%f4773, %f2401, %f4709, %f4766;
	fma.rn.f32 	%f4774, %f2401, %f4710, %f4769;
	fma.rn.f32 	%f4775, %f2401, %f4711, %f4769;
	.loc	1 191 19                        // prefix_prefill.py:191:19
	mul.f32 	%f4657, %f4757, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4656, %f4657;
	// end inline asm
	mul.f32 	%f4659, %f4758, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4658, %f4659;
	// end inline asm
	mul.f32 	%f4661, %f4760, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4660, %f4661;
	// end inline asm
	mul.f32 	%f4663, %f4761, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4662, %f4663;
	// end inline asm
	mul.f32 	%f4665, %f4762, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4664, %f4665;
	// end inline asm
	mul.f32 	%f4667, %f4763, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4666, %f4667;
	// end inline asm
	mul.f32 	%f4669, %f4764, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4668, %f4669;
	// end inline asm
	mul.f32 	%f4671, %f4765, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4670, %f4671;
	// end inline asm
	mul.f32 	%f4673, %f4767, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4672, %f4673;
	// end inline asm
	mul.f32 	%f4675, %f4768, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4674, %f4675;
	// end inline asm
	mul.f32 	%f4677, %f4770, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4676, %f4677;
	// end inline asm
	mul.f32 	%f4679, %f4771, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4678, %f4679;
	// end inline asm
	mul.f32 	%f4681, %f4772, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4680, %f4681;
	// end inline asm
	mul.f32 	%f4683, %f4773, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4682, %f4683;
	// end inline asm
	mul.f32 	%f4685, %f4774, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4684, %f4685;
	// end inline asm
	mul.f32 	%f4687, %f4775, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4686, %f4687;
	// end inline asm
$L__tmp15:
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f4776, %f4656, %f4658;
	add.f32 	%f4777, %f4660, %f4662;
	add.f32 	%f4778, %f4776, %f4664;
	add.f32 	%f4779, %f4778, %f4666;
	add.f32 	%f4780, %f4777, %f4668;
	add.f32 	%f4781, %f4780, %f4670;
	add.f32 	%f4782, %f4672, %f4674;
	add.f32 	%f4783, %f4676, %f4678;
	add.f32 	%f4784, %f4782, %f4680;
	add.f32 	%f4785, %f4784, %f4682;
	add.f32 	%f4786, %f4783, %f4684;
	add.f32 	%f4787, %f4786, %f4686;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r3116, %f4779;
	shfl.sync.bfly.b32	%r3117, %r3116, 2, 31, -1;
	mov.b32 	%f4788, %r3117;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f4789, %f4779, %f4788;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r3118, %f4789;
	shfl.sync.bfly.b32	%r3119, %r3118, 1, 31, -1;
	mov.b32 	%r3120, %f4781;
	shfl.sync.bfly.b32	%r3121, %r3120, 2, 31, -1;
	mov.b32 	%f4790, %r3121;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f4791, %f4781, %f4790;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r3122, %f4791;
	shfl.sync.bfly.b32	%r3123, %r3122, 1, 31, -1;
	mov.b32 	%r3124, %f4785;
	shfl.sync.bfly.b32	%r3125, %r3124, 2, 31, -1;
	mov.b32 	%f4792, %r3125;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f4793, %f4785, %f4792;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r3126, %f4793;
	shfl.sync.bfly.b32	%r3127, %r3126, 1, 31, -1;
	mov.b32 	%r3128, %f4787;
	shfl.sync.bfly.b32	%r3129, %r3128, 2, 31, -1;
	mov.b32 	%f4794, %r3129;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f4795, %f4787, %f4794;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r3130, %f4795;
	shfl.sync.bfly.b32	%r3131, %r3130, 1, 31, -1;
	mov.b32 	%f4796, %r3131;
	mov.b32 	%f4797, %r3127;
	mov.b32 	%f4798, %r3123;
	mov.b32 	%f4799, %r3119;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f1169, %f4789, %f4799;
	add.f32 	%f1170, %f4791, %f4798;
	add.f32 	%f1171, %f4793, %f4797;
	add.f32 	%f1172, %f4795, %f4796;
$L__tmp16:
	.loc	1 193 29                        // prefix_prefill.py:193:29
	sub.f32 	%f4800, %f857, %f8516;
	sub.f32 	%f4801, %f858, %f8517;
	sub.f32 	%f4802, %f859, %f8518;
	sub.f32 	%f4803, %f860, %f8519;
	.loc	1 193 23                        // prefix_prefill.py:193:23
	mul.f32 	%f4689, %f4800, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4688, %f4689;
	// end inline asm
	mul.f32 	%f4691, %f4801, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4690, %f4691;
	// end inline asm
	mul.f32 	%f4693, %f4802, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4692, %f4693;
	// end inline asm
	mul.f32 	%f4695, %f4803, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f4694, %f4695;
	// end inline asm
	.loc	1 194 20                        // prefix_prefill.py:194:20
	mul.f32 	%f8524, %f4144, %f4688;
	mul.f32 	%f8525, %f4145, %f4688;
	mul.f32 	%f8526, %f4146, %f4690;
	mul.f32 	%f8527, %f4147, %f4690;
	mul.f32 	%f8528, %f4152, %f4688;
	mul.f32 	%f8529, %f4153, %f4688;
	mul.f32 	%f8530, %f4154, %f4690;
	mul.f32 	%f8531, %f4155, %f4690;
	mul.f32 	%f8532, %f4160, %f4688;
	mul.f32 	%f8533, %f4161, %f4688;
	mul.f32 	%f8534, %f4162, %f4690;
	mul.f32 	%f8535, %f4163, %f4690;
	mul.f32 	%f8536, %f4168, %f4688;
	mul.f32 	%f8537, %f4169, %f4688;
	mul.f32 	%f8538, %f4170, %f4690;
	mul.f32 	%f8539, %f4171, %f4690;
	mul.f32 	%f8540, %f4176, %f4688;
	mul.f32 	%f8541, %f4177, %f4688;
	mul.f32 	%f8542, %f4178, %f4690;
	mul.f32 	%f8543, %f4179, %f4690;
	mul.f32 	%f8544, %f4184, %f4688;
	mul.f32 	%f8545, %f4185, %f4688;
	mul.f32 	%f8546, %f4186, %f4690;
	mul.f32 	%f8547, %f4187, %f4690;
	mul.f32 	%f8548, %f4192, %f4688;
	mul.f32 	%f8549, %f4193, %f4688;
	mul.f32 	%f8550, %f4194, %f4690;
	mul.f32 	%f8551, %f4195, %f4690;
	mul.f32 	%f8552, %f4200, %f4688;
	mul.f32 	%f8553, %f4201, %f4688;
	mul.f32 	%f8554, %f4202, %f4690;
	mul.f32 	%f8555, %f4203, %f4690;
	mul.f32 	%f8556, %f4208, %f4688;
	mul.f32 	%f8557, %f4209, %f4688;
	mul.f32 	%f8558, %f4210, %f4690;
	mul.f32 	%f8559, %f4211, %f4690;
	mul.f32 	%f8560, %f4216, %f4688;
	mul.f32 	%f8561, %f4217, %f4688;
	mul.f32 	%f8562, %f4218, %f4690;
	mul.f32 	%f8563, %f4219, %f4690;
	mul.f32 	%f8564, %f4224, %f4688;
	mul.f32 	%f8565, %f4225, %f4688;
	mul.f32 	%f8566, %f4226, %f4690;
	mul.f32 	%f8567, %f4227, %f4690;
	mul.f32 	%f8568, %f4232, %f4688;
	mul.f32 	%f8569, %f4233, %f4688;
	mul.f32 	%f8570, %f4234, %f4690;
	mul.f32 	%f8571, %f4235, %f4690;
	mul.f32 	%f8572, %f4240, %f4688;
	mul.f32 	%f8573, %f4241, %f4688;
	mul.f32 	%f8574, %f4242, %f4690;
	mul.f32 	%f8575, %f4243, %f4690;
	mul.f32 	%f8576, %f4248, %f4688;
	mul.f32 	%f8577, %f4249, %f4688;
	mul.f32 	%f8578, %f4250, %f4690;
	mul.f32 	%f8579, %f4251, %f4690;
	mul.f32 	%f8580, %f4256, %f4688;
	mul.f32 	%f8581, %f4257, %f4688;
	mul.f32 	%f8582, %f4258, %f4690;
	mul.f32 	%f8583, %f4259, %f4690;
	mul.f32 	%f8584, %f4264, %f4688;
	mul.f32 	%f8585, %f4265, %f4688;
	mul.f32 	%f8586, %f4266, %f4690;
	mul.f32 	%f8587, %f4267, %f4690;
	mul.f32 	%f8588, %f4272, %f4692;
	mul.f32 	%f8589, %f4273, %f4692;
	mul.f32 	%f8590, %f4274, %f4694;
	mul.f32 	%f8591, %f4275, %f4694;
	mul.f32 	%f8592, %f4280, %f4692;
	mul.f32 	%f8593, %f4281, %f4692;
	mul.f32 	%f8594, %f4282, %f4694;
	mul.f32 	%f8595, %f4283, %f4694;
	mul.f32 	%f8596, %f4288, %f4692;
	mul.f32 	%f8597, %f4289, %f4692;
	mul.f32 	%f8598, %f4290, %f4694;
	mul.f32 	%f8599, %f4291, %f4694;
	mul.f32 	%f8600, %f4296, %f4692;
	mul.f32 	%f8601, %f4297, %f4692;
	mul.f32 	%f8602, %f4298, %f4694;
	mul.f32 	%f8603, %f4299, %f4694;
	mul.f32 	%f8604, %f4304, %f4692;
	mul.f32 	%f8605, %f4305, %f4692;
	mul.f32 	%f8606, %f4306, %f4694;
	mul.f32 	%f8607, %f4307, %f4694;
	mul.f32 	%f8608, %f4312, %f4692;
	mul.f32 	%f8609, %f4313, %f4692;
	mul.f32 	%f8610, %f4314, %f4694;
	mul.f32 	%f8611, %f4315, %f4694;
	mul.f32 	%f8612, %f4320, %f4692;
	mul.f32 	%f8613, %f4321, %f4692;
	mul.f32 	%f8614, %f4322, %f4694;
	mul.f32 	%f8615, %f4323, %f4694;
	mul.f32 	%f8616, %f4328, %f4692;
	mul.f32 	%f8617, %f4329, %f4692;
	mul.f32 	%f8618, %f4330, %f4694;
	mul.f32 	%f8619, %f4331, %f4694;
	mul.f32 	%f8620, %f4336, %f4692;
	mul.f32 	%f8621, %f4337, %f4692;
	mul.f32 	%f8622, %f4338, %f4694;
	mul.f32 	%f8623, %f4339, %f4694;
	mul.f32 	%f8624, %f4344, %f4692;
	mul.f32 	%f8625, %f4345, %f4692;
	mul.f32 	%f8626, %f4346, %f4694;
	mul.f32 	%f8627, %f4347, %f4694;
	mul.f32 	%f8628, %f4352, %f4692;
	mul.f32 	%f8629, %f4353, %f4692;
	mul.f32 	%f8630, %f4354, %f4694;
	mul.f32 	%f8631, %f4355, %f4694;
	mul.f32 	%f8632, %f4360, %f4692;
	mul.f32 	%f8633, %f4361, %f4692;
	mul.f32 	%f8634, %f4362, %f4694;
	mul.f32 	%f8635, %f4363, %f4694;
	mul.f32 	%f8636, %f4368, %f4692;
	mul.f32 	%f8637, %f4369, %f4692;
	mul.f32 	%f8638, %f4370, %f4694;
	mul.f32 	%f8639, %f4371, %f4694;
	mul.f32 	%f8640, %f4376, %f4692;
	mul.f32 	%f8641, %f4377, %f4692;
	mul.f32 	%f8642, %f4378, %f4694;
	mul.f32 	%f8643, %f4379, %f4694;
	mul.f32 	%f8644, %f4384, %f4692;
	mul.f32 	%f8645, %f4385, %f4692;
	mul.f32 	%f8646, %f4386, %f4694;
	mul.f32 	%f8647, %f4387, %f4694;
	mul.f32 	%f8648, %f4392, %f4692;
	mul.f32 	%f8649, %f4393, %f4692;
	mul.f32 	%f8650, %f4394, %f4694;
	mul.f32 	%f8651, %f4395, %f4694;
	mul.wide.s32 	%rd534, %r437, 2;
	mul.wide.s32 	%rd535, %r445, 2;
	.loc	1 197 11                        // prefix_prefill.py:197:11
	@%p245 bra 	$L__BB0_29;
	bra.uni 	$L__BB0_28;
$L__BB0_29:                             //   in Loop: Header=BB0_2 Depth=1
	.loc	1 205 39                        // prefix_prefill.py:205:39
	add.s64 	%rd298, %rd111, %rd534;
	add.s64 	%rd299, %rd111, %rd535;
	.loc	1 205 29                        // prefix_prefill.py:205:29
	// begin inline asm
	mov.u32 %r7383, 0x0;
	mov.u32 %r7384, 0x0;
	mov.u32 %r7385, 0x0;
	mov.u32 %r7386, 0x0;
	@%p546 ld.global.v4.b32 { %r7383, %r7384, %r7385, %r7386 }, [ %rd298 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r7387, 0x0;
	mov.u32 %r7388, 0x0;
	mov.u32 %r7389, 0x0;
	mov.u32 %r7390, 0x0;
	@%p546 ld.global.v4.b32 { %r7387, %r7388, %r7389, %r7390 }, [ %rd299 + 0 ];
	// end inline asm
	bra.uni 	$L__BB0_30;
$L__BB0_4:                              // %.preheader
	.loc	1 135 28                        // prefix_prefill.py:135:28
	setp.ge.s32 	%p298, %r7391, %r5;
	@%p298 bra 	$L__BB0_36;
// %bb.5:                               // %.lr.ph727
	.loc	1 0 28                          // prefix_prefill.py:0:28
	add.s32 	%r3415, %r912, 32768;
	add.s32 	%r118, %r3415, %r911;
	and.b32  	%r3420, %r7316, 6;
	or.b32  	%r3421, %r3420, %r7314;
	xor.b32  	%r3422, %r7315, %r7313;
	shl.b32 	%r3423, %r3422, 4;
	shl.b32 	%r3424, %r3421, 11;
	shl.b32 	%r3425, %r7313, 8;
	or.b32  	%r3426, %r3424, %r3425;
	or.b32  	%r3427, %r3423, %r3426;
	add.s32 	%r3545, %r912, %r3427;
	or.b32  	%r3428, %r7315, 2;
	xor.b32  	%r3429, %r3428, %r7313;
	shl.b32 	%r3430, %r3429, 4;
	or.b32  	%r3431, %r3430, %r3426;
	add.s32 	%r3550, %r912, %r3431;
	or.b32  	%r3432, %r7315, 4;
	xor.b32  	%r3433, %r3432, %r7313;
	shl.b32 	%r3434, %r3433, 4;
	or.b32  	%r3435, %r3434, %r3426;
	add.s32 	%r3555, %r912, %r3435;
	or.b32  	%r3436, %r7315, 6;
	xor.b32  	%r3437, %r3436, %r7313;
	shl.b32 	%r3438, %r3437, 4;
	or.b32  	%r3439, %r3438, %r3426;
	add.s32 	%r3560, %r912, %r3439;
	or.b32  	%r3440, %r7315, 8;
	xor.b32  	%r3441, %r3440, %r7313;
	shl.b32 	%r3442, %r3441, 4;
	or.b32  	%r3443, %r3442, %r3426;
	add.s32 	%r3565, %r912, %r3443;
	or.b32  	%r3444, %r7315, 10;
	xor.b32  	%r3445, %r3444, %r7313;
	shl.b32 	%r3446, %r3445, 4;
	or.b32  	%r3447, %r3446, %r3426;
	add.s32 	%r3570, %r912, %r3447;
	or.b32  	%r3448, %r7315, 12;
	xor.b32  	%r3449, %r3448, %r7313;
	shl.b32 	%r3450, %r3449, 4;
	or.b32  	%r3451, %r3450, %r3426;
	add.s32 	%r3575, %r912, %r3451;
	or.b32  	%r3452, %r7315, 14;
	xor.b32  	%r3453, %r3452, %r7313;
	shl.b32 	%r3454, %r3453, 4;
	or.b32  	%r3455, %r3454, %r3426;
	add.s32 	%r3580, %r912, %r3455;
	add.s32 	%r3585, %r3545, 16384;
	add.s32 	%r3590, %r3550, 16384;
	add.s32 	%r3595, %r3555, 16384;
	add.s32 	%r3600, %r3560, 16384;
	add.s32 	%r3605, %r3565, 16384;
	add.s32 	%r3610, %r3570, 16384;
	add.s32 	%r3615, %r3575, 16384;
	add.s32 	%r3620, %r3580, 16384;
	shl.b32 	%r3456, %r7315, 3;
	or.b32  	%r3457, %r3456, %r7313;
	xor.b32  	%r3458, %r7314, %r7313;
	shl.b32 	%r3459, %r3458, 4;
	shl.b32 	%r3460, %r3457, 8;
	or.b32  	%r3461, %r3460, %r3459;
	add.s32 	%r3625, %r3415, %r3461;
	or.b32  	%r3462, %r7314, 2;
	xor.b32  	%r3463, %r3462, %r7313;
	shl.b32 	%r3464, %r3463, 4;
	or.b32  	%r3465, %r3464, %r3460;
	add.s32 	%r3630, %r3415, %r3465;
	or.b32  	%r3466, %r7314, 4;
	xor.b32  	%r3467, %r3466, %r7313;
	shl.b32 	%r3468, %r3467, 4;
	or.b32  	%r3469, %r3468, %r3460;
	add.s32 	%r3635, %r3415, %r3469;
	or.b32  	%r3470, %r7314, 6;
	xor.b32  	%r3471, %r3470, %r7313;
	shl.b32 	%r3472, %r3471, 4;
	or.b32  	%r3473, %r3472, %r3460;
	add.s32 	%r3640, %r3415, %r3473;
	or.b32  	%r3474, %r7314, 8;
	xor.b32  	%r3475, %r3474, %r7313;
	shl.b32 	%r3476, %r3475, 4;
	or.b32  	%r3477, %r3476, %r3460;
	add.s32 	%r3645, %r3415, %r3477;
	or.b32  	%r3478, %r7314, 10;
	xor.b32  	%r3479, %r3478, %r7313;
	shl.b32 	%r3480, %r3479, 4;
	or.b32  	%r3481, %r3480, %r3460;
	add.s32 	%r3650, %r3415, %r3481;
	or.b32  	%r3482, %r7314, 12;
	xor.b32  	%r3483, %r3482, %r7313;
	shl.b32 	%r3484, %r3483, 4;
	or.b32  	%r3485, %r3484, %r3460;
	add.s32 	%r3655, %r3415, %r3485;
	or.b32  	%r3486, %r7314, 14;
	xor.b32  	%r3487, %r3486, %r7313;
	shl.b32 	%r3488, %r3487, 4;
	or.b32  	%r3489, %r3488, %r3460;
	add.s32 	%r3660, %r3415, %r3489;
	shl.b32 	%r3491, %r7317, 1;
	or.b32  	%r3493, %r7318, %r3491;
	add.s32 	%r143, %r3415, %r3493;
	add.s32 	%r144, %r143, 2048;
	xor.b32  	%r3495, %r7314, %r7319;
	shl.b32 	%r3496, %r3495, 4;
	shl.b32 	%r3497, %r3457, 5;
	or.b32  	%r3498, %r3497, %r3496;
	add.s32 	%r3933, %r3415, %r3498;
	add.s32 	%r3938, %r3933, 512;
	add.s32 	%r3943, %r3933, 1024;
	add.s32 	%r3948, %r3933, 1536;
	add.s32 	%r3953, %r3933, 2048;
	add.s32 	%r3958, %r3933, 2560;
	add.s32 	%r3963, %r3933, 3072;
	add.s32 	%r3968, %r3933, 3584;
	mov.f32 	%f8656, %f8516;
	mov.f32 	%f8657, %f8517;
	mov.f32 	%f8658, %f8518;
	mov.f32 	%f8659, %f8519;
	bra.uni 	$L__BB0_6;
$L__BB0_34:                             //   in Loop: Header=BB0_6 Depth=1
	.loc	1 205 39                        // prefix_prefill.py:205:39
	mul.wide.s32 	%rd346, %r511, 2;
	add.s64 	%rd344, %rd111, %rd346;
	mul.wide.s32 	%rd347, %r519, 2;
	add.s64 	%rd345, %rd111, %rd347;
	.loc	1 205 29                        // prefix_prefill.py:205:29
	// begin inline asm
	mov.u32 %r7400, 0x0;
	mov.u32 %r7401, 0x0;
	mov.u32 %r7402, 0x0;
	mov.u32 %r7403, 0x0;
	@%p546 ld.global.v4.b32 { %r7400, %r7401, %r7402, %r7403 }, [ %rd344 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r7404, 0x0;
	mov.u32 %r7405, 0x0;
	mov.u32 %r7406, 0x0;
	mov.u32 %r7407, 0x0;
	@%p546 ld.global.v4.b32 { %r7404, %r7405, %r7406, %r7407 }, [ %rd345 + 0 ];
	// end inline asm
$L__BB0_35:                             //   in Loop: Header=BB0_6 Depth=1
	.loc	1 197 11                        // prefix_prefill.py:197:11
	bar.sync 	0;
	st.shared.v4.b32 	[%r143], {%r7400, %r7401, %r7402, %r7403};
	st.shared.v4.b32 	[%r144], {%r7404, %r7405, %r7406, %r7407};
	.loc	1 211 17                        // prefix_prefill.py:211:17
	mov.b32 	%r3913, %f5316;
	// begin inline asm
	cvt.rn.bf16.f32 %rs289, %r3913;
	// end inline asm
	mov.b32 	%r3914, %f5318;
	// begin inline asm
	cvt.rn.bf16.f32 %rs290, %r3914;
	// end inline asm
	mov.b32 	%r3915, %f5320;
	// begin inline asm
	cvt.rn.bf16.f32 %rs291, %r3915;
	// end inline asm
	mov.b32 	%r3916, %f5322;
	// begin inline asm
	cvt.rn.bf16.f32 %rs292, %r3916;
	// end inline asm
	mov.b32 	%r3917, %f5324;
	// begin inline asm
	cvt.rn.bf16.f32 %rs293, %r3917;
	// end inline asm
	mov.b32 	%r3918, %f5326;
	// begin inline asm
	cvt.rn.bf16.f32 %rs294, %r3918;
	// end inline asm
	mov.b32 	%r3919, %f5328;
	// begin inline asm
	cvt.rn.bf16.f32 %rs295, %r3919;
	// end inline asm
	mov.b32 	%r3920, %f5330;
	// begin inline asm
	cvt.rn.bf16.f32 %rs296, %r3920;
	// end inline asm
	mov.b32 	%r3921, %f5332;
	// begin inline asm
	cvt.rn.bf16.f32 %rs297, %r3921;
	// end inline asm
	mov.b32 	%r3922, %f5334;
	// begin inline asm
	cvt.rn.bf16.f32 %rs298, %r3922;
	// end inline asm
	mov.b32 	%r3923, %f5336;
	// begin inline asm
	cvt.rn.bf16.f32 %rs299, %r3923;
	// end inline asm
	mov.b32 	%r3924, %f5338;
	// begin inline asm
	cvt.rn.bf16.f32 %rs300, %r3924;
	// end inline asm
	mov.b32 	%r3925, %f5340;
	// begin inline asm
	cvt.rn.bf16.f32 %rs301, %r3925;
	// end inline asm
	mov.b32 	%r3926, %f5342;
	// begin inline asm
	cvt.rn.bf16.f32 %rs302, %r3926;
	// end inline asm
	mov.b32 	%r3927, %f5344;
	// begin inline asm
	cvt.rn.bf16.f32 %rs303, %r3927;
	// end inline asm
	mov.b32 	%r3928, %f5346;
	// begin inline asm
	cvt.rn.bf16.f32 %rs304, %r3928;
	// end inline asm
	mov.b32 	%r3969, {%rs289, %rs290};
	mov.b32 	%r3970, {%rs291, %rs292};
	mov.b32 	%r3971, {%rs293, %rs294};
	mov.b32 	%r3972, {%rs295, %rs296};
	mov.b32 	%r4065, {%rs297, %rs298};
	mov.b32 	%r4066, {%rs299, %rs300};
	mov.b32 	%r4067, {%rs301, %rs302};
	mov.b32 	%r4068, {%rs303, %rs304};
	.loc	1 197 11                        // prefix_prefill.py:197:11
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3973, %r3974, %r3979, %r3980 }, [ %r3933 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3985, %r3986, %r3991, %r3992 }, [ %r3938 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3997, %r3998, %r4003, %r4004 }, [ %r3943 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4009, %r4010, %r4015, %r4016 }, [ %r3948 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4021, %r4022, %r4027, %r4028 }, [ %r3953 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4033, %r4034, %r4039, %r4040 }, [ %r3958 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4045, %r4046, %r4051, %r4052 }, [ %r3963 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4057, %r4058, %r4063, %r4064 }, [ %r3968 + 0 ];
	// end inline asm
	.loc	1 213 24                        // prefix_prefill.py:213:24
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8524, %f8525, %f8526, %f8527 }, { %r3969, %r3970, %r3971, %r3972 }, { %r3973, %r3974 }, { %f8524, %f8525, %f8526, %f8527 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8528, %f8529, %f8530, %f8531 }, { %r3969, %r3970, %r3971, %r3972 }, { %r3979, %r3980 }, { %f8528, %f8529, %f8530, %f8531 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8532, %f8533, %f8534, %f8535 }, { %r3969, %r3970, %r3971, %r3972 }, { %r3985, %r3986 }, { %f8532, %f8533, %f8534, %f8535 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8536, %f8537, %f8538, %f8539 }, { %r3969, %r3970, %r3971, %r3972 }, { %r3991, %r3992 }, { %f8536, %f8537, %f8538, %f8539 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8540, %f8541, %f8542, %f8543 }, { %r3969, %r3970, %r3971, %r3972 }, { %r3997, %r3998 }, { %f8540, %f8541, %f8542, %f8543 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8544, %f8545, %f8546, %f8547 }, { %r3969, %r3970, %r3971, %r3972 }, { %r4003, %r4004 }, { %f8544, %f8545, %f8546, %f8547 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8548, %f8549, %f8550, %f8551 }, { %r3969, %r3970, %r3971, %r3972 }, { %r4009, %r4010 }, { %f8548, %f8549, %f8550, %f8551 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8552, %f8553, %f8554, %f8555 }, { %r3969, %r3970, %r3971, %r3972 }, { %r4015, %r4016 }, { %f8552, %f8553, %f8554, %f8555 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8556, %f8557, %f8558, %f8559 }, { %r3969, %r3970, %r3971, %r3972 }, { %r4021, %r4022 }, { %f8556, %f8557, %f8558, %f8559 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8560, %f8561, %f8562, %f8563 }, { %r3969, %r3970, %r3971, %r3972 }, { %r4027, %r4028 }, { %f8560, %f8561, %f8562, %f8563 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8564, %f8565, %f8566, %f8567 }, { %r3969, %r3970, %r3971, %r3972 }, { %r4033, %r4034 }, { %f8564, %f8565, %f8566, %f8567 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8568, %f8569, %f8570, %f8571 }, { %r3969, %r3970, %r3971, %r3972 }, { %r4039, %r4040 }, { %f8568, %f8569, %f8570, %f8571 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8572, %f8573, %f8574, %f8575 }, { %r3969, %r3970, %r3971, %r3972 }, { %r4045, %r4046 }, { %f8572, %f8573, %f8574, %f8575 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8576, %f8577, %f8578, %f8579 }, { %r3969, %r3970, %r3971, %r3972 }, { %r4051, %r4052 }, { %f8576, %f8577, %f8578, %f8579 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8580, %f8581, %f8582, %f8583 }, { %r3969, %r3970, %r3971, %r3972 }, { %r4057, %r4058 }, { %f8580, %f8581, %f8582, %f8583 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8584, %f8585, %f8586, %f8587 }, { %r3969, %r3970, %r3971, %r3972 }, { %r4063, %r4064 }, { %f8584, %f8585, %f8586, %f8587 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8588, %f8589, %f8590, %f8591 }, { %r4065, %r4066, %r4067, %r4068 }, { %r3973, %r3974 }, { %f8588, %f8589, %f8590, %f8591 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8592, %f8593, %f8594, %f8595 }, { %r4065, %r4066, %r4067, %r4068 }, { %r3979, %r3980 }, { %f8592, %f8593, %f8594, %f8595 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8596, %f8597, %f8598, %f8599 }, { %r4065, %r4066, %r4067, %r4068 }, { %r3985, %r3986 }, { %f8596, %f8597, %f8598, %f8599 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8600, %f8601, %f8602, %f8603 }, { %r4065, %r4066, %r4067, %r4068 }, { %r3991, %r3992 }, { %f8600, %f8601, %f8602, %f8603 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8604, %f8605, %f8606, %f8607 }, { %r4065, %r4066, %r4067, %r4068 }, { %r3997, %r3998 }, { %f8604, %f8605, %f8606, %f8607 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8608, %f8609, %f8610, %f8611 }, { %r4065, %r4066, %r4067, %r4068 }, { %r4003, %r4004 }, { %f8608, %f8609, %f8610, %f8611 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8612, %f8613, %f8614, %f8615 }, { %r4065, %r4066, %r4067, %r4068 }, { %r4009, %r4010 }, { %f8612, %f8613, %f8614, %f8615 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8616, %f8617, %f8618, %f8619 }, { %r4065, %r4066, %r4067, %r4068 }, { %r4015, %r4016 }, { %f8616, %f8617, %f8618, %f8619 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8620, %f8621, %f8622, %f8623 }, { %r4065, %r4066, %r4067, %r4068 }, { %r4021, %r4022 }, { %f8620, %f8621, %f8622, %f8623 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8624, %f8625, %f8626, %f8627 }, { %r4065, %r4066, %r4067, %r4068 }, { %r4027, %r4028 }, { %f8624, %f8625, %f8626, %f8627 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8628, %f8629, %f8630, %f8631 }, { %r4065, %r4066, %r4067, %r4068 }, { %r4033, %r4034 }, { %f8628, %f8629, %f8630, %f8631 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8632, %f8633, %f8634, %f8635 }, { %r4065, %r4066, %r4067, %r4068 }, { %r4039, %r4040 }, { %f8632, %f8633, %f8634, %f8635 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8636, %f8637, %f8638, %f8639 }, { %r4065, %r4066, %r4067, %r4068 }, { %r4045, %r4046 }, { %f8636, %f8637, %f8638, %f8639 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8640, %f8641, %f8642, %f8643 }, { %r4065, %r4066, %r4067, %r4068 }, { %r4051, %r4052 }, { %f8640, %f8641, %f8642, %f8643 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8644, %f8645, %f8646, %f8647 }, { %r4065, %r4066, %r4067, %r4068 }, { %r4057, %r4058 }, { %f8644, %f8645, %f8646, %f8647 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8648, %f8649, %f8650, %f8651 }, { %r4065, %r4066, %r4067, %r4068 }, { %r4063, %r4064 }, { %f8648, %f8649, %f8650, %f8651 };
	// end inline asm
	.loc	1 215 28                        // prefix_prefill.py:215:28
	fma.rn.f32 	%f8788, %f8788, %f5348, %f1593;
	fma.rn.f32 	%f8789, %f8789, %f5350, %f1594;
	fma.rn.f32 	%f8790, %f8790, %f5352, %f1595;
	fma.rn.f32 	%f8791, %f8791, %f5354, %f1596;
	.loc	1 135 28                        // prefix_prefill.py:135:28
	setp.lt.s32 	%p352, %r527, %r5;
	mov.u32 	%r7391, %r527;
	mov.f32 	%f8656, %f8516;
	mov.f32 	%f8657, %f8517;
	mov.f32 	%f8658, %f8518;
	mov.f32 	%f8659, %f8519;
	@%p352 bra 	$L__BB0_6;
	bra.uni 	$L__BB0_36;
$L__BB0_6:                              // =>This Inner Loop Header: Depth=1
	.loc	1 139 33                        // prefix_prefill.py:139:33
	shr.s32 	%r3500, %r7391, 4;
	.loc	1 139 21                        // prefix_prefill.py:139:21
	mul.wide.s32 	%rd335, %r3500, 4;
	add.s64 	%rd334, %rd1, %rd335;
	.loc	1 138 21                        // prefix_prefill.py:138:21
	// begin inline asm
	mov.u32 %r3499, 0x0;
	@%p546 ld.global.b32 { %r3499 }, [ %rd334 + 0 ];
	// end inline asm
	.loc	1 143 12                        // prefix_prefill.py:143:12
	mad.lo.s32 	%r3501, %r3499, %r672, %r7312;
	.loc	1 144 24                        // prefix_prefill.py:144:24
	add.s32 	%r503, %r12, %r7391;
	add.s32 	%r504, %r503, 8;
	add.s32 	%r505, %r68, %r7391;
	add.s32 	%r506, %r505, 1;
	add.s32 	%r507, %r505, 8;
	.loc	1 144 46                        // prefix_prefill.py:144:46
	add.s32 	%r508, %r505, 9;
	shr.s32 	%r3502, %r503, 31;
	shr.u32 	%r3503, %r3502, 28;
	add.s32 	%r3504, %r503, %r3503;
	and.b32  	%r3505, %r3504, 536870896;
	sub.s32 	%r3506, %r503, %r3505;
	shr.s32 	%r3507, %r504, 31;
	shr.u32 	%r3508, %r3507, 28;
	add.s32 	%r3509, %r504, %r3508;
	and.b32  	%r3510, %r3509, 536870896;
	sub.s32 	%r3511, %r504, %r3510;
	.loc	1 144 60                        // prefix_prefill.py:144:60
	shl.b32 	%r3512, %r3506, 3;
	shl.b32 	%r3513, %r3511, 3;
	.loc	1 144 12                        // prefix_prefill.py:144:12
	add.s32 	%r509, %r3501, %r3512;
	add.s32 	%r510, %r3501, %r3513;
	.loc	1 148 31                        // prefix_prefill.py:148:31
	mul.lo.s32 	%r3514, %r3499, %r673;
	add.s32 	%r3515, %r3514, %r78;
	add.s32 	%r3516, %r3514, %r79;
	.loc	1 153 21                        // prefix_prefill.py:153:21
	add.s32 	%r527, %r7391, 16;
	.loc	1 153 34                        // prefix_prefill.py:153:34
	setp.le.s32 	%p300, %r527, %r5;
	@%p300 bra 	$L__BB0_31;
// %bb.7:                               //   in Loop: Header=BB0_6 Depth=1
	.loc	1 158 50                        // prefix_prefill.py:158:50
	setp.lt.s32 	%p303, %r503, %r5;
	setp.lt.s32 	%p308, %r504, %r5;
	.loc	1 156 26                        // prefix_prefill.py:156:26
	mul.wide.s32 	%rd342, %r509, 2;
	add.s64 	%rd340, %rd110, %rd342;
	mul.wide.s32 	%rd343, %r510, 2;
	add.s64 	%rd341, %rd110, %rd343;
	.loc	1 156 16                        // prefix_prefill.py:156:16
	// begin inline asm
	mov.u32 %r7398, 0x0;
	mov.u32 %r7399, 0x0;
	mov.u32 %r7396, 0x0;
	mov.u32 %r7397, 0x0;
	@%p303 ld.global.v4.b32 { %r7398, %r7399, %r7396, %r7397 }, [ %rd340 + 0 ];
	@!%p303 mov.u32 %r7398, %r684;
	@!%p303 mov.u32 %r7399, %r684;
	@!%p303 mov.u32 %r7396, %r684;
	@!%p303 mov.u32 %r7397, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r7392, 0x0;
	mov.u32 %r7393, 0x0;
	mov.u32 %r7394, 0x0;
	mov.u32 %r7395, 0x0;
	@%p308 ld.global.v4.b32 { %r7392, %r7393, %r7394, %r7395 }, [ %rd341 + 0 ];
	@!%p308 mov.u32 %r7392, %r684;
	@!%p308 mov.u32 %r7393, %r684;
	@!%p308 mov.u32 %r7394, %r684;
	@!%p308 mov.u32 %r7395, %r684;
	// end inline asm
	.loc	1 153 11                        // prefix_prefill.py:153:11
	bra.uni 	$L__BB0_32;
$L__BB0_31:                             //   in Loop: Header=BB0_6 Depth=1
	.loc	1 161 39                        // prefix_prefill.py:161:39
	mul.wide.s32 	%rd338, %r509, 2;
	add.s64 	%rd336, %rd110, %rd338;
	mul.wide.s32 	%rd339, %r510, 2;
	add.s64 	%rd337, %rd110, %rd339;
	.loc	1 161 29                        // prefix_prefill.py:161:29
	// begin inline asm
	mov.u32 %r7398, 0x0;
	mov.u32 %r7399, 0x0;
	mov.u32 %r7396, 0x0;
	mov.u32 %r7397, 0x0;
	@%p546 ld.global.v4.b32 { %r7398, %r7399, %r7396, %r7397 }, [ %rd336 + 0 ];
	// end inline asm
	// begin inline asm
	mov.u32 %r7392, 0x0;
	mov.u32 %r7393, 0x0;
	mov.u32 %r7394, 0x0;
	mov.u32 %r7395, 0x0;
	@%p546 ld.global.v4.b32 { %r7392, %r7393, %r7394, %r7395 }, [ %rd337 + 0 ];
	// end inline asm
$L__BB0_32:                             //   in Loop: Header=BB0_6 Depth=1
	.loc	1 0 0                           // prefix_prefill.py:0:0
	add.s32 	%r511, %r3515, %r21;
	add.s32 	%r519, %r3516, %r21;
	.loc	1 153 11                        // prefix_prefill.py:153:11
	bar.sync 	0;
	st.shared.v4.b32 	[%r118], {%r7398, %r7399, %r7396, %r7397};
	st.shared.v4.b32 	[%r118+2048], {%r7392, %r7393, %r7394, %r7395};
	.loc	1 123 16                        // prefix_prefill.py:123:16
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3661, %r3662, %r3663, %r3664 }, [ %r3545 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3685, %r3686, %r3687, %r3688 }, [ %r3550 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3709, %r3710, %r3711, %r3712 }, [ %r3555 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3733, %r3734, %r3735, %r3736 }, [ %r3560 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3757, %r3758, %r3759, %r3760 }, [ %r3565 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3781, %r3782, %r3783, %r3784 }, [ %r3570 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3805, %r3806, %r3807, %r3808 }, [ %r3575 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3829, %r3830, %r3831, %r3832 }, [ %r3580 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3673, %r3674, %r3675, %r3676 }, [ %r3585 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3697, %r3698, %r3699, %r3700 }, [ %r3590 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3721, %r3722, %r3723, %r3724 }, [ %r3595 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3745, %r3746, %r3747, %r3748 }, [ %r3600 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3769, %r3770, %r3771, %r3772 }, [ %r3605 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3793, %r3794, %r3795, %r3796 }, [ %r3610 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3817, %r3818, %r3819, %r3820 }, [ %r3615 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3841, %r3842, %r3843, %r3844 }, [ %r3620 + 0 ];
	// end inline asm
	.loc	1 153 11                        // prefix_prefill.py:153:11
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3665, %r3666, %r3671, %r3672 }, [ %r3625 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3689, %r3690, %r3695, %r3696 }, [ %r3630 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3713, %r3714, %r3719, %r3720 }, [ %r3635 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3737, %r3738, %r3743, %r3744 }, [ %r3640 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3761, %r3762, %r3767, %r3768 }, [ %r3645 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3785, %r3786, %r3791, %r3792 }, [ %r3650 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3809, %r3810, %r3815, %r3816 }, [ %r3655 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r3833, %r3834, %r3839, %r3840 }, [ %r3660 + 0 ];
	// end inline asm
	mov.f32 	%f5116, 0f00000000;
	.loc	1 169 23                        // prefix_prefill.py:169:23
	mov.f32 	%f5092, %f5116;
	mov.f32 	%f5093, %f5116;
	mov.f32 	%f5094, %f5116;
	mov.f32 	%f5095, %f5116;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5092, %f5093, %f5094, %f5095 }, { %r3661, %r3662, %r3663, %r3664 }, { %r3665, %r3666 }, { %f5092, %f5093, %f5094, %f5095 };
	// end inline asm
	mov.f32 	%f5100, %f5116;
	mov.f32 	%f5101, %f5116;
	mov.f32 	%f5102, %f5116;
	mov.f32 	%f5103, %f5116;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5100, %f5101, %f5102, %f5103 }, { %r3661, %r3662, %r3663, %r3664 }, { %r3671, %r3672 }, { %f5100, %f5101, %f5102, %f5103 };
	// end inline asm
	mov.f32 	%f5108, %f5116;
	mov.f32 	%f5109, %f5116;
	mov.f32 	%f5110, %f5116;
	mov.f32 	%f5111, %f5116;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5108, %f5109, %f5110, %f5111 }, { %r3673, %r3674, %r3675, %r3676 }, { %r3665, %r3666 }, { %f5108, %f5109, %f5110, %f5111 };
	// end inline asm
	mov.f32 	%f5117, %f5116;
	mov.f32 	%f5118, %f5116;
	mov.f32 	%f5119, %f5116;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5116, %f5117, %f5118, %f5119 }, { %r3673, %r3674, %r3675, %r3676 }, { %r3671, %r3672 }, { %f5116, %f5117, %f5118, %f5119 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5092, %f5093, %f5094, %f5095 }, { %r3685, %r3686, %r3687, %r3688 }, { %r3689, %r3690 }, { %f5092, %f5093, %f5094, %f5095 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5100, %f5101, %f5102, %f5103 }, { %r3685, %r3686, %r3687, %r3688 }, { %r3695, %r3696 }, { %f5100, %f5101, %f5102, %f5103 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5108, %f5109, %f5110, %f5111 }, { %r3697, %r3698, %r3699, %r3700 }, { %r3689, %r3690 }, { %f5108, %f5109, %f5110, %f5111 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5116, %f5117, %f5118, %f5119 }, { %r3697, %r3698, %r3699, %r3700 }, { %r3695, %r3696 }, { %f5116, %f5117, %f5118, %f5119 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5092, %f5093, %f5094, %f5095 }, { %r3709, %r3710, %r3711, %r3712 }, { %r3713, %r3714 }, { %f5092, %f5093, %f5094, %f5095 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5100, %f5101, %f5102, %f5103 }, { %r3709, %r3710, %r3711, %r3712 }, { %r3719, %r3720 }, { %f5100, %f5101, %f5102, %f5103 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5108, %f5109, %f5110, %f5111 }, { %r3721, %r3722, %r3723, %r3724 }, { %r3713, %r3714 }, { %f5108, %f5109, %f5110, %f5111 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5116, %f5117, %f5118, %f5119 }, { %r3721, %r3722, %r3723, %r3724 }, { %r3719, %r3720 }, { %f5116, %f5117, %f5118, %f5119 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5092, %f5093, %f5094, %f5095 }, { %r3733, %r3734, %r3735, %r3736 }, { %r3737, %r3738 }, { %f5092, %f5093, %f5094, %f5095 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5100, %f5101, %f5102, %f5103 }, { %r3733, %r3734, %r3735, %r3736 }, { %r3743, %r3744 }, { %f5100, %f5101, %f5102, %f5103 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5108, %f5109, %f5110, %f5111 }, { %r3745, %r3746, %r3747, %r3748 }, { %r3737, %r3738 }, { %f5108, %f5109, %f5110, %f5111 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5116, %f5117, %f5118, %f5119 }, { %r3745, %r3746, %r3747, %r3748 }, { %r3743, %r3744 }, { %f5116, %f5117, %f5118, %f5119 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5092, %f5093, %f5094, %f5095 }, { %r3757, %r3758, %r3759, %r3760 }, { %r3761, %r3762 }, { %f5092, %f5093, %f5094, %f5095 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5100, %f5101, %f5102, %f5103 }, { %r3757, %r3758, %r3759, %r3760 }, { %r3767, %r3768 }, { %f5100, %f5101, %f5102, %f5103 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5108, %f5109, %f5110, %f5111 }, { %r3769, %r3770, %r3771, %r3772 }, { %r3761, %r3762 }, { %f5108, %f5109, %f5110, %f5111 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5116, %f5117, %f5118, %f5119 }, { %r3769, %r3770, %r3771, %r3772 }, { %r3767, %r3768 }, { %f5116, %f5117, %f5118, %f5119 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5092, %f5093, %f5094, %f5095 }, { %r3781, %r3782, %r3783, %r3784 }, { %r3785, %r3786 }, { %f5092, %f5093, %f5094, %f5095 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5100, %f5101, %f5102, %f5103 }, { %r3781, %r3782, %r3783, %r3784 }, { %r3791, %r3792 }, { %f5100, %f5101, %f5102, %f5103 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5108, %f5109, %f5110, %f5111 }, { %r3793, %r3794, %r3795, %r3796 }, { %r3785, %r3786 }, { %f5108, %f5109, %f5110, %f5111 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5116, %f5117, %f5118, %f5119 }, { %r3793, %r3794, %r3795, %r3796 }, { %r3791, %r3792 }, { %f5116, %f5117, %f5118, %f5119 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5092, %f5093, %f5094, %f5095 }, { %r3805, %r3806, %r3807, %r3808 }, { %r3809, %r3810 }, { %f5092, %f5093, %f5094, %f5095 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5100, %f5101, %f5102, %f5103 }, { %r3805, %r3806, %r3807, %r3808 }, { %r3815, %r3816 }, { %f5100, %f5101, %f5102, %f5103 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5108, %f5109, %f5110, %f5111 }, { %r3817, %r3818, %r3819, %r3820 }, { %r3809, %r3810 }, { %f5108, %f5109, %f5110, %f5111 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5116, %f5117, %f5118, %f5119 }, { %r3817, %r3818, %r3819, %r3820 }, { %r3815, %r3816 }, { %f5116, %f5117, %f5118, %f5119 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5092, %f5093, %f5094, %f5095 }, { %r3829, %r3830, %r3831, %r3832 }, { %r3833, %r3834 }, { %f5092, %f5093, %f5094, %f5095 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5100, %f5101, %f5102, %f5103 }, { %r3829, %r3830, %r3831, %r3832 }, { %r3839, %r3840 }, { %f5100, %f5101, %f5102, %f5103 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5108, %f5109, %f5110, %f5111 }, { %r3841, %r3842, %r3843, %r3844 }, { %r3833, %r3834 }, { %f5108, %f5109, %f5110, %f5111 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5116, %f5117, %f5118, %f5119 }, { %r3841, %r3842, %r3843, %r3844 }, { %r3839, %r3840 }, { %f5116, %f5117, %f5118, %f5119 };
	// end inline asm
	.loc	1 170 55                        // prefix_prefill.py:170:55
	setp.lt.s32 	%p314, %r505, %r5;
	setp.lt.s32 	%p315, %r506, %r5;
	setp.lt.s32 	%p316, %r507, %r5;
	setp.lt.s32 	%p317, %r508, %r5;
	.loc	1 171 22                        // prefix_prefill.py:171:22
	selp.f32 	%f5356, %f5092, 0fFF800000, %p314;
	selp.f32 	%f5357, %f5093, 0fFF800000, %p315;
	selp.f32 	%f5358, %f5094, 0fFF800000, %p314;
	selp.f32 	%f5359, %f5095, 0fFF800000, %p315;
	selp.f32 	%f5360, %f5100, 0fFF800000, %p316;
	selp.f32 	%f5361, %f5101, 0fFF800000, %p317;
	selp.f32 	%f5362, %f5102, 0fFF800000, %p316;
	selp.f32 	%f5363, %f5103, 0fFF800000, %p317;
	selp.f32 	%f5364, %f5108, 0fFF800000, %p314;
	selp.f32 	%f5365, %f5109, 0fFF800000, %p315;
	selp.f32 	%f5366, %f5110, 0fFF800000, %p314;
	selp.f32 	%f5367, %f5111, 0fFF800000, %p315;
	selp.f32 	%f5368, %f5116, 0fFF800000, %p316;
	selp.f32 	%f5369, %f5117, 0fFF800000, %p317;
	selp.f32 	%f5370, %f5118, 0fFF800000, %p316;
	selp.f32 	%f5371, %f5119, 0fFF800000, %p317;
	.loc	1 172 14                        // prefix_prefill.py:172:14
	mul.f32 	%f5372, %f2401, %f5356;
	mul.f32 	%f5373, %f2401, %f5357;
	mul.f32 	%f5374, %f2401, %f5358;
	mul.f32 	%f5375, %f2401, %f5359;
	mul.f32 	%f5376, %f2401, %f5360;
	mul.f32 	%f5377, %f2401, %f5361;
	mul.f32 	%f5378, %f2401, %f5362;
	mul.f32 	%f5379, %f2401, %f5363;
	mul.f32 	%f5380, %f2401, %f5364;
	mul.f32 	%f5381, %f2401, %f5365;
	mul.f32 	%f5382, %f2401, %f5366;
	mul.f32 	%f5383, %f2401, %f5367;
	mul.f32 	%f5384, %f2401, %f5368;
	mul.f32 	%f5385, %f2401, %f5369;
	mul.f32 	%f5386, %f2401, %f5370;
	mul.f32 	%f5387, %f2401, %f5371;
$L__tmp17:
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f5388, %f5372, %f5373;
	max.f32 	%f5389, %f5374, %f5375;
	max.f32 	%f5390, %f5388, %f5376;
	max.f32 	%f5391, %f5390, %f5377;
	max.f32 	%f5392, %f5389, %f5378;
	max.f32 	%f5393, %f5392, %f5379;
	max.f32 	%f5394, %f5380, %f5381;
	max.f32 	%f5395, %f5382, %f5383;
	max.f32 	%f5396, %f5394, %f5384;
	max.f32 	%f5397, %f5396, %f5385;
	max.f32 	%f5398, %f5395, %f5386;
	max.f32 	%f5399, %f5398, %f5387;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r3857, %f5391;
	shfl.sync.bfly.b32	%r3858, %r3857, 2, 31, -1;
	mov.b32 	%f5400, %r3858;
	mov.b32 	%r3859, %f5393;
	mov.b32 	%r3860, %f5397;
	mov.b32 	%r3861, %f5399;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f5401, %f5391, %f5400;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r3862, %f5401;
	shfl.sync.bfly.b32	%r3863, %r3862, 1, 31, -1;
	shfl.sync.bfly.b32	%r3864, %r3859, 2, 31, -1;
	mov.b32 	%f5402, %r3864;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f5403, %f5393, %f5402;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r3865, %f5403;
	shfl.sync.bfly.b32	%r3866, %r3865, 1, 31, -1;
	shfl.sync.bfly.b32	%r3867, %r3860, 2, 31, -1;
	mov.b32 	%f5404, %r3867;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f5405, %f5397, %f5404;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r3868, %f5405;
	shfl.sync.bfly.b32	%r3869, %r3868, 1, 31, -1;
	shfl.sync.bfly.b32	%r3870, %r3861, 2, 31, -1;
	mov.b32 	%f5406, %r3870;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f5407, %f5399, %f5406;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r3871, %f5407;
	shfl.sync.bfly.b32	%r3872, %r3871, 1, 31, -1;
	mov.b32 	%f5408, %r3872;
	mov.b32 	%f5409, %r3869;
	mov.b32 	%f5410, %r3866;
	mov.b32 	%f5411, %r3863;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f5412, %f5401, %f5411;
	max.f32 	%f5413, %f5403, %f5410;
	max.f32 	%f5414, %f5405, %f5409;
	max.f32 	%f5415, %f5407, %f5408;
$L__tmp18:
	.loc	1 190 31                        // prefix_prefill.py:190:31
	max.f32 	%f8519, %f8659, %f5415;
	max.f32 	%f8518, %f8658, %f5414;
	max.f32 	%f8517, %f8657, %f5413;
	max.f32 	%f8516, %f8656, %f5412;
	.loc	1 191 24                        // prefix_prefill.py:191:24
	neg.f32 	%f5416, %f8516;
	fma.rn.f32 	%f5417, %f2401, %f5356, %f5416;
	fma.rn.f32 	%f5418, %f2401, %f5357, %f5416;
	neg.f32 	%f5419, %f8517;
	fma.rn.f32 	%f5420, %f2401, %f5358, %f5419;
	fma.rn.f32 	%f5421, %f2401, %f5359, %f5419;
	fma.rn.f32 	%f5422, %f2401, %f5360, %f5416;
	fma.rn.f32 	%f5423, %f2401, %f5361, %f5416;
	fma.rn.f32 	%f5424, %f2401, %f5362, %f5419;
	fma.rn.f32 	%f5425, %f2401, %f5363, %f5419;
	neg.f32 	%f5426, %f8518;
	fma.rn.f32 	%f5427, %f2401, %f5364, %f5426;
	fma.rn.f32 	%f5428, %f2401, %f5365, %f5426;
	neg.f32 	%f5429, %f8519;
	fma.rn.f32 	%f5430, %f2401, %f5366, %f5429;
	fma.rn.f32 	%f5431, %f2401, %f5367, %f5429;
	fma.rn.f32 	%f5432, %f2401, %f5368, %f5426;
	fma.rn.f32 	%f5433, %f2401, %f5369, %f5426;
	fma.rn.f32 	%f5434, %f2401, %f5370, %f5429;
	fma.rn.f32 	%f5435, %f2401, %f5371, %f5429;
	.loc	1 191 19                        // prefix_prefill.py:191:19
	mul.f32 	%f5317, %f5417, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f5316, %f5317;
	// end inline asm
	mul.f32 	%f5319, %f5418, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f5318, %f5319;
	// end inline asm
	mul.f32 	%f5321, %f5420, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f5320, %f5321;
	// end inline asm
	mul.f32 	%f5323, %f5421, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f5322, %f5323;
	// end inline asm
	mul.f32 	%f5325, %f5422, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f5324, %f5325;
	// end inline asm
	mul.f32 	%f5327, %f5423, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f5326, %f5327;
	// end inline asm
	mul.f32 	%f5329, %f5424, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f5328, %f5329;
	// end inline asm
	mul.f32 	%f5331, %f5425, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f5330, %f5331;
	// end inline asm
	mul.f32 	%f5333, %f5427, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f5332, %f5333;
	// end inline asm
	mul.f32 	%f5335, %f5428, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f5334, %f5335;
	// end inline asm
	mul.f32 	%f5337, %f5430, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f5336, %f5337;
	// end inline asm
	mul.f32 	%f5339, %f5431, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f5338, %f5339;
	// end inline asm
	mul.f32 	%f5341, %f5432, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f5340, %f5341;
	// end inline asm
	mul.f32 	%f5343, %f5433, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f5342, %f5343;
	// end inline asm
	mul.f32 	%f5345, %f5434, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f5344, %f5345;
	// end inline asm
	mul.f32 	%f5347, %f5435, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f5346, %f5347;
	// end inline asm
$L__tmp19:
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f5436, %f5316, %f5318;
	add.f32 	%f5437, %f5320, %f5322;
	add.f32 	%f5438, %f5436, %f5324;
	add.f32 	%f5439, %f5438, %f5326;
	add.f32 	%f5440, %f5437, %f5328;
	add.f32 	%f5441, %f5440, %f5330;
	add.f32 	%f5442, %f5332, %f5334;
	add.f32 	%f5443, %f5336, %f5338;
	add.f32 	%f5444, %f5442, %f5340;
	add.f32 	%f5445, %f5444, %f5342;
	add.f32 	%f5446, %f5443, %f5344;
	add.f32 	%f5447, %f5446, %f5346;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r3873, %f5439;
	shfl.sync.bfly.b32	%r3874, %r3873, 2, 31, -1;
	mov.b32 	%f5448, %r3874;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f5449, %f5439, %f5448;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r3875, %f5449;
	shfl.sync.bfly.b32	%r3876, %r3875, 1, 31, -1;
	mov.b32 	%r3877, %f5441;
	shfl.sync.bfly.b32	%r3878, %r3877, 2, 31, -1;
	mov.b32 	%f5450, %r3878;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f5451, %f5441, %f5450;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r3879, %f5451;
	shfl.sync.bfly.b32	%r3880, %r3879, 1, 31, -1;
	mov.b32 	%r3881, %f5445;
	shfl.sync.bfly.b32	%r3882, %r3881, 2, 31, -1;
	mov.b32 	%f5452, %r3882;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f5453, %f5445, %f5452;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r3883, %f5453;
	shfl.sync.bfly.b32	%r3884, %r3883, 1, 31, -1;
	mov.b32 	%r3885, %f5447;
	shfl.sync.bfly.b32	%r3886, %r3885, 2, 31, -1;
	mov.b32 	%f5454, %r3886;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f5455, %f5447, %f5454;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r3887, %f5455;
	shfl.sync.bfly.b32	%r3888, %r3887, 1, 31, -1;
	mov.b32 	%f5456, %r3888;
	mov.b32 	%f5457, %r3884;
	mov.b32 	%f5458, %r3880;
	mov.b32 	%f5459, %r3876;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f1593, %f5449, %f5459;
	add.f32 	%f1594, %f5451, %f5458;
	add.f32 	%f1595, %f5453, %f5457;
	add.f32 	%f1596, %f5455, %f5456;
$L__tmp20:
	.loc	1 193 29                        // prefix_prefill.py:193:29
	sub.f32 	%f5460, %f8659, %f8519;
	sub.f32 	%f5461, %f8658, %f8518;
	sub.f32 	%f5462, %f8657, %f8517;
	sub.f32 	%f5463, %f8656, %f8516;
	.loc	1 193 23                        // prefix_prefill.py:193:23
	mul.f32 	%f5349, %f5463, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f5348, %f5349;
	// end inline asm
	mul.f32 	%f5351, %f5462, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f5350, %f5351;
	// end inline asm
	mul.f32 	%f5353, %f5461, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f5352, %f5353;
	// end inline asm
	mul.f32 	%f5355, %f5460, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f5354, %f5355;
	// end inline asm
	.loc	1 194 20                        // prefix_prefill.py:194:20
	mul.f32 	%f8524, %f8524, %f5348;
	mul.f32 	%f8525, %f8525, %f5348;
	mul.f32 	%f8526, %f8526, %f5350;
	mul.f32 	%f8527, %f8527, %f5350;
	mul.f32 	%f8528, %f8528, %f5348;
	mul.f32 	%f8529, %f8529, %f5348;
	mul.f32 	%f8530, %f8530, %f5350;
	mul.f32 	%f8531, %f8531, %f5350;
	mul.f32 	%f8532, %f8532, %f5348;
	mul.f32 	%f8533, %f8533, %f5348;
	mul.f32 	%f8534, %f8534, %f5350;
	mul.f32 	%f8535, %f8535, %f5350;
	mul.f32 	%f8536, %f8536, %f5348;
	mul.f32 	%f8537, %f8537, %f5348;
	mul.f32 	%f8538, %f8538, %f5350;
	mul.f32 	%f8539, %f8539, %f5350;
	mul.f32 	%f8540, %f8540, %f5348;
	mul.f32 	%f8541, %f8541, %f5348;
	mul.f32 	%f8542, %f8542, %f5350;
	mul.f32 	%f8543, %f8543, %f5350;
	mul.f32 	%f8544, %f8544, %f5348;
	mul.f32 	%f8545, %f8545, %f5348;
	mul.f32 	%f8546, %f8546, %f5350;
	mul.f32 	%f8547, %f8547, %f5350;
	mul.f32 	%f8548, %f8548, %f5348;
	mul.f32 	%f8549, %f8549, %f5348;
	mul.f32 	%f8550, %f8550, %f5350;
	mul.f32 	%f8551, %f8551, %f5350;
	mul.f32 	%f8552, %f8552, %f5348;
	mul.f32 	%f8553, %f8553, %f5348;
	mul.f32 	%f8554, %f8554, %f5350;
	mul.f32 	%f8555, %f8555, %f5350;
	mul.f32 	%f8556, %f8556, %f5348;
	mul.f32 	%f8557, %f8557, %f5348;
	mul.f32 	%f8558, %f8558, %f5350;
	mul.f32 	%f8559, %f8559, %f5350;
	mul.f32 	%f8560, %f8560, %f5348;
	mul.f32 	%f8561, %f8561, %f5348;
	mul.f32 	%f8562, %f8562, %f5350;
	mul.f32 	%f8563, %f8563, %f5350;
	mul.f32 	%f8564, %f8564, %f5348;
	mul.f32 	%f8565, %f8565, %f5348;
	mul.f32 	%f8566, %f8566, %f5350;
	mul.f32 	%f8567, %f8567, %f5350;
	mul.f32 	%f8568, %f8568, %f5348;
	mul.f32 	%f8569, %f8569, %f5348;
	mul.f32 	%f8570, %f8570, %f5350;
	mul.f32 	%f8571, %f8571, %f5350;
	mul.f32 	%f8572, %f8572, %f5348;
	mul.f32 	%f8573, %f8573, %f5348;
	mul.f32 	%f8574, %f8574, %f5350;
	mul.f32 	%f8575, %f8575, %f5350;
	mul.f32 	%f8576, %f8576, %f5348;
	mul.f32 	%f8577, %f8577, %f5348;
	mul.f32 	%f8578, %f8578, %f5350;
	mul.f32 	%f8579, %f8579, %f5350;
	mul.f32 	%f8580, %f8580, %f5348;
	mul.f32 	%f8581, %f8581, %f5348;
	mul.f32 	%f8582, %f8582, %f5350;
	mul.f32 	%f8583, %f8583, %f5350;
	mul.f32 	%f8584, %f8584, %f5348;
	mul.f32 	%f8585, %f8585, %f5348;
	mul.f32 	%f8586, %f8586, %f5350;
	mul.f32 	%f8587, %f8587, %f5350;
	mul.f32 	%f8588, %f8588, %f5352;
	mul.f32 	%f8589, %f8589, %f5352;
	mul.f32 	%f8590, %f8590, %f5354;
	mul.f32 	%f8591, %f8591, %f5354;
	mul.f32 	%f8592, %f8592, %f5352;
	mul.f32 	%f8593, %f8593, %f5352;
	mul.f32 	%f8594, %f8594, %f5354;
	mul.f32 	%f8595, %f8595, %f5354;
	mul.f32 	%f8596, %f8596, %f5352;
	mul.f32 	%f8597, %f8597, %f5352;
	mul.f32 	%f8598, %f8598, %f5354;
	mul.f32 	%f8599, %f8599, %f5354;
	mul.f32 	%f8600, %f8600, %f5352;
	mul.f32 	%f8601, %f8601, %f5352;
	mul.f32 	%f8602, %f8602, %f5354;
	mul.f32 	%f8603, %f8603, %f5354;
	mul.f32 	%f8604, %f8604, %f5352;
	mul.f32 	%f8605, %f8605, %f5352;
	mul.f32 	%f8606, %f8606, %f5354;
	mul.f32 	%f8607, %f8607, %f5354;
	mul.f32 	%f8608, %f8608, %f5352;
	mul.f32 	%f8609, %f8609, %f5352;
	mul.f32 	%f8610, %f8610, %f5354;
	mul.f32 	%f8611, %f8611, %f5354;
	mul.f32 	%f8612, %f8612, %f5352;
	mul.f32 	%f8613, %f8613, %f5352;
	mul.f32 	%f8614, %f8614, %f5354;
	mul.f32 	%f8615, %f8615, %f5354;
	mul.f32 	%f8616, %f8616, %f5352;
	mul.f32 	%f8617, %f8617, %f5352;
	mul.f32 	%f8618, %f8618, %f5354;
	mul.f32 	%f8619, %f8619, %f5354;
	mul.f32 	%f8620, %f8620, %f5352;
	mul.f32 	%f8621, %f8621, %f5352;
	mul.f32 	%f8622, %f8622, %f5354;
	mul.f32 	%f8623, %f8623, %f5354;
	mul.f32 	%f8624, %f8624, %f5352;
	mul.f32 	%f8625, %f8625, %f5352;
	mul.f32 	%f8626, %f8626, %f5354;
	mul.f32 	%f8627, %f8627, %f5354;
	mul.f32 	%f8628, %f8628, %f5352;
	mul.f32 	%f8629, %f8629, %f5352;
	mul.f32 	%f8630, %f8630, %f5354;
	mul.f32 	%f8631, %f8631, %f5354;
	mul.f32 	%f8632, %f8632, %f5352;
	mul.f32 	%f8633, %f8633, %f5352;
	mul.f32 	%f8634, %f8634, %f5354;
	mul.f32 	%f8635, %f8635, %f5354;
	mul.f32 	%f8636, %f8636, %f5352;
	mul.f32 	%f8637, %f8637, %f5352;
	mul.f32 	%f8638, %f8638, %f5354;
	mul.f32 	%f8639, %f8639, %f5354;
	mul.f32 	%f8640, %f8640, %f5352;
	mul.f32 	%f8641, %f8641, %f5352;
	mul.f32 	%f8642, %f8642, %f5354;
	mul.f32 	%f8643, %f8643, %f5354;
	mul.f32 	%f8644, %f8644, %f5352;
	mul.f32 	%f8645, %f8645, %f5352;
	mul.f32 	%f8646, %f8646, %f5354;
	mul.f32 	%f8647, %f8647, %f5354;
	mul.f32 	%f8648, %f8648, %f5352;
	mul.f32 	%f8649, %f8649, %f5352;
	mul.f32 	%f8650, %f8650, %f5354;
	mul.f32 	%f8651, %f8651, %f5354;
	.loc	1 197 11                        // prefix_prefill.py:197:11
	@%p300 bra 	$L__BB0_34;
// %bb.33:                              //   in Loop: Header=BB0_6 Depth=1
	.loc	1 0 0                           // prefix_prefill.py:0:0
	add.s32 	%r512, %r3515, %r70;
	add.s32 	%r513, %r3515, %r71;
	add.s32 	%r514, %r3515, %r72;
	add.s32 	%r515, %r3515, %r73;
	add.s32 	%r516, %r3515, %r74;
	add.s32 	%r517, %r3515, %r75;
	add.s32 	%r518, %r3515, %r76;
	add.s32 	%r520, %r3516, %r70;
	add.s32 	%r521, %r3516, %r71;
	add.s32 	%r522, %r3516, %r72;
	add.s32 	%r523, %r3516, %r73;
	add.s32 	%r524, %r3516, %r74;
	add.s32 	%r525, %r3516, %r75;
	add.s32 	%r526, %r3516, %r76;
	.loc	1 202 28                        // prefix_prefill.py:202:28
	add.s32 	%r3897, %r21, %r7391;
	add.s32 	%r3898, %r3897, 1;
	add.s32 	%r3899, %r3897, 2;
	add.s32 	%r3900, %r3897, 3;
	add.s32 	%r3901, %r3897, 4;
	add.s32 	%r3902, %r3897, 5;
	add.s32 	%r3903, %r3897, 6;
	.loc	1 202 50                        // prefix_prefill.py:202:50
	add.s32 	%r3904, %r3897, 7;
	setp.lt.s32 	%p320, %r3897, %r5;
	setp.lt.s32 	%p322, %r3898, %r5;
	setp.lt.s32 	%p324, %r3899, %r5;
	setp.lt.s32 	%p326, %r3900, %r5;
	setp.lt.s32 	%p328, %r3901, %r5;
	setp.lt.s32 	%p330, %r3902, %r5;
	setp.lt.s32 	%p332, %r3903, %r5;
	setp.lt.s32 	%p334, %r3904, %r5;
	.loc	1 200 26                        // prefix_prefill.py:200:26
	mul.wide.s32 	%rd364, %r511, 2;
	add.s64 	%rd348, %rd111, %rd364;
	mul.wide.s32 	%rd365, %r512, 2;
	add.s64 	%rd349, %rd111, %rd365;
	mul.wide.s32 	%rd366, %r513, 2;
	add.s64 	%rd350, %rd111, %rd366;
	mul.wide.s32 	%rd367, %r514, 2;
	add.s64 	%rd351, %rd111, %rd367;
	mul.wide.s32 	%rd368, %r515, 2;
	add.s64 	%rd352, %rd111, %rd368;
	mul.wide.s32 	%rd369, %r516, 2;
	add.s64 	%rd353, %rd111, %rd369;
	mul.wide.s32 	%rd370, %r517, 2;
	add.s64 	%rd354, %rd111, %rd370;
	mul.wide.s32 	%rd371, %r518, 2;
	add.s64 	%rd355, %rd111, %rd371;
	mul.wide.s32 	%rd372, %r519, 2;
	add.s64 	%rd356, %rd111, %rd372;
	mul.wide.s32 	%rd373, %r520, 2;
	add.s64 	%rd357, %rd111, %rd373;
	mul.wide.s32 	%rd374, %r521, 2;
	add.s64 	%rd358, %rd111, %rd374;
	mul.wide.s32 	%rd375, %r522, 2;
	add.s64 	%rd359, %rd111, %rd375;
	mul.wide.s32 	%rd376, %r523, 2;
	add.s64 	%rd360, %rd111, %rd376;
	mul.wide.s32 	%rd377, %r524, 2;
	add.s64 	%rd361, %rd111, %rd377;
	mul.wide.s32 	%rd378, %r525, 2;
	add.s64 	%rd362, %rd111, %rd378;
	mul.wide.s32 	%rd379, %r526, 2;
	add.s64 	%rd363, %rd111, %rd379;
	.loc	1 200 16                        // prefix_prefill.py:200:16
	// begin inline asm
	mov.u16 %rs257, 0x0;
	@%p320 ld.global.b16 { %rs257 }, [ %rd348 + 0 ];
	@!%p320 mov.u16 %rs257, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs259, 0x0;
	@%p322 ld.global.b16 { %rs259 }, [ %rd349 + 0 ];
	@!%p322 mov.u16 %rs259, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs261, 0x0;
	@%p324 ld.global.b16 { %rs261 }, [ %rd350 + 0 ];
	@!%p324 mov.u16 %rs261, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs263, 0x0;
	@%p326 ld.global.b16 { %rs263 }, [ %rd351 + 0 ];
	@!%p326 mov.u16 %rs263, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs265, 0x0;
	@%p328 ld.global.b16 { %rs265 }, [ %rd352 + 0 ];
	@!%p328 mov.u16 %rs265, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs267, 0x0;
	@%p330 ld.global.b16 { %rs267 }, [ %rd353 + 0 ];
	@!%p330 mov.u16 %rs267, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs269, 0x0;
	@%p332 ld.global.b16 { %rs269 }, [ %rd354 + 0 ];
	@!%p332 mov.u16 %rs269, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs271, 0x0;
	@%p334 ld.global.b16 { %rs271 }, [ %rd355 + 0 ];
	@!%p334 mov.u16 %rs271, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs273, 0x0;
	@%p320 ld.global.b16 { %rs273 }, [ %rd356 + 0 ];
	@!%p320 mov.u16 %rs273, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs275, 0x0;
	@%p322 ld.global.b16 { %rs275 }, [ %rd357 + 0 ];
	@!%p322 mov.u16 %rs275, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs277, 0x0;
	@%p324 ld.global.b16 { %rs277 }, [ %rd358 + 0 ];
	@!%p324 mov.u16 %rs277, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs279, 0x0;
	@%p326 ld.global.b16 { %rs279 }, [ %rd359 + 0 ];
	@!%p326 mov.u16 %rs279, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs281, 0x0;
	@%p328 ld.global.b16 { %rs281 }, [ %rd360 + 0 ];
	@!%p328 mov.u16 %rs281, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs283, 0x0;
	@%p330 ld.global.b16 { %rs283 }, [ %rd361 + 0 ];
	@!%p330 mov.u16 %rs283, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs285, 0x0;
	@%p332 ld.global.b16 { %rs285 }, [ %rd362 + 0 ];
	@!%p332 mov.u16 %rs285, %rs258;
	// end inline asm
	// begin inline asm
	mov.u16 %rs287, 0x0;
	@%p334 ld.global.b16 { %rs287 }, [ %rd363 + 0 ];
	@!%p334 mov.u16 %rs287, %rs258;
	// end inline asm
	mov.b32 	%r7400, {%rs257, %rs259};
	mov.b32 	%r7401, {%rs261, %rs263};
	mov.b32 	%r7402, {%rs265, %rs267};
	mov.b32 	%r7403, {%rs269, %rs271};
	mov.b32 	%r7404, {%rs273, %rs275};
	mov.b32 	%r7405, {%rs277, %rs279};
	mov.b32 	%r7406, {%rs281, %rs283};
	mov.b32 	%r7407, {%rs285, %rs287};
	.loc	1 197 11                        // prefix_prefill.py:197:11
	bra.uni 	$L__BB0_35;
$L__BB0_36:                             // %._crit_edge
	.loc	1 0 11                          // prefix_prefill.py:0:11
	ld.param.u32 	%r671, [_fwd_kernel_param_20];
	ld.param.u32 	%r670, [_fwd_kernel_param_19];
	ld.param.u64 	%rd112, [_fwd_kernel_param_11];
	.loc	1 226 44                        // prefix_prefill.py:226:44
	setp.lt.s32 	%p353, %r6, %r4;
	.loc	1 230 53                        // prefix_prefill.py:230:53
	add.s32 	%r4189, %r6, 128;
	.loc	1 230 38                        // prefix_prefill.py:230:38
	selp.b32 	%r576, %r4189, 0, %p353;
	.loc	1 231 24                        // prefix_prefill.py:231:24
	setp.lt.s32 	%p354, %r576, 1;
	@%p354 bra 	$L__BB0_39;
// %bb.37:                              // %.lr.ph732
	.loc	1 0 24                          // prefix_prefill.py:0:24
	bfe.u32 	%r817, %r7, 2, 3;
	or.b32  	%r819, %r817, %r818;
	or.b32  	%r821, %r819, %r820;
	or.b32  	%r45, %r6, %r821;
	ld.param.u32 	%r669, [_fwd_kernel_param_18];
	ld.param.u32 	%r668, [_fwd_kernel_param_17];
	ld.param.u32 	%r667, [_fwd_kernel_param_16];
	ld.param.u32 	%r666, [_fwd_kernel_param_15];
	ld.param.u64 	%rd109, [_fwd_kernel_param_2];
	ld.param.u64 	%rd108, [_fwd_kernel_param_1];
	or.b32  	%r46, %r45, 8;
	or.b32  	%r47, %r45, 64;
	or.b32  	%r48, %r45, 72;
	or.b32  	%r69, %r68, 9;
	shl.b32 	%r4169, %r666, 3;
	mad.lo.s32 	%r4170, %r2, %r667, %r23;
	mad.lo.s32 	%r4171, %r666, %r12, %r4170;
	add.s32 	%r4172, %r4171, %r4169;
	add.s32 	%r4173, %r4172, %r4169;
	add.s32 	%r4174, %r4173, %r4169;
	mad.lo.s32 	%r4175, %r666, %r19, %r4170;
	mad.lo.s32 	%r4176, %r666, %r18, %r4170;
	mad.lo.s32 	%r4177, %r666, %r17, %r4170;
	mad.lo.s32 	%r4178, %r666, %r16, %r4170;
	shl.b32 	%r4179, %r668, 3;
	mad.lo.s32 	%r4180, %r2, %r669, %r23;
	mad.lo.s32 	%r4181, %r668, %r12, %r4180;
	add.s32 	%r4182, %r4181, %r4179;
	add.s32 	%r4183, %r4182, %r4179;
	add.s32 	%r4184, %r4183, %r4179;
	mad.lo.s32 	%r4185, %r668, %r19, %r4180;
	mad.lo.s32 	%r4186, %r668, %r18, %r4180;
	mad.lo.s32 	%r4187, %r668, %r17, %r4180;
	mad.lo.s32 	%r4188, %r668, %r16, %r4180;
	mul.wide.s32 	%rd380, %r4171, 2;
	add.s64 	%rd4, %rd108, %rd380;
	mul.wide.s32 	%rd381, %r4172, 2;
	add.s64 	%rd5, %rd108, %rd381;
	mul.wide.s32 	%rd382, %r4173, 2;
	add.s64 	%rd6, %rd108, %rd382;
	mul.wide.s32 	%rd383, %r4174, 2;
	add.s64 	%rd7, %rd108, %rd383;
	mul.wide.s32 	%rd384, %r4175, 2;
	add.s64 	%rd8, %rd108, %rd384;
	mul.wide.s32 	%rd385, %r4176, 2;
	add.s64 	%rd9, %rd108, %rd385;
	mul.wide.s32 	%rd386, %r4177, 2;
	add.s64 	%rd10, %rd108, %rd386;
	mul.wide.s32 	%rd387, %r4178, 2;
	add.s64 	%rd11, %rd108, %rd387;
	mul.wide.s32 	%rd388, %r4181, 2;
	add.s64 	%rd12, %rd109, %rd388;
	mul.wide.s32 	%rd389, %r4182, 2;
	add.s64 	%rd13, %rd109, %rd389;
	mul.wide.s32 	%rd390, %r4183, 2;
	add.s64 	%rd14, %rd109, %rd390;
	mul.wide.s32 	%rd391, %r4184, 2;
	add.s64 	%rd15, %rd109, %rd391;
	mul.wide.s32 	%rd392, %r4185, 2;
	add.s64 	%rd16, %rd109, %rd392;
	mul.wide.s32 	%rd393, %r4186, 2;
	add.s64 	%rd17, %rd109, %rd393;
	mul.wide.s32 	%rd394, %r4187, 2;
	add.s64 	%rd18, %rd109, %rd394;
	mul.wide.s32 	%rd395, %r4188, 2;
	add.s64 	%rd19, %rd109, %rd395;
	add.s32 	%r4192, %r912, 32768;
	add.s32 	%r577, %r4192, %r911;
	and.b32  	%r4197, %r7316, 6;
	or.b32  	%r4198, %r4197, %r7314;
	xor.b32  	%r4199, %r7315, %r7313;
	shl.b32 	%r4200, %r4198, 10;
	shl.b32 	%r4201, %r7313, 7;
	or.b32  	%r4202, %r4200, %r4201;
	shl.b32 	%r4203, %r4199, 3;
	or.b32  	%r4204, %r4202, %r4203;
	shl.b32 	%r4205, %r4204, 1;
	add.s32 	%r4361, %r912, %r4205;
	or.b32  	%r4206, %r7315, 2;
	xor.b32  	%r4207, %r4206, %r7313;
	shl.b32 	%r4208, %r4207, 3;
	or.b32  	%r4209, %r4202, %r4208;
	shl.b32 	%r4210, %r4209, 1;
	add.s32 	%r4366, %r912, %r4210;
	or.b32  	%r4211, %r7315, 4;
	xor.b32  	%r4212, %r4211, %r7313;
	shl.b32 	%r4213, %r4212, 3;
	or.b32  	%r4214, %r4202, %r4213;
	shl.b32 	%r4215, %r4214, 1;
	add.s32 	%r4371, %r912, %r4215;
	or.b32  	%r4216, %r7315, 6;
	xor.b32  	%r4217, %r4216, %r7313;
	shl.b32 	%r4218, %r4217, 3;
	or.b32  	%r4219, %r4202, %r4218;
	shl.b32 	%r4220, %r4219, 1;
	add.s32 	%r4376, %r912, %r4220;
	or.b32  	%r4221, %r7315, 8;
	xor.b32  	%r4222, %r4221, %r7313;
	shl.b32 	%r4223, %r4222, 3;
	or.b32  	%r4224, %r4202, %r4223;
	shl.b32 	%r4225, %r4224, 1;
	add.s32 	%r4381, %r912, %r4225;
	or.b32  	%r4226, %r7315, 10;
	xor.b32  	%r4227, %r4226, %r7313;
	shl.b32 	%r4228, %r4227, 3;
	or.b32  	%r4229, %r4202, %r4228;
	shl.b32 	%r4230, %r4229, 1;
	add.s32 	%r4386, %r912, %r4230;
	or.b32  	%r4231, %r7315, 12;
	xor.b32  	%r4232, %r4231, %r7313;
	shl.b32 	%r4233, %r4232, 3;
	or.b32  	%r4234, %r4202, %r4233;
	shl.b32 	%r4235, %r4234, 1;
	add.s32 	%r4391, %r912, %r4235;
	or.b32  	%r4236, %r7315, 14;
	xor.b32  	%r4237, %r4236, %r7313;
	shl.b32 	%r4238, %r4237, 3;
	or.b32  	%r4239, %r4202, %r4238;
	shl.b32 	%r4240, %r4239, 1;
	add.s32 	%r4396, %r912, %r4240;
	add.s32 	%r4401, %r4361, 16384;
	add.s32 	%r4406, %r4366, 16384;
	add.s32 	%r4411, %r4371, 16384;
	add.s32 	%r4416, %r4376, 16384;
	add.s32 	%r4421, %r4381, 16384;
	add.s32 	%r4426, %r4386, 16384;
	add.s32 	%r4431, %r4391, 16384;
	add.s32 	%r4436, %r4396, 16384;
	xor.b32  	%r4241, %r7314, %r7313;
	shl.b32 	%r4242, %r4241, 4;
	shl.b32 	%r4243, %r7313, 8;
	shl.b32 	%r4244, %r7315, 11;
	or.b32  	%r4245, %r4244, %r4243;
	or.b32  	%r4246, %r4242, %r4245;
	add.s32 	%r4441, %r4192, %r4246;
	or.b32  	%r4247, %r7314, 2;
	xor.b32  	%r4248, %r4247, %r7313;
	shl.b32 	%r4249, %r4248, 4;
	or.b32  	%r4250, %r4249, %r4245;
	add.s32 	%r4446, %r4192, %r4250;
	or.b32  	%r4251, %r7314, 4;
	xor.b32  	%r4252, %r4251, %r7313;
	shl.b32 	%r4253, %r4252, 4;
	or.b32  	%r4254, %r4253, %r4245;
	add.s32 	%r4451, %r4192, %r4254;
	or.b32  	%r4255, %r7314, 6;
	xor.b32  	%r4256, %r4255, %r7313;
	shl.b32 	%r4257, %r4256, 4;
	or.b32  	%r4258, %r4257, %r4245;
	add.s32 	%r4456, %r4192, %r4258;
	or.b32  	%r4259, %r7314, 8;
	xor.b32  	%r4260, %r4259, %r7313;
	shl.b32 	%r4261, %r4260, 4;
	or.b32  	%r4262, %r4261, %r4245;
	add.s32 	%r4461, %r4192, %r4262;
	or.b32  	%r4263, %r7314, 10;
	xor.b32  	%r4264, %r4263, %r7313;
	shl.b32 	%r4265, %r4264, 4;
	or.b32  	%r4266, %r4265, %r4245;
	add.s32 	%r4466, %r4192, %r4266;
	or.b32  	%r4267, %r7314, 12;
	xor.b32  	%r4268, %r4267, %r7313;
	shl.b32 	%r4269, %r4268, 4;
	or.b32  	%r4270, %r4269, %r4245;
	add.s32 	%r4471, %r4192, %r4270;
	or.b32  	%r4271, %r7314, 14;
	xor.b32  	%r4272, %r4271, %r7313;
	shl.b32 	%r4273, %r4272, 4;
	or.b32  	%r4274, %r4273, %r4245;
	add.s32 	%r4476, %r4192, %r4274;
	add.s32 	%r4481, %r4441, 4096;
	add.s32 	%r4486, %r4446, 4096;
	add.s32 	%r4491, %r4451, 4096;
	add.s32 	%r4496, %r4456, 4096;
	add.s32 	%r4501, %r4461, 4096;
	add.s32 	%r4506, %r4466, 4096;
	add.s32 	%r4511, %r4471, 4096;
	add.s32 	%r4516, %r4476, 4096;
	add.s32 	%r4521, %r4441, 8192;
	add.s32 	%r4526, %r4446, 8192;
	add.s32 	%r4531, %r4451, 8192;
	add.s32 	%r4536, %r4456, 8192;
	add.s32 	%r4541, %r4461, 8192;
	add.s32 	%r4546, %r4466, 8192;
	add.s32 	%r4551, %r4471, 8192;
	add.s32 	%r4556, %r4476, 8192;
	add.s32 	%r4561, %r4441, 12288;
	add.s32 	%r4566, %r4446, 12288;
	add.s32 	%r4571, %r4451, 12288;
	add.s32 	%r4576, %r4456, 12288;
	add.s32 	%r4581, %r4461, 12288;
	add.s32 	%r4586, %r4466, 12288;
	add.s32 	%r4591, %r4471, 12288;
	add.s32 	%r4596, %r4476, 12288;
	shl.b32 	%r4275, %r7, 7;
	and.b32  	%r4276, %r4275, 1920;
	or.b32  	%r4277, %r4203, %r4276;
	shl.b32 	%r4278, %r4277, 1;
	add.s32 	%r5497, %r4192, %r4278;
	add.s32 	%r5502, %r5497, 4096;
	add.s32 	%r5507, %r5497, 8192;
	add.s32 	%r5512, %r5497, 12288;
	or.b32  	%r4279, %r4208, %r4276;
	shl.b32 	%r4280, %r4279, 1;
	add.s32 	%r5517, %r4192, %r4280;
	add.s32 	%r5522, %r5517, 4096;
	add.s32 	%r5527, %r5517, 8192;
	add.s32 	%r5532, %r5517, 12288;
	or.b32  	%r4281, %r4213, %r4276;
	shl.b32 	%r4282, %r4281, 1;
	add.s32 	%r5537, %r4192, %r4282;
	add.s32 	%r5542, %r5537, 4096;
	add.s32 	%r5547, %r5537, 8192;
	add.s32 	%r5552, %r5537, 12288;
	or.b32  	%r4283, %r4218, %r4276;
	shl.b32 	%r4284, %r4283, 1;
	add.s32 	%r5557, %r4192, %r4284;
	add.s32 	%r5562, %r5557, 4096;
	add.s32 	%r5567, %r5557, 8192;
	add.s32 	%r5572, %r5557, 12288;
	or.b32  	%r4285, %r4223, %r4276;
	shl.b32 	%r4286, %r4285, 1;
	add.s32 	%r5577, %r4192, %r4286;
	add.s32 	%r5582, %r5577, 4096;
	add.s32 	%r5587, %r5577, 8192;
	add.s32 	%r5592, %r5577, 12288;
	or.b32  	%r4287, %r4228, %r4276;
	shl.b32 	%r4288, %r4287, 1;
	add.s32 	%r5597, %r4192, %r4288;
	add.s32 	%r5602, %r5597, 4096;
	add.s32 	%r5607, %r5597, 8192;
	add.s32 	%r5612, %r5597, 12288;
	or.b32  	%r4289, %r4233, %r4276;
	shl.b32 	%r4290, %r4289, 1;
	add.s32 	%r5617, %r4192, %r4290;
	add.s32 	%r5622, %r5617, 4096;
	add.s32 	%r5627, %r5617, 8192;
	add.s32 	%r5632, %r5617, 12288;
	or.b32  	%r4291, %r4238, %r4276;
	shl.b32 	%r4292, %r4291, 1;
	add.s32 	%r5637, %r4192, %r4292;
	add.s32 	%r5642, %r5637, 4096;
	add.s32 	%r5647, %r5637, 8192;
	add.s32 	%r5652, %r5637, 12288;
	.loc	1 231 24                        // prefix_prefill.py:231:24
	cvt.u64.u32 	%rd33, %r69;
	cvt.u64.u32 	%rd20, %r68;
	cvt.u64.u32 	%rd28, %r12;
	cvt.u64.u32 	%rd27, %r13;
	cvt.u64.u32 	%rd26, %r14;
	cvt.u64.u32 	%rd25, %r15;
	cvt.u64.u32 	%rd21, %r16;
	cvt.u64.u32 	%rd22, %r17;
	cvt.u64.u32 	%rd23, %r18;
	cvt.u64.u32 	%rd24, %r19;
	cvt.u64.u32 	%rd29, %r576;
	mov.u64 	%rd32, 16;
	mov.u64 	%rd31, 17;
	mov.u64 	%rd30, 24;
	cvt.s64.s32 	%rd34, %r4;
	cvt.s64.s32 	%rd76, %r45;
	cvt.s64.s32 	%rd74, %r46;
	cvt.s64.s32 	%rd44, %r47;
	cvt.s64.s32 	%rd42, %r48;
	mul.lo.s32 	%r7409, %r678, %r668;
	shl.b32 	%r659, %r668, 6;
	mul.lo.s32 	%r7408, %r678, %r666;
	shl.b32 	%r661, %r666, 6;
	mov.u64 	%rd551, 0;
$L__BB0_38:                             // =>This Inner Loop Header: Depth=1
	.loc	1 237 32                        // prefix_prefill.py:237:32
	or.b64  	%rd413, %rd551, %rd28;
	or.b64  	%rd414, %rd551, %rd27;
	or.b64  	%rd415, %rd551, %rd26;
	or.b64  	%rd416, %rd551, %rd25;
	or.b64  	%rd417, %rd551, %rd24;
	or.b64  	%rd418, %rd551, %rd23;
	or.b64  	%rd419, %rd551, %rd22;
	or.b64  	%rd420, %rd551, %rd21;
	.loc	1 237 51                        // prefix_prefill.py:237:51
	setp.lt.s64 	%p391, %rd420, %rd34;
	setp.lt.s64 	%p386, %rd419, %rd34;
	setp.lt.s64 	%p381, %rd418, %rd34;
	setp.lt.s64 	%p376, %rd417, %rd34;
	setp.lt.s64 	%p371, %rd416, %rd34;
	setp.lt.s64 	%p366, %rd415, %rd34;
	setp.lt.s64 	%p361, %rd414, %rd34;
	setp.lt.s64 	%p356, %rd413, %rd34;
	.loc	1 235 20                        // prefix_prefill.py:235:20
	mul.wide.s32 	%rd421, %r7408, 2;
	add.s64 	%rd397, %rd4, %rd421;
	add.s64 	%rd398, %rd5, %rd421;
	add.s64 	%rd399, %rd6, %rd421;
	add.s64 	%rd400, %rd7, %rd421;
	add.s64 	%rd401, %rd8, %rd421;
	add.s64 	%rd402, %rd9, %rd421;
	add.s64 	%rd403, %rd10, %rd421;
	add.s64 	%rd404, %rd11, %rd421;
	.loc	1 234 20                        // prefix_prefill.py:234:20
	// begin inline asm
	mov.u32 %r4293, 0x0;
	mov.u32 %r4294, 0x0;
	mov.u32 %r4295, 0x0;
	mov.u32 %r4296, 0x0;
	@%p356 ld.global.v4.b32 { %r4293, %r4294, %r4295, %r4296 }, [ %rd397 + 0 ];
	@!%p356 mov.u32 %r4293, %r684;
	@!%p356 mov.u32 %r4294, %r684;
	@!%p356 mov.u32 %r4295, %r684;
	@!%p356 mov.u32 %r4296, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r4301, 0x0;
	mov.u32 %r4302, 0x0;
	mov.u32 %r4303, 0x0;
	mov.u32 %r4304, 0x0;
	@%p361 ld.global.v4.b32 { %r4301, %r4302, %r4303, %r4304 }, [ %rd398 + 0 ];
	@!%p361 mov.u32 %r4301, %r684;
	@!%p361 mov.u32 %r4302, %r684;
	@!%p361 mov.u32 %r4303, %r684;
	@!%p361 mov.u32 %r4304, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r4309, 0x0;
	mov.u32 %r4310, 0x0;
	mov.u32 %r4311, 0x0;
	mov.u32 %r4312, 0x0;
	@%p366 ld.global.v4.b32 { %r4309, %r4310, %r4311, %r4312 }, [ %rd399 + 0 ];
	@!%p366 mov.u32 %r4309, %r684;
	@!%p366 mov.u32 %r4310, %r684;
	@!%p366 mov.u32 %r4311, %r684;
	@!%p366 mov.u32 %r4312, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r4317, 0x0;
	mov.u32 %r4318, 0x0;
	mov.u32 %r4319, 0x0;
	mov.u32 %r4320, 0x0;
	@%p371 ld.global.v4.b32 { %r4317, %r4318, %r4319, %r4320 }, [ %rd400 + 0 ];
	@!%p371 mov.u32 %r4317, %r684;
	@!%p371 mov.u32 %r4318, %r684;
	@!%p371 mov.u32 %r4319, %r684;
	@!%p371 mov.u32 %r4320, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r4325, 0x0;
	mov.u32 %r4326, 0x0;
	mov.u32 %r4327, 0x0;
	mov.u32 %r4328, 0x0;
	@%p376 ld.global.v4.b32 { %r4325, %r4326, %r4327, %r4328 }, [ %rd401 + 0 ];
	@!%p376 mov.u32 %r4325, %r684;
	@!%p376 mov.u32 %r4326, %r684;
	@!%p376 mov.u32 %r4327, %r684;
	@!%p376 mov.u32 %r4328, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r4333, 0x0;
	mov.u32 %r4334, 0x0;
	mov.u32 %r4335, 0x0;
	mov.u32 %r4336, 0x0;
	@%p381 ld.global.v4.b32 { %r4333, %r4334, %r4335, %r4336 }, [ %rd402 + 0 ];
	@!%p381 mov.u32 %r4333, %r684;
	@!%p381 mov.u32 %r4334, %r684;
	@!%p381 mov.u32 %r4335, %r684;
	@!%p381 mov.u32 %r4336, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r4341, 0x0;
	mov.u32 %r4342, 0x0;
	mov.u32 %r4343, 0x0;
	mov.u32 %r4344, 0x0;
	@%p386 ld.global.v4.b32 { %r4341, %r4342, %r4343, %r4344 }, [ %rd403 + 0 ];
	@!%p386 mov.u32 %r4341, %r684;
	@!%p386 mov.u32 %r4342, %r684;
	@!%p386 mov.u32 %r4343, %r684;
	@!%p386 mov.u32 %r4344, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r4349, 0x0;
	mov.u32 %r4350, 0x0;
	mov.u32 %r4351, 0x0;
	mov.u32 %r4352, 0x0;
	@%p391 ld.global.v4.b32 { %r4349, %r4350, %r4351, %r4352 }, [ %rd404 + 0 ];
	@!%p391 mov.u32 %r4349, %r684;
	@!%p391 mov.u32 %r4350, %r684;
	@!%p391 mov.u32 %r4351, %r684;
	@!%p391 mov.u32 %r4352, %r684;
	// end inline asm
	bar.sync 	0;
	st.shared.v4.b32 	[%r577], {%r4293, %r4294, %r4295, %r4296};
	st.shared.v4.b32 	[%r577+2048], {%r4301, %r4302, %r4303, %r4304};
	st.shared.v4.b32 	[%r577+4096], {%r4309, %r4310, %r4311, %r4312};
	st.shared.v4.b32 	[%r577+6144], {%r4317, %r4318, %r4319, %r4320};
	st.shared.v4.b32 	[%r577+8192], {%r4325, %r4326, %r4327, %r4328};
	st.shared.v4.b32 	[%r577+10240], {%r4333, %r4334, %r4335, %r4336};
	st.shared.v4.b32 	[%r577+12288], {%r4341, %r4342, %r4343, %r4344};
	st.shared.v4.b32 	[%r577+14336], {%r4349, %r4350, %r4351, %r4352};
	.loc	1 123 16                        // prefix_prefill.py:123:16
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4597, %r4598, %r4599, %r4600 }, [ %r4361 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4693, %r4694, %r4695, %r4696 }, [ %r4366 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4789, %r4790, %r4791, %r4792 }, [ %r4371 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4885, %r4886, %r4887, %r4888 }, [ %r4376 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4981, %r4982, %r4983, %r4984 }, [ %r4381 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r5077, %r5078, %r5079, %r5080 }, [ %r4386 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r5173, %r5174, %r5175, %r5176 }, [ %r4391 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r5269, %r5270, %r5271, %r5272 }, [ %r4396 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4645, %r4646, %r4647, %r4648 }, [ %r4401 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4741, %r4742, %r4743, %r4744 }, [ %r4406 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4837, %r4838, %r4839, %r4840 }, [ %r4411 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4933, %r4934, %r4935, %r4936 }, [ %r4416 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r5029, %r5030, %r5031, %r5032 }, [ %r4421 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r5125, %r5126, %r5127, %r5128 }, [ %r4426 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r5221, %r5222, %r5223, %r5224 }, [ %r4431 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r5317, %r5318, %r5319, %r5320 }, [ %r4436 + 0 ];
	// end inline asm
	.loc	1 234 20                        // prefix_prefill.py:234:20
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4601, %r4602, %r4607, %r4608 }, [ %r4441 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4697, %r4698, %r4703, %r4704 }, [ %r4446 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4793, %r4794, %r4799, %r4800 }, [ %r4451 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4889, %r4890, %r4895, %r4896 }, [ %r4456 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4985, %r4986, %r4991, %r4992 }, [ %r4461 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r5081, %r5082, %r5087, %r5088 }, [ %r4466 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r5177, %r5178, %r5183, %r5184 }, [ %r4471 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r5273, %r5274, %r5279, %r5280 }, [ %r4476 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4613, %r4614, %r4619, %r4620 }, [ %r4481 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4709, %r4710, %r4715, %r4716 }, [ %r4486 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4805, %r4806, %r4811, %r4812 }, [ %r4491 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4901, %r4902, %r4907, %r4908 }, [ %r4496 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4997, %r4998, %r5003, %r5004 }, [ %r4501 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r5093, %r5094, %r5099, %r5100 }, [ %r4506 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r5189, %r5190, %r5195, %r5196 }, [ %r4511 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r5285, %r5286, %r5291, %r5292 }, [ %r4516 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4625, %r4626, %r4631, %r4632 }, [ %r4521 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4721, %r4722, %r4727, %r4728 }, [ %r4526 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4817, %r4818, %r4823, %r4824 }, [ %r4531 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4913, %r4914, %r4919, %r4920 }, [ %r4536 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r5009, %r5010, %r5015, %r5016 }, [ %r4541 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r5105, %r5106, %r5111, %r5112 }, [ %r4546 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r5201, %r5202, %r5207, %r5208 }, [ %r4551 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r5297, %r5298, %r5303, %r5304 }, [ %r4556 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4637, %r4638, %r4643, %r4644 }, [ %r4561 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4733, %r4734, %r4739, %r4740 }, [ %r4566 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4829, %r4830, %r4835, %r4836 }, [ %r4571 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r4925, %r4926, %r4931, %r4932 }, [ %r4576 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r5021, %r5022, %r5027, %r5028 }, [ %r4581 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r5117, %r5118, %r5123, %r5124 }, [ %r4586 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r5213, %r5214, %r5219, %r5220 }, [ %r4591 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.shared.b16 { %r5309, %r5310, %r5315, %r5316 }, [ %r4596 + 0 ];
	// end inline asm
	mov.f32 	%f5968, 0f00000000;
	.loc	1 241 23                        // prefix_prefill.py:241:23
	mov.f32 	%f5848, %f5968;
	mov.f32 	%f5849, %f5968;
	mov.f32 	%f5850, %f5968;
	mov.f32 	%f5851, %f5968;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5848, %f5849, %f5850, %f5851 }, { %r4597, %r4598, %r4599, %r4600 }, { %r4601, %r4602 }, { %f5848, %f5849, %f5850, %f5851 };
	// end inline asm
	mov.f32 	%f5856, %f5968;
	mov.f32 	%f5857, %f5968;
	mov.f32 	%f5858, %f5968;
	mov.f32 	%f5859, %f5968;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5856, %f5857, %f5858, %f5859 }, { %r4597, %r4598, %r4599, %r4600 }, { %r4607, %r4608 }, { %f5856, %f5857, %f5858, %f5859 };
	// end inline asm
	mov.f32 	%f5864, %f5968;
	mov.f32 	%f5865, %f5968;
	mov.f32 	%f5866, %f5968;
	mov.f32 	%f5867, %f5968;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5864, %f5865, %f5866, %f5867 }, { %r4597, %r4598, %r4599, %r4600 }, { %r4613, %r4614 }, { %f5864, %f5865, %f5866, %f5867 };
	// end inline asm
	mov.f32 	%f5872, %f5968;
	mov.f32 	%f5873, %f5968;
	mov.f32 	%f5874, %f5968;
	mov.f32 	%f5875, %f5968;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5872, %f5873, %f5874, %f5875 }, { %r4597, %r4598, %r4599, %r4600 }, { %r4619, %r4620 }, { %f5872, %f5873, %f5874, %f5875 };
	// end inline asm
	mov.f32 	%f5880, %f5968;
	mov.f32 	%f5881, %f5968;
	mov.f32 	%f5882, %f5968;
	mov.f32 	%f5883, %f5968;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5880, %f5881, %f5882, %f5883 }, { %r4597, %r4598, %r4599, %r4600 }, { %r4625, %r4626 }, { %f5880, %f5881, %f5882, %f5883 };
	// end inline asm
	mov.f32 	%f5888, %f5968;
	mov.f32 	%f5889, %f5968;
	mov.f32 	%f5890, %f5968;
	mov.f32 	%f5891, %f5968;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5888, %f5889, %f5890, %f5891 }, { %r4597, %r4598, %r4599, %r4600 }, { %r4631, %r4632 }, { %f5888, %f5889, %f5890, %f5891 };
	// end inline asm
	mov.f32 	%f5896, %f5968;
	mov.f32 	%f5897, %f5968;
	mov.f32 	%f5898, %f5968;
	mov.f32 	%f5899, %f5968;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5896, %f5897, %f5898, %f5899 }, { %r4597, %r4598, %r4599, %r4600 }, { %r4637, %r4638 }, { %f5896, %f5897, %f5898, %f5899 };
	// end inline asm
	mov.f32 	%f5904, %f5968;
	mov.f32 	%f5905, %f5968;
	mov.f32 	%f5906, %f5968;
	mov.f32 	%f5907, %f5968;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5904, %f5905, %f5906, %f5907 }, { %r4597, %r4598, %r4599, %r4600 }, { %r4643, %r4644 }, { %f5904, %f5905, %f5906, %f5907 };
	// end inline asm
	mov.f32 	%f5912, %f5968;
	mov.f32 	%f5913, %f5968;
	mov.f32 	%f5914, %f5968;
	mov.f32 	%f5915, %f5968;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5912, %f5913, %f5914, %f5915 }, { %r4645, %r4646, %r4647, %r4648 }, { %r4601, %r4602 }, { %f5912, %f5913, %f5914, %f5915 };
	// end inline asm
	mov.f32 	%f5920, %f5968;
	mov.f32 	%f5921, %f5968;
	mov.f32 	%f5922, %f5968;
	mov.f32 	%f5923, %f5968;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5920, %f5921, %f5922, %f5923 }, { %r4645, %r4646, %r4647, %r4648 }, { %r4607, %r4608 }, { %f5920, %f5921, %f5922, %f5923 };
	// end inline asm
	mov.f32 	%f5928, %f5968;
	mov.f32 	%f5929, %f5968;
	mov.f32 	%f5930, %f5968;
	mov.f32 	%f5931, %f5968;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5928, %f5929, %f5930, %f5931 }, { %r4645, %r4646, %r4647, %r4648 }, { %r4613, %r4614 }, { %f5928, %f5929, %f5930, %f5931 };
	// end inline asm
	mov.f32 	%f5936, %f5968;
	mov.f32 	%f5937, %f5968;
	mov.f32 	%f5938, %f5968;
	mov.f32 	%f5939, %f5968;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5936, %f5937, %f5938, %f5939 }, { %r4645, %r4646, %r4647, %r4648 }, { %r4619, %r4620 }, { %f5936, %f5937, %f5938, %f5939 };
	// end inline asm
	mov.f32 	%f5944, %f5968;
	mov.f32 	%f5945, %f5968;
	mov.f32 	%f5946, %f5968;
	mov.f32 	%f5947, %f5968;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5944, %f5945, %f5946, %f5947 }, { %r4645, %r4646, %r4647, %r4648 }, { %r4625, %r4626 }, { %f5944, %f5945, %f5946, %f5947 };
	// end inline asm
	mov.f32 	%f5952, %f5968;
	mov.f32 	%f5953, %f5968;
	mov.f32 	%f5954, %f5968;
	mov.f32 	%f5955, %f5968;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5952, %f5953, %f5954, %f5955 }, { %r4645, %r4646, %r4647, %r4648 }, { %r4631, %r4632 }, { %f5952, %f5953, %f5954, %f5955 };
	// end inline asm
	mov.f32 	%f5960, %f5968;
	mov.f32 	%f5961, %f5968;
	mov.f32 	%f5962, %f5968;
	mov.f32 	%f5963, %f5968;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5960, %f5961, %f5962, %f5963 }, { %r4645, %r4646, %r4647, %r4648 }, { %r4637, %r4638 }, { %f5960, %f5961, %f5962, %f5963 };
	// end inline asm
	mov.f32 	%f5969, %f5968;
	mov.f32 	%f5970, %f5968;
	mov.f32 	%f5971, %f5968;
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5968, %f5969, %f5970, %f5971 }, { %r4645, %r4646, %r4647, %r4648 }, { %r4643, %r4644 }, { %f5968, %f5969, %f5970, %f5971 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5848, %f5849, %f5850, %f5851 }, { %r4693, %r4694, %r4695, %r4696 }, { %r4697, %r4698 }, { %f5848, %f5849, %f5850, %f5851 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5856, %f5857, %f5858, %f5859 }, { %r4693, %r4694, %r4695, %r4696 }, { %r4703, %r4704 }, { %f5856, %f5857, %f5858, %f5859 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5864, %f5865, %f5866, %f5867 }, { %r4693, %r4694, %r4695, %r4696 }, { %r4709, %r4710 }, { %f5864, %f5865, %f5866, %f5867 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5872, %f5873, %f5874, %f5875 }, { %r4693, %r4694, %r4695, %r4696 }, { %r4715, %r4716 }, { %f5872, %f5873, %f5874, %f5875 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5880, %f5881, %f5882, %f5883 }, { %r4693, %r4694, %r4695, %r4696 }, { %r4721, %r4722 }, { %f5880, %f5881, %f5882, %f5883 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5888, %f5889, %f5890, %f5891 }, { %r4693, %r4694, %r4695, %r4696 }, { %r4727, %r4728 }, { %f5888, %f5889, %f5890, %f5891 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5896, %f5897, %f5898, %f5899 }, { %r4693, %r4694, %r4695, %r4696 }, { %r4733, %r4734 }, { %f5896, %f5897, %f5898, %f5899 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5904, %f5905, %f5906, %f5907 }, { %r4693, %r4694, %r4695, %r4696 }, { %r4739, %r4740 }, { %f5904, %f5905, %f5906, %f5907 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5912, %f5913, %f5914, %f5915 }, { %r4741, %r4742, %r4743, %r4744 }, { %r4697, %r4698 }, { %f5912, %f5913, %f5914, %f5915 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5920, %f5921, %f5922, %f5923 }, { %r4741, %r4742, %r4743, %r4744 }, { %r4703, %r4704 }, { %f5920, %f5921, %f5922, %f5923 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5928, %f5929, %f5930, %f5931 }, { %r4741, %r4742, %r4743, %r4744 }, { %r4709, %r4710 }, { %f5928, %f5929, %f5930, %f5931 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5936, %f5937, %f5938, %f5939 }, { %r4741, %r4742, %r4743, %r4744 }, { %r4715, %r4716 }, { %f5936, %f5937, %f5938, %f5939 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5944, %f5945, %f5946, %f5947 }, { %r4741, %r4742, %r4743, %r4744 }, { %r4721, %r4722 }, { %f5944, %f5945, %f5946, %f5947 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5952, %f5953, %f5954, %f5955 }, { %r4741, %r4742, %r4743, %r4744 }, { %r4727, %r4728 }, { %f5952, %f5953, %f5954, %f5955 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5960, %f5961, %f5962, %f5963 }, { %r4741, %r4742, %r4743, %r4744 }, { %r4733, %r4734 }, { %f5960, %f5961, %f5962, %f5963 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5968, %f5969, %f5970, %f5971 }, { %r4741, %r4742, %r4743, %r4744 }, { %r4739, %r4740 }, { %f5968, %f5969, %f5970, %f5971 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5848, %f5849, %f5850, %f5851 }, { %r4789, %r4790, %r4791, %r4792 }, { %r4793, %r4794 }, { %f5848, %f5849, %f5850, %f5851 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5856, %f5857, %f5858, %f5859 }, { %r4789, %r4790, %r4791, %r4792 }, { %r4799, %r4800 }, { %f5856, %f5857, %f5858, %f5859 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5864, %f5865, %f5866, %f5867 }, { %r4789, %r4790, %r4791, %r4792 }, { %r4805, %r4806 }, { %f5864, %f5865, %f5866, %f5867 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5872, %f5873, %f5874, %f5875 }, { %r4789, %r4790, %r4791, %r4792 }, { %r4811, %r4812 }, { %f5872, %f5873, %f5874, %f5875 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5880, %f5881, %f5882, %f5883 }, { %r4789, %r4790, %r4791, %r4792 }, { %r4817, %r4818 }, { %f5880, %f5881, %f5882, %f5883 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5888, %f5889, %f5890, %f5891 }, { %r4789, %r4790, %r4791, %r4792 }, { %r4823, %r4824 }, { %f5888, %f5889, %f5890, %f5891 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5896, %f5897, %f5898, %f5899 }, { %r4789, %r4790, %r4791, %r4792 }, { %r4829, %r4830 }, { %f5896, %f5897, %f5898, %f5899 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5904, %f5905, %f5906, %f5907 }, { %r4789, %r4790, %r4791, %r4792 }, { %r4835, %r4836 }, { %f5904, %f5905, %f5906, %f5907 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5912, %f5913, %f5914, %f5915 }, { %r4837, %r4838, %r4839, %r4840 }, { %r4793, %r4794 }, { %f5912, %f5913, %f5914, %f5915 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5920, %f5921, %f5922, %f5923 }, { %r4837, %r4838, %r4839, %r4840 }, { %r4799, %r4800 }, { %f5920, %f5921, %f5922, %f5923 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5928, %f5929, %f5930, %f5931 }, { %r4837, %r4838, %r4839, %r4840 }, { %r4805, %r4806 }, { %f5928, %f5929, %f5930, %f5931 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5936, %f5937, %f5938, %f5939 }, { %r4837, %r4838, %r4839, %r4840 }, { %r4811, %r4812 }, { %f5936, %f5937, %f5938, %f5939 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5944, %f5945, %f5946, %f5947 }, { %r4837, %r4838, %r4839, %r4840 }, { %r4817, %r4818 }, { %f5944, %f5945, %f5946, %f5947 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5952, %f5953, %f5954, %f5955 }, { %r4837, %r4838, %r4839, %r4840 }, { %r4823, %r4824 }, { %f5952, %f5953, %f5954, %f5955 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5960, %f5961, %f5962, %f5963 }, { %r4837, %r4838, %r4839, %r4840 }, { %r4829, %r4830 }, { %f5960, %f5961, %f5962, %f5963 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5968, %f5969, %f5970, %f5971 }, { %r4837, %r4838, %r4839, %r4840 }, { %r4835, %r4836 }, { %f5968, %f5969, %f5970, %f5971 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5848, %f5849, %f5850, %f5851 }, { %r4885, %r4886, %r4887, %r4888 }, { %r4889, %r4890 }, { %f5848, %f5849, %f5850, %f5851 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5856, %f5857, %f5858, %f5859 }, { %r4885, %r4886, %r4887, %r4888 }, { %r4895, %r4896 }, { %f5856, %f5857, %f5858, %f5859 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5864, %f5865, %f5866, %f5867 }, { %r4885, %r4886, %r4887, %r4888 }, { %r4901, %r4902 }, { %f5864, %f5865, %f5866, %f5867 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5872, %f5873, %f5874, %f5875 }, { %r4885, %r4886, %r4887, %r4888 }, { %r4907, %r4908 }, { %f5872, %f5873, %f5874, %f5875 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5880, %f5881, %f5882, %f5883 }, { %r4885, %r4886, %r4887, %r4888 }, { %r4913, %r4914 }, { %f5880, %f5881, %f5882, %f5883 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5888, %f5889, %f5890, %f5891 }, { %r4885, %r4886, %r4887, %r4888 }, { %r4919, %r4920 }, { %f5888, %f5889, %f5890, %f5891 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5896, %f5897, %f5898, %f5899 }, { %r4885, %r4886, %r4887, %r4888 }, { %r4925, %r4926 }, { %f5896, %f5897, %f5898, %f5899 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5904, %f5905, %f5906, %f5907 }, { %r4885, %r4886, %r4887, %r4888 }, { %r4931, %r4932 }, { %f5904, %f5905, %f5906, %f5907 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5912, %f5913, %f5914, %f5915 }, { %r4933, %r4934, %r4935, %r4936 }, { %r4889, %r4890 }, { %f5912, %f5913, %f5914, %f5915 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5920, %f5921, %f5922, %f5923 }, { %r4933, %r4934, %r4935, %r4936 }, { %r4895, %r4896 }, { %f5920, %f5921, %f5922, %f5923 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5928, %f5929, %f5930, %f5931 }, { %r4933, %r4934, %r4935, %r4936 }, { %r4901, %r4902 }, { %f5928, %f5929, %f5930, %f5931 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5936, %f5937, %f5938, %f5939 }, { %r4933, %r4934, %r4935, %r4936 }, { %r4907, %r4908 }, { %f5936, %f5937, %f5938, %f5939 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5944, %f5945, %f5946, %f5947 }, { %r4933, %r4934, %r4935, %r4936 }, { %r4913, %r4914 }, { %f5944, %f5945, %f5946, %f5947 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5952, %f5953, %f5954, %f5955 }, { %r4933, %r4934, %r4935, %r4936 }, { %r4919, %r4920 }, { %f5952, %f5953, %f5954, %f5955 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5960, %f5961, %f5962, %f5963 }, { %r4933, %r4934, %r4935, %r4936 }, { %r4925, %r4926 }, { %f5960, %f5961, %f5962, %f5963 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5968, %f5969, %f5970, %f5971 }, { %r4933, %r4934, %r4935, %r4936 }, { %r4931, %r4932 }, { %f5968, %f5969, %f5970, %f5971 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5848, %f5849, %f5850, %f5851 }, { %r4981, %r4982, %r4983, %r4984 }, { %r4985, %r4986 }, { %f5848, %f5849, %f5850, %f5851 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5856, %f5857, %f5858, %f5859 }, { %r4981, %r4982, %r4983, %r4984 }, { %r4991, %r4992 }, { %f5856, %f5857, %f5858, %f5859 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5864, %f5865, %f5866, %f5867 }, { %r4981, %r4982, %r4983, %r4984 }, { %r4997, %r4998 }, { %f5864, %f5865, %f5866, %f5867 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5872, %f5873, %f5874, %f5875 }, { %r4981, %r4982, %r4983, %r4984 }, { %r5003, %r5004 }, { %f5872, %f5873, %f5874, %f5875 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5880, %f5881, %f5882, %f5883 }, { %r4981, %r4982, %r4983, %r4984 }, { %r5009, %r5010 }, { %f5880, %f5881, %f5882, %f5883 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5888, %f5889, %f5890, %f5891 }, { %r4981, %r4982, %r4983, %r4984 }, { %r5015, %r5016 }, { %f5888, %f5889, %f5890, %f5891 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5896, %f5897, %f5898, %f5899 }, { %r4981, %r4982, %r4983, %r4984 }, { %r5021, %r5022 }, { %f5896, %f5897, %f5898, %f5899 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5904, %f5905, %f5906, %f5907 }, { %r4981, %r4982, %r4983, %r4984 }, { %r5027, %r5028 }, { %f5904, %f5905, %f5906, %f5907 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5912, %f5913, %f5914, %f5915 }, { %r5029, %r5030, %r5031, %r5032 }, { %r4985, %r4986 }, { %f5912, %f5913, %f5914, %f5915 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5920, %f5921, %f5922, %f5923 }, { %r5029, %r5030, %r5031, %r5032 }, { %r4991, %r4992 }, { %f5920, %f5921, %f5922, %f5923 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5928, %f5929, %f5930, %f5931 }, { %r5029, %r5030, %r5031, %r5032 }, { %r4997, %r4998 }, { %f5928, %f5929, %f5930, %f5931 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5936, %f5937, %f5938, %f5939 }, { %r5029, %r5030, %r5031, %r5032 }, { %r5003, %r5004 }, { %f5936, %f5937, %f5938, %f5939 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5944, %f5945, %f5946, %f5947 }, { %r5029, %r5030, %r5031, %r5032 }, { %r5009, %r5010 }, { %f5944, %f5945, %f5946, %f5947 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5952, %f5953, %f5954, %f5955 }, { %r5029, %r5030, %r5031, %r5032 }, { %r5015, %r5016 }, { %f5952, %f5953, %f5954, %f5955 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5960, %f5961, %f5962, %f5963 }, { %r5029, %r5030, %r5031, %r5032 }, { %r5021, %r5022 }, { %f5960, %f5961, %f5962, %f5963 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5968, %f5969, %f5970, %f5971 }, { %r5029, %r5030, %r5031, %r5032 }, { %r5027, %r5028 }, { %f5968, %f5969, %f5970, %f5971 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5848, %f5849, %f5850, %f5851 }, { %r5077, %r5078, %r5079, %r5080 }, { %r5081, %r5082 }, { %f5848, %f5849, %f5850, %f5851 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5856, %f5857, %f5858, %f5859 }, { %r5077, %r5078, %r5079, %r5080 }, { %r5087, %r5088 }, { %f5856, %f5857, %f5858, %f5859 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5864, %f5865, %f5866, %f5867 }, { %r5077, %r5078, %r5079, %r5080 }, { %r5093, %r5094 }, { %f5864, %f5865, %f5866, %f5867 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5872, %f5873, %f5874, %f5875 }, { %r5077, %r5078, %r5079, %r5080 }, { %r5099, %r5100 }, { %f5872, %f5873, %f5874, %f5875 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5880, %f5881, %f5882, %f5883 }, { %r5077, %r5078, %r5079, %r5080 }, { %r5105, %r5106 }, { %f5880, %f5881, %f5882, %f5883 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5888, %f5889, %f5890, %f5891 }, { %r5077, %r5078, %r5079, %r5080 }, { %r5111, %r5112 }, { %f5888, %f5889, %f5890, %f5891 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5896, %f5897, %f5898, %f5899 }, { %r5077, %r5078, %r5079, %r5080 }, { %r5117, %r5118 }, { %f5896, %f5897, %f5898, %f5899 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5904, %f5905, %f5906, %f5907 }, { %r5077, %r5078, %r5079, %r5080 }, { %r5123, %r5124 }, { %f5904, %f5905, %f5906, %f5907 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5912, %f5913, %f5914, %f5915 }, { %r5125, %r5126, %r5127, %r5128 }, { %r5081, %r5082 }, { %f5912, %f5913, %f5914, %f5915 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5920, %f5921, %f5922, %f5923 }, { %r5125, %r5126, %r5127, %r5128 }, { %r5087, %r5088 }, { %f5920, %f5921, %f5922, %f5923 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5928, %f5929, %f5930, %f5931 }, { %r5125, %r5126, %r5127, %r5128 }, { %r5093, %r5094 }, { %f5928, %f5929, %f5930, %f5931 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5936, %f5937, %f5938, %f5939 }, { %r5125, %r5126, %r5127, %r5128 }, { %r5099, %r5100 }, { %f5936, %f5937, %f5938, %f5939 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5944, %f5945, %f5946, %f5947 }, { %r5125, %r5126, %r5127, %r5128 }, { %r5105, %r5106 }, { %f5944, %f5945, %f5946, %f5947 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5952, %f5953, %f5954, %f5955 }, { %r5125, %r5126, %r5127, %r5128 }, { %r5111, %r5112 }, { %f5952, %f5953, %f5954, %f5955 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5960, %f5961, %f5962, %f5963 }, { %r5125, %r5126, %r5127, %r5128 }, { %r5117, %r5118 }, { %f5960, %f5961, %f5962, %f5963 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5968, %f5969, %f5970, %f5971 }, { %r5125, %r5126, %r5127, %r5128 }, { %r5123, %r5124 }, { %f5968, %f5969, %f5970, %f5971 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5848, %f5849, %f5850, %f5851 }, { %r5173, %r5174, %r5175, %r5176 }, { %r5177, %r5178 }, { %f5848, %f5849, %f5850, %f5851 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5856, %f5857, %f5858, %f5859 }, { %r5173, %r5174, %r5175, %r5176 }, { %r5183, %r5184 }, { %f5856, %f5857, %f5858, %f5859 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5864, %f5865, %f5866, %f5867 }, { %r5173, %r5174, %r5175, %r5176 }, { %r5189, %r5190 }, { %f5864, %f5865, %f5866, %f5867 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5872, %f5873, %f5874, %f5875 }, { %r5173, %r5174, %r5175, %r5176 }, { %r5195, %r5196 }, { %f5872, %f5873, %f5874, %f5875 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5880, %f5881, %f5882, %f5883 }, { %r5173, %r5174, %r5175, %r5176 }, { %r5201, %r5202 }, { %f5880, %f5881, %f5882, %f5883 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5888, %f5889, %f5890, %f5891 }, { %r5173, %r5174, %r5175, %r5176 }, { %r5207, %r5208 }, { %f5888, %f5889, %f5890, %f5891 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5896, %f5897, %f5898, %f5899 }, { %r5173, %r5174, %r5175, %r5176 }, { %r5213, %r5214 }, { %f5896, %f5897, %f5898, %f5899 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5904, %f5905, %f5906, %f5907 }, { %r5173, %r5174, %r5175, %r5176 }, { %r5219, %r5220 }, { %f5904, %f5905, %f5906, %f5907 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5912, %f5913, %f5914, %f5915 }, { %r5221, %r5222, %r5223, %r5224 }, { %r5177, %r5178 }, { %f5912, %f5913, %f5914, %f5915 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5920, %f5921, %f5922, %f5923 }, { %r5221, %r5222, %r5223, %r5224 }, { %r5183, %r5184 }, { %f5920, %f5921, %f5922, %f5923 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5928, %f5929, %f5930, %f5931 }, { %r5221, %r5222, %r5223, %r5224 }, { %r5189, %r5190 }, { %f5928, %f5929, %f5930, %f5931 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5936, %f5937, %f5938, %f5939 }, { %r5221, %r5222, %r5223, %r5224 }, { %r5195, %r5196 }, { %f5936, %f5937, %f5938, %f5939 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5944, %f5945, %f5946, %f5947 }, { %r5221, %r5222, %r5223, %r5224 }, { %r5201, %r5202 }, { %f5944, %f5945, %f5946, %f5947 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5952, %f5953, %f5954, %f5955 }, { %r5221, %r5222, %r5223, %r5224 }, { %r5207, %r5208 }, { %f5952, %f5953, %f5954, %f5955 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5960, %f5961, %f5962, %f5963 }, { %r5221, %r5222, %r5223, %r5224 }, { %r5213, %r5214 }, { %f5960, %f5961, %f5962, %f5963 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5968, %f5969, %f5970, %f5971 }, { %r5221, %r5222, %r5223, %r5224 }, { %r5219, %r5220 }, { %f5968, %f5969, %f5970, %f5971 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5848, %f5849, %f5850, %f5851 }, { %r5269, %r5270, %r5271, %r5272 }, { %r5273, %r5274 }, { %f5848, %f5849, %f5850, %f5851 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5856, %f5857, %f5858, %f5859 }, { %r5269, %r5270, %r5271, %r5272 }, { %r5279, %r5280 }, { %f5856, %f5857, %f5858, %f5859 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5864, %f5865, %f5866, %f5867 }, { %r5269, %r5270, %r5271, %r5272 }, { %r5285, %r5286 }, { %f5864, %f5865, %f5866, %f5867 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5872, %f5873, %f5874, %f5875 }, { %r5269, %r5270, %r5271, %r5272 }, { %r5291, %r5292 }, { %f5872, %f5873, %f5874, %f5875 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5880, %f5881, %f5882, %f5883 }, { %r5269, %r5270, %r5271, %r5272 }, { %r5297, %r5298 }, { %f5880, %f5881, %f5882, %f5883 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5888, %f5889, %f5890, %f5891 }, { %r5269, %r5270, %r5271, %r5272 }, { %r5303, %r5304 }, { %f5888, %f5889, %f5890, %f5891 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5896, %f5897, %f5898, %f5899 }, { %r5269, %r5270, %r5271, %r5272 }, { %r5309, %r5310 }, { %f5896, %f5897, %f5898, %f5899 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5904, %f5905, %f5906, %f5907 }, { %r5269, %r5270, %r5271, %r5272 }, { %r5315, %r5316 }, { %f5904, %f5905, %f5906, %f5907 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5912, %f5913, %f5914, %f5915 }, { %r5317, %r5318, %r5319, %r5320 }, { %r5273, %r5274 }, { %f5912, %f5913, %f5914, %f5915 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5920, %f5921, %f5922, %f5923 }, { %r5317, %r5318, %r5319, %r5320 }, { %r5279, %r5280 }, { %f5920, %f5921, %f5922, %f5923 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5928, %f5929, %f5930, %f5931 }, { %r5317, %r5318, %r5319, %r5320 }, { %r5285, %r5286 }, { %f5928, %f5929, %f5930, %f5931 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5936, %f5937, %f5938, %f5939 }, { %r5317, %r5318, %r5319, %r5320 }, { %r5291, %r5292 }, { %f5936, %f5937, %f5938, %f5939 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5944, %f5945, %f5946, %f5947 }, { %r5317, %r5318, %r5319, %r5320 }, { %r5297, %r5298 }, { %f5944, %f5945, %f5946, %f5947 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5952, %f5953, %f5954, %f5955 }, { %r5317, %r5318, %r5319, %r5320 }, { %r5303, %r5304 }, { %f5952, %f5953, %f5954, %f5955 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5960, %f5961, %f5962, %f5963 }, { %r5317, %r5318, %r5319, %r5320 }, { %r5309, %r5310 }, { %f5960, %f5961, %f5962, %f5963 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f5968, %f5969, %f5970, %f5971 }, { %r5317, %r5318, %r5319, %r5320 }, { %r5315, %r5316 }, { %f5968, %f5969, %f5970, %f5971 };
	// end inline asm
	.loc	1 242 14                        // prefix_prefill.py:242:14
	mul.f32 	%f7904, %f2401, %f5848;
	mul.f32 	%f7905, %f2401, %f5849;
	mul.f32 	%f7906, %f2401, %f5850;
	mul.f32 	%f7907, %f2401, %f5851;
	mul.f32 	%f7908, %f2401, %f5856;
	mul.f32 	%f7909, %f2401, %f5857;
	mul.f32 	%f7910, %f2401, %f5858;
	mul.f32 	%f7911, %f2401, %f5859;
	mul.f32 	%f7912, %f2401, %f5864;
	mul.f32 	%f7913, %f2401, %f5865;
	mul.f32 	%f7914, %f2401, %f5866;
	mul.f32 	%f7915, %f2401, %f5867;
	mul.f32 	%f7916, %f2401, %f5872;
	mul.f32 	%f7917, %f2401, %f5873;
	mul.f32 	%f7918, %f2401, %f5874;
	mul.f32 	%f7919, %f2401, %f5875;
	mul.f32 	%f7920, %f2401, %f5880;
	mul.f32 	%f7921, %f2401, %f5881;
	mul.f32 	%f7922, %f2401, %f5882;
	mul.f32 	%f7923, %f2401, %f5883;
	mul.f32 	%f7924, %f2401, %f5888;
	mul.f32 	%f7925, %f2401, %f5889;
	mul.f32 	%f7926, %f2401, %f5890;
	mul.f32 	%f7927, %f2401, %f5891;
	mul.f32 	%f7928, %f2401, %f5896;
	mul.f32 	%f7929, %f2401, %f5897;
	mul.f32 	%f7930, %f2401, %f5898;
	mul.f32 	%f7931, %f2401, %f5899;
	mul.f32 	%f7932, %f2401, %f5904;
	mul.f32 	%f7933, %f2401, %f5905;
	mul.f32 	%f7934, %f2401, %f5906;
	mul.f32 	%f7935, %f2401, %f5907;
	mul.f32 	%f7936, %f2401, %f5912;
	mul.f32 	%f7937, %f2401, %f5913;
	mul.f32 	%f7938, %f2401, %f5914;
	mul.f32 	%f7939, %f2401, %f5915;
	mul.f32 	%f7940, %f2401, %f5920;
	mul.f32 	%f7941, %f2401, %f5921;
	mul.f32 	%f7942, %f2401, %f5922;
	mul.f32 	%f7943, %f2401, %f5923;
	mul.f32 	%f7944, %f2401, %f5928;
	mul.f32 	%f7945, %f2401, %f5929;
	mul.f32 	%f7946, %f2401, %f5930;
	mul.f32 	%f7947, %f2401, %f5931;
	mul.f32 	%f7948, %f2401, %f5936;
	mul.f32 	%f7949, %f2401, %f5937;
	mul.f32 	%f7950, %f2401, %f5938;
	mul.f32 	%f7951, %f2401, %f5939;
	mul.f32 	%f7952, %f2401, %f5944;
	mul.f32 	%f7953, %f2401, %f5945;
	mul.f32 	%f7954, %f2401, %f5946;
	mul.f32 	%f7955, %f2401, %f5947;
	mul.f32 	%f7956, %f2401, %f5952;
	mul.f32 	%f7957, %f2401, %f5953;
	mul.f32 	%f7958, %f2401, %f5954;
	mul.f32 	%f7959, %f2401, %f5955;
	mul.f32 	%f7960, %f2401, %f5960;
	mul.f32 	%f7961, %f2401, %f5961;
	mul.f32 	%f7962, %f2401, %f5962;
	mul.f32 	%f7963, %f2401, %f5963;
	mul.f32 	%f7964, %f2401, %f5968;
	mul.f32 	%f7965, %f2401, %f5969;
	mul.f32 	%f7966, %f2401, %f5970;
	mul.f32 	%f7967, %f2401, %f5971;
	.loc	1 237 32                        // prefix_prefill.py:237:32
	add.s64 	%rd422, %rd20, %rd551;
	add.s64 	%rd423, %rd422, 1;
	add.s64 	%rd424, %rd422, 8;
	or.b64  	%rd425, %rd422, %rd32;
	or.b64  	%rd426, %rd422, %rd31;
	or.b64  	%rd427, %rd422, %rd30;
	or.b64  	%rd428, %rd551, %rd33;
	add.s64 	%rd429, %rd422, 25;
	or.b64  	%rd430, %rd422, 48;
	or.b64  	%rd431, %rd422, 49;
	or.b64  	%rd432, %rd422, 56;
	or.b64  	%rd433, %rd422, 57;
	or.b64  	%rd434, %rd422, 32;
	or.b64  	%rd435, %rd422, 33;
	or.b64  	%rd436, %rd422, 40;
	or.b64  	%rd437, %rd422, 41;
	.loc	1 244 42                        // prefix_prefill.py:244:42
	setp.gt.s64 	%p435, %rd437, %rd44;
	selp.u16 	%rs385, 1, 0, %p435;
	shl.b16 	%rs386, %rs385, 2;
	setp.gt.s64 	%p436, %rd436, %rd44;
	selp.u16 	%rs387, -1, 0, %p436;
	shl.b16 	%rs388, %rs387, 3;
	or.b16  	%rs389, %rs388, %rs386;
	setp.gt.s64 	%p437, %rd437, %rd42;
	selp.u16 	%rs390, 1, 0, %p437;
	setp.gt.s64 	%p438, %rd436, %rd42;
	selp.u16 	%rs391, -1, 0, %p438;
	shl.b16 	%rs392, %rs391, 1;
	or.b16  	%rs393, %rs390, %rs392;
	and.b16  	%rs394, %rs393, 3;
	or.b16  	%rs395, %rs394, %rs389;
	and.b16  	%rs396, %rs395, 15;
	shl.b16 	%rs397, %rs396, 8;
	setp.gt.s64 	%p439, %rd435, %rd44;
	selp.u16 	%rs398, 1, 0, %p439;
	shl.b16 	%rs399, %rs398, 2;
	setp.gt.s64 	%p440, %rd434, %rd44;
	selp.u16 	%rs400, -1, 0, %p440;
	shl.b16 	%rs401, %rs400, 3;
	or.b16  	%rs402, %rs401, %rs399;
	setp.gt.s64 	%p441, %rd435, %rd42;
	selp.u16 	%rs403, 1, 0, %p441;
	setp.gt.s64 	%p442, %rd434, %rd42;
	selp.u16 	%rs404, -1, 0, %p442;
	shl.b16 	%rs405, %rs404, 1;
	or.b16  	%rs406, %rs403, %rs405;
	and.b16  	%rs407, %rs406, 3;
	or.b16  	%rs408, %rs407, %rs402;
	shl.b16 	%rs409, %rs408, 12;
	or.b16  	%rs410, %rs409, %rs397;
	setp.gt.s64 	%p443, %rd433, %rd44;
	selp.u16 	%rs411, 1, 0, %p443;
	shl.b16 	%rs412, %rs411, 2;
	setp.gt.s64 	%p444, %rd432, %rd44;
	selp.u16 	%rs413, -1, 0, %p444;
	shl.b16 	%rs414, %rs413, 3;
	or.b16  	%rs415, %rs414, %rs412;
	setp.gt.s64 	%p445, %rd433, %rd42;
	selp.u16 	%rs416, 1, 0, %p445;
	setp.gt.s64 	%p446, %rd432, %rd42;
	selp.u16 	%rs417, -1, 0, %p446;
	shl.b16 	%rs418, %rs417, 1;
	or.b16  	%rs419, %rs416, %rs418;
	and.b16  	%rs420, %rs419, 3;
	or.b16  	%rs421, %rs420, %rs415;
	and.b16  	%rs422, %rs421, 15;
	setp.gt.s64 	%p447, %rd431, %rd44;
	selp.u16 	%rs423, 1, 0, %p447;
	shl.b16 	%rs424, %rs423, 2;
	setp.gt.s64 	%p448, %rd430, %rd44;
	selp.u16 	%rs425, -1, 0, %p448;
	shl.b16 	%rs426, %rs425, 3;
	or.b16  	%rs427, %rs426, %rs424;
	setp.gt.s64 	%p449, %rd431, %rd42;
	selp.u16 	%rs428, 1, 0, %p449;
	setp.gt.s64 	%p450, %rd430, %rd42;
	selp.u16 	%rs429, -1, 0, %p450;
	shl.b16 	%rs430, %rs429, 1;
	or.b16  	%rs431, %rs428, %rs430;
	and.b16  	%rs432, %rs431, 3;
	or.b16  	%rs433, %rs432, %rs427;
	shl.b16 	%rs434, %rs433, 4;
	or.b16  	%rs435, %rs422, %rs434;
	and.b16  	%rs436, %rs435, 255;
	or.b16  	%rs437, %rs436, %rs410;
	cvt.u32.u16 	%r6453, %rs437;
	setp.gt.s64 	%p451, %rd428, %rd44;
	selp.u16 	%rs438, 1, 0, %p451;
	shl.b16 	%rs439, %rs438, 2;
	setp.gt.s64 	%p452, %rd424, %rd44;
	selp.u16 	%rs440, -1, 0, %p452;
	shl.b16 	%rs441, %rs440, 3;
	or.b16  	%rs442, %rs441, %rs439;
	setp.gt.s64 	%p453, %rd428, %rd42;
	selp.u16 	%rs443, 1, 0, %p453;
	setp.gt.s64 	%p454, %rd424, %rd42;
	selp.u16 	%rs444, -1, 0, %p454;
	shl.b16 	%rs445, %rs444, 1;
	or.b16  	%rs446, %rs443, %rs445;
	and.b16  	%rs447, %rs446, 3;
	or.b16  	%rs448, %rs447, %rs442;
	and.b16  	%rs449, %rs448, 15;
	shl.b16 	%rs450, %rs449, 8;
	setp.gt.s64 	%p455, %rd423, %rd44;
	selp.u16 	%rs451, 1, 0, %p455;
	shl.b16 	%rs452, %rs451, 2;
	setp.gt.s64 	%p456, %rd422, %rd44;
	selp.u16 	%rs453, -1, 0, %p456;
	shl.b16 	%rs454, %rs453, 3;
	or.b16  	%rs455, %rs454, %rs452;
	setp.gt.s64 	%p457, %rd423, %rd42;
	selp.u16 	%rs456, 1, 0, %p457;
	setp.gt.s64 	%p458, %rd422, %rd42;
	selp.u16 	%rs457, -1, 0, %p458;
	shl.b16 	%rs458, %rs457, 1;
	or.b16  	%rs459, %rs456, %rs458;
	and.b16  	%rs460, %rs459, 3;
	or.b16  	%rs461, %rs460, %rs455;
	shl.b16 	%rs462, %rs461, 12;
	or.b16  	%rs463, %rs462, %rs450;
	setp.gt.s64 	%p459, %rd429, %rd44;
	selp.u16 	%rs464, 1, 0, %p459;
	shl.b16 	%rs465, %rs464, 2;
	setp.gt.s64 	%p460, %rd427, %rd44;
	selp.u16 	%rs466, -1, 0, %p460;
	shl.b16 	%rs467, %rs466, 3;
	or.b16  	%rs468, %rs467, %rs465;
	setp.gt.s64 	%p461, %rd429, %rd42;
	selp.u16 	%rs469, 1, 0, %p461;
	setp.gt.s64 	%p462, %rd427, %rd42;
	selp.u16 	%rs470, -1, 0, %p462;
	shl.b16 	%rs471, %rs470, 1;
	or.b16  	%rs472, %rs469, %rs471;
	and.b16  	%rs473, %rs472, 3;
	or.b16  	%rs474, %rs473, %rs468;
	and.b16  	%rs475, %rs474, 15;
	setp.gt.s64 	%p463, %rd426, %rd44;
	selp.u16 	%rs476, 1, 0, %p463;
	shl.b16 	%rs477, %rs476, 2;
	setp.gt.s64 	%p464, %rd425, %rd44;
	selp.u16 	%rs478, -1, 0, %p464;
	shl.b16 	%rs479, %rs478, 3;
	or.b16  	%rs480, %rs479, %rs477;
	setp.gt.s64 	%p465, %rd426, %rd42;
	selp.u16 	%rs481, 1, 0, %p465;
	setp.gt.s64 	%p466, %rd425, %rd42;
	selp.u16 	%rs482, -1, 0, %p466;
	shl.b16 	%rs483, %rs482, 1;
	or.b16  	%rs484, %rs481, %rs483;
	and.b16  	%rs485, %rs484, 3;
	or.b16  	%rs486, %rs485, %rs480;
	shl.b16 	%rs487, %rs486, 4;
	or.b16  	%rs488, %rs475, %rs487;
	and.b16  	%rs489, %rs488, 255;
	or.b16  	%rs490, %rs489, %rs463;
	cvt.u32.u16 	%r6454, %rs490;
	shl.b32 	%r6455, %r6454, 16;
	or.b32  	%r6456, %r6453, %r6455;
	cvt.u64.u32 	%rd438, %r6456;
	setp.gt.s64 	%p467, %rd437, %rd76;
	selp.u16 	%rs491, 1, 0, %p467;
	shl.b16 	%rs492, %rs491, 2;
	setp.gt.s64 	%p468, %rd436, %rd76;
	selp.u16 	%rs493, -1, 0, %p468;
	shl.b16 	%rs494, %rs493, 3;
	or.b16  	%rs495, %rs494, %rs492;
	setp.gt.s64 	%p469, %rd437, %rd74;
	selp.u16 	%rs496, 1, 0, %p469;
	setp.gt.s64 	%p470, %rd436, %rd74;
	selp.u16 	%rs497, -1, 0, %p470;
	shl.b16 	%rs498, %rs497, 1;
	or.b16  	%rs499, %rs496, %rs498;
	and.b16  	%rs500, %rs499, 3;
	or.b16  	%rs501, %rs500, %rs495;
	and.b16  	%rs502, %rs501, 15;
	shl.b16 	%rs503, %rs502, 8;
	setp.gt.s64 	%p471, %rd435, %rd76;
	selp.u16 	%rs504, 1, 0, %p471;
	shl.b16 	%rs505, %rs504, 2;
	setp.gt.s64 	%p472, %rd434, %rd76;
	selp.u16 	%rs506, -1, 0, %p472;
	shl.b16 	%rs507, %rs506, 3;
	or.b16  	%rs508, %rs507, %rs505;
	setp.gt.s64 	%p473, %rd435, %rd74;
	selp.u16 	%rs509, 1, 0, %p473;
	setp.gt.s64 	%p474, %rd434, %rd74;
	selp.u16 	%rs510, -1, 0, %p474;
	shl.b16 	%rs511, %rs510, 1;
	or.b16  	%rs512, %rs509, %rs511;
	and.b16  	%rs513, %rs512, 3;
	or.b16  	%rs514, %rs513, %rs508;
	shl.b16 	%rs515, %rs514, 12;
	or.b16  	%rs516, %rs515, %rs503;
	setp.gt.s64 	%p475, %rd433, %rd76;
	selp.u16 	%rs517, 1, 0, %p475;
	shl.b16 	%rs518, %rs517, 2;
	setp.gt.s64 	%p476, %rd432, %rd76;
	selp.u16 	%rs519, -1, 0, %p476;
	shl.b16 	%rs520, %rs519, 3;
	or.b16  	%rs521, %rs520, %rs518;
	setp.gt.s64 	%p477, %rd433, %rd74;
	selp.u16 	%rs522, 1, 0, %p477;
	setp.gt.s64 	%p478, %rd432, %rd74;
	selp.u16 	%rs523, -1, 0, %p478;
	shl.b16 	%rs524, %rs523, 1;
	or.b16  	%rs525, %rs522, %rs524;
	and.b16  	%rs526, %rs525, 3;
	or.b16  	%rs527, %rs526, %rs521;
	and.b16  	%rs528, %rs527, 15;
	setp.gt.s64 	%p479, %rd431, %rd76;
	selp.u16 	%rs529, 1, 0, %p479;
	shl.b16 	%rs530, %rs529, 2;
	setp.gt.s64 	%p480, %rd430, %rd76;
	selp.u16 	%rs531, -1, 0, %p480;
	shl.b16 	%rs532, %rs531, 3;
	or.b16  	%rs533, %rs532, %rs530;
	setp.gt.s64 	%p481, %rd431, %rd74;
	selp.u16 	%rs534, 1, 0, %p481;
	setp.gt.s64 	%p482, %rd430, %rd74;
	selp.u16 	%rs535, -1, 0, %p482;
	shl.b16 	%rs536, %rs535, 1;
	or.b16  	%rs537, %rs534, %rs536;
	and.b16  	%rs538, %rs537, 3;
	or.b16  	%rs539, %rs538, %rs533;
	shl.b16 	%rs540, %rs539, 4;
	or.b16  	%rs541, %rs528, %rs540;
	and.b16  	%rs542, %rs541, 255;
	or.b16  	%rs543, %rs542, %rs516;
	cvt.u32.u16 	%r6457, %rs543;
	shr.u32 	%r6458, %r6457, 1;
	shr.u32 	%r6459, %r6457, 2;
	shr.u32 	%r6460, %r6457, 3;
	shr.u32 	%r6461, %r6457, 4;
	shr.u32 	%r6462, %r6457, 5;
	shr.u32 	%r6463, %r6457, 6;
	shr.u32 	%r6464, %r6457, 7;
	shr.u32 	%r6465, %r6457, 8;
	shr.u32 	%r6466, %r6457, 9;
	shr.u32 	%r6467, %r6457, 10;
	shr.u32 	%r6468, %r6457, 11;
	shr.u32 	%r6469, %r6457, 12;
	shr.u32 	%r6470, %r6457, 13;
	shr.u32 	%r6471, %r6457, 14;
	shr.u32 	%r6472, %r6457, 15;
	setp.gt.s64 	%p483, %rd429, %rd74;
	setp.gt.s64 	%p484, %rd427, %rd74;
	setp.gt.s64 	%p485, %rd429, %rd76;
	setp.gt.s64 	%p486, %rd427, %rd76;
	setp.gt.s64 	%p487, %rd426, %rd74;
	setp.gt.s64 	%p488, %rd425, %rd74;
	setp.gt.s64 	%p489, %rd426, %rd76;
	setp.gt.s64 	%p490, %rd425, %rd76;
	setp.gt.s64 	%p491, %rd428, %rd74;
	setp.gt.s64 	%p492, %rd424, %rd74;
	setp.gt.s64 	%p493, %rd428, %rd76;
	setp.gt.s64 	%p494, %rd424, %rd76;
	setp.gt.s64 	%p495, %rd423, %rd74;
	setp.gt.s64 	%p496, %rd422, %rd74;
	setp.gt.s64 	%p497, %rd423, %rd76;
	setp.gt.s64 	%p498, %rd422, %rd76;
	.loc	1 245 22                        // prefix_prefill.py:245:22
	selp.f32 	%f7968, 0fFF800000, %f7904, %p498;
	selp.f32 	%f7969, 0fFF800000, %f7905, %p497;
	selp.f32 	%f7970, 0fFF800000, %f7906, %p496;
	selp.f32 	%f7971, 0fFF800000, %f7907, %p495;
	selp.f32 	%f7972, 0fFF800000, %f7908, %p494;
	selp.f32 	%f7973, 0fFF800000, %f7909, %p493;
	selp.f32 	%f7974, 0fFF800000, %f7910, %p492;
	selp.f32 	%f7975, 0fFF800000, %f7911, %p491;
	selp.f32 	%f7976, 0fFF800000, %f7912, %p490;
	selp.f32 	%f7977, 0fFF800000, %f7913, %p489;
	selp.f32 	%f7978, 0fFF800000, %f7914, %p488;
	selp.f32 	%f7979, 0fFF800000, %f7915, %p487;
	selp.f32 	%f7980, 0fFF800000, %f7916, %p486;
	selp.f32 	%f7981, 0fFF800000, %f7917, %p485;
	selp.f32 	%f7982, 0fFF800000, %f7918, %p484;
	selp.f32 	%f7983, 0fFF800000, %f7919, %p483;
	and.b32  	%r6473, %r6472, 1;
	setp.eq.b32 	%p499, %r6473, 1;
	selp.f32 	%f7984, 0fFF800000, %f7920, %p499;
	and.b32  	%r6474, %r6471, 1;
	setp.eq.b32 	%p500, %r6474, 1;
	selp.f32 	%f7985, 0fFF800000, %f7921, %p500;
	and.b32  	%r6475, %r6470, 1;
	setp.eq.b32 	%p501, %r6475, 1;
	selp.f32 	%f7986, 0fFF800000, %f7922, %p501;
	and.b32  	%r6476, %r6469, 1;
	setp.eq.b32 	%p502, %r6476, 1;
	selp.f32 	%f7987, 0fFF800000, %f7923, %p502;
	and.b32  	%r6477, %r6468, 1;
	setp.eq.b32 	%p503, %r6477, 1;
	selp.f32 	%f7988, 0fFF800000, %f7924, %p503;
	and.b32  	%r6478, %r6467, 1;
	setp.eq.b32 	%p504, %r6478, 1;
	selp.f32 	%f7989, 0fFF800000, %f7925, %p504;
	and.b32  	%r6479, %r6466, 1;
	setp.eq.b32 	%p505, %r6479, 1;
	selp.f32 	%f7990, 0fFF800000, %f7926, %p505;
	and.b32  	%r6480, %r6465, 1;
	setp.eq.b32 	%p506, %r6480, 1;
	selp.f32 	%f7991, 0fFF800000, %f7927, %p506;
	and.b32  	%r6481, %r6464, 1;
	setp.eq.b32 	%p507, %r6481, 1;
	selp.f32 	%f7992, 0fFF800000, %f7928, %p507;
	and.b32  	%r6482, %r6463, 1;
	setp.eq.b32 	%p508, %r6482, 1;
	selp.f32 	%f7993, 0fFF800000, %f7929, %p508;
	and.b32  	%r6483, %r6462, 1;
	setp.eq.b32 	%p509, %r6483, 1;
	selp.f32 	%f7994, 0fFF800000, %f7930, %p509;
	and.b32  	%r6484, %r6461, 1;
	setp.eq.b32 	%p510, %r6484, 1;
	selp.f32 	%f7995, 0fFF800000, %f7931, %p510;
	and.b32  	%r6485, %r6460, 1;
	setp.eq.b32 	%p511, %r6485, 1;
	selp.f32 	%f7996, 0fFF800000, %f7932, %p511;
	and.b32  	%r6486, %r6459, 1;
	setp.eq.b32 	%p512, %r6486, 1;
	selp.f32 	%f7997, 0fFF800000, %f7933, %p512;
	and.b32  	%r6487, %r6458, 1;
	setp.eq.b32 	%p513, %r6487, 1;
	selp.f32 	%f7998, 0fFF800000, %f7934, %p513;
	selp.f32 	%f7999, 0fFF800000, %f7935, %p477;
	shr.u64 	%rd439, %rd438, 31;
	and.b64  	%rd440, %rd439, 1;
	setp.eq.b64 	%p514, %rd440, 1;
	selp.f32 	%f8000, 0fFF800000, %f7936, %p514;
	shr.u64 	%rd441, %rd438, 30;
	and.b64  	%rd442, %rd441, 1;
	setp.eq.b64 	%p515, %rd442, 1;
	selp.f32 	%f8001, 0fFF800000, %f7937, %p515;
	shr.u64 	%rd443, %rd438, 29;
	and.b64  	%rd444, %rd443, 1;
	setp.eq.b64 	%p516, %rd444, 1;
	selp.f32 	%f8002, 0fFF800000, %f7938, %p516;
	shr.u64 	%rd445, %rd438, 28;
	and.b64  	%rd446, %rd445, 1;
	setp.eq.b64 	%p517, %rd446, 1;
	selp.f32 	%f8003, 0fFF800000, %f7939, %p517;
	shr.u64 	%rd447, %rd438, 27;
	and.b64  	%rd448, %rd447, 1;
	setp.eq.b64 	%p518, %rd448, 1;
	selp.f32 	%f8004, 0fFF800000, %f7940, %p518;
	shr.u64 	%rd449, %rd438, 26;
	and.b64  	%rd450, %rd449, 1;
	setp.eq.b64 	%p519, %rd450, 1;
	selp.f32 	%f8005, 0fFF800000, %f7941, %p519;
	shr.u64 	%rd451, %rd438, 25;
	and.b64  	%rd452, %rd451, 1;
	setp.eq.b64 	%p520, %rd452, 1;
	selp.f32 	%f8006, 0fFF800000, %f7942, %p520;
	shr.u64 	%rd453, %rd438, 24;
	and.b64  	%rd454, %rd453, 1;
	setp.eq.b64 	%p521, %rd454, 1;
	selp.f32 	%f8007, 0fFF800000, %f7943, %p521;
	shr.u64 	%rd455, %rd438, 23;
	and.b64  	%rd456, %rd455, 1;
	setp.eq.b64 	%p522, %rd456, 1;
	selp.f32 	%f8008, 0fFF800000, %f7944, %p522;
	shr.u64 	%rd457, %rd438, 22;
	and.b64  	%rd458, %rd457, 1;
	setp.eq.b64 	%p523, %rd458, 1;
	selp.f32 	%f8009, 0fFF800000, %f7945, %p523;
	shr.u64 	%rd459, %rd438, 21;
	and.b64  	%rd460, %rd459, 1;
	setp.eq.b64 	%p524, %rd460, 1;
	selp.f32 	%f8010, 0fFF800000, %f7946, %p524;
	shr.u64 	%rd461, %rd438, 20;
	and.b64  	%rd462, %rd461, 1;
	setp.eq.b64 	%p525, %rd462, 1;
	selp.f32 	%f8011, 0fFF800000, %f7947, %p525;
	shr.u64 	%rd463, %rd438, 19;
	and.b64  	%rd464, %rd463, 1;
	setp.eq.b64 	%p526, %rd464, 1;
	selp.f32 	%f8012, 0fFF800000, %f7948, %p526;
	shr.u64 	%rd465, %rd438, 18;
	and.b64  	%rd466, %rd465, 1;
	setp.eq.b64 	%p527, %rd466, 1;
	selp.f32 	%f8013, 0fFF800000, %f7949, %p527;
	shr.u64 	%rd467, %rd438, 17;
	and.b64  	%rd468, %rd467, 1;
	setp.eq.b64 	%p528, %rd468, 1;
	selp.f32 	%f8014, 0fFF800000, %f7950, %p528;
	shr.u64 	%rd469, %rd438, 16;
	and.b64  	%rd470, %rd469, 1;
	setp.eq.b64 	%p529, %rd470, 1;
	selp.f32 	%f8015, 0fFF800000, %f7951, %p529;
	shr.u64 	%rd471, %rd438, 15;
	and.b64  	%rd472, %rd471, 1;
	setp.eq.b64 	%p530, %rd472, 1;
	selp.f32 	%f8016, 0fFF800000, %f7952, %p530;
	shr.u64 	%rd473, %rd438, 14;
	and.b64  	%rd474, %rd473, 1;
	setp.eq.b64 	%p531, %rd474, 1;
	selp.f32 	%f8017, 0fFF800000, %f7953, %p531;
	shr.u64 	%rd475, %rd438, 13;
	and.b64  	%rd476, %rd475, 1;
	setp.eq.b64 	%p532, %rd476, 1;
	selp.f32 	%f8018, 0fFF800000, %f7954, %p532;
	shr.u64 	%rd477, %rd438, 12;
	and.b64  	%rd478, %rd477, 1;
	setp.eq.b64 	%p533, %rd478, 1;
	selp.f32 	%f8019, 0fFF800000, %f7955, %p533;
	shr.u64 	%rd479, %rd438, 11;
	and.b64  	%rd480, %rd479, 1;
	setp.eq.b64 	%p534, %rd480, 1;
	selp.f32 	%f8020, 0fFF800000, %f7956, %p534;
	shr.u64 	%rd481, %rd438, 10;
	and.b64  	%rd482, %rd481, 1;
	setp.eq.b64 	%p535, %rd482, 1;
	selp.f32 	%f8021, 0fFF800000, %f7957, %p535;
	shr.u64 	%rd483, %rd438, 9;
	and.b64  	%rd484, %rd483, 1;
	setp.eq.b64 	%p536, %rd484, 1;
	selp.f32 	%f8022, 0fFF800000, %f7958, %p536;
	shr.u64 	%rd485, %rd438, 8;
	and.b64  	%rd486, %rd485, 1;
	setp.eq.b64 	%p537, %rd486, 1;
	selp.f32 	%f8023, 0fFF800000, %f7959, %p537;
	shr.u64 	%rd487, %rd438, 7;
	and.b64  	%rd488, %rd487, 1;
	setp.eq.b64 	%p538, %rd488, 1;
	selp.f32 	%f8024, 0fFF800000, %f7960, %p538;
	shr.u64 	%rd489, %rd438, 6;
	and.b64  	%rd490, %rd489, 1;
	setp.eq.b64 	%p539, %rd490, 1;
	selp.f32 	%f8025, 0fFF800000, %f7961, %p539;
	shr.u64 	%rd491, %rd438, 5;
	and.b64  	%rd492, %rd491, 1;
	setp.eq.b64 	%p540, %rd492, 1;
	selp.f32 	%f8026, 0fFF800000, %f7962, %p540;
	shr.u64 	%rd493, %rd438, 4;
	and.b64  	%rd494, %rd493, 1;
	setp.eq.b64 	%p541, %rd494, 1;
	selp.f32 	%f8027, 0fFF800000, %f7963, %p541;
	shr.u64 	%rd495, %rd438, 3;
	and.b64  	%rd496, %rd495, 1;
	setp.eq.b64 	%p542, %rd496, 1;
	selp.f32 	%f8028, 0fFF800000, %f7964, %p542;
	shr.u64 	%rd497, %rd438, 2;
	and.b64  	%rd498, %rd497, 1;
	setp.eq.b64 	%p543, %rd498, 1;
	selp.f32 	%f8029, 0fFF800000, %f7965, %p543;
	shr.u64 	%rd499, %rd438, 1;
	and.b64  	%rd500, %rd499, 1;
	setp.eq.b64 	%p544, %rd500, 1;
	selp.f32 	%f8030, 0fFF800000, %f7966, %p544;
	selp.f32 	%f8031, 0fFF800000, %f7967, %p445;
$L__tmp21:
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f8032, %f7968, %f7969;
	max.f32 	%f8033, %f7970, %f7971;
	max.f32 	%f8034, %f8032, %f7972;
	max.f32 	%f8035, %f8034, %f7973;
	max.f32 	%f8036, %f8033, %f7974;
	max.f32 	%f8037, %f8036, %f7975;
	max.f32 	%f8038, %f8035, %f7976;
	max.f32 	%f8039, %f8038, %f7977;
	max.f32 	%f8040, %f8037, %f7978;
	max.f32 	%f8041, %f8040, %f7979;
	max.f32 	%f8042, %f8039, %f7980;
	max.f32 	%f8043, %f8042, %f7981;
	max.f32 	%f8044, %f8041, %f7982;
	max.f32 	%f8045, %f8044, %f7983;
	max.f32 	%f8046, %f8043, %f7984;
	max.f32 	%f8047, %f8046, %f7985;
	max.f32 	%f8048, %f8045, %f7986;
	max.f32 	%f8049, %f8048, %f7987;
	max.f32 	%f8050, %f8047, %f7988;
	max.f32 	%f8051, %f8050, %f7989;
	max.f32 	%f8052, %f8049, %f7990;
	max.f32 	%f8053, %f8052, %f7991;
	max.f32 	%f8054, %f8051, %f7992;
	max.f32 	%f8055, %f8054, %f7993;
	max.f32 	%f8056, %f8053, %f7994;
	max.f32 	%f8057, %f8056, %f7995;
	max.f32 	%f8058, %f8055, %f7996;
	max.f32 	%f8059, %f8058, %f7997;
	max.f32 	%f8060, %f8057, %f7998;
	max.f32 	%f8061, %f8060, %f7999;
	max.f32 	%f8062, %f8000, %f8001;
	max.f32 	%f8063, %f8002, %f8003;
	max.f32 	%f8064, %f8062, %f8004;
	max.f32 	%f8065, %f8064, %f8005;
	max.f32 	%f8066, %f8063, %f8006;
	max.f32 	%f8067, %f8066, %f8007;
	max.f32 	%f8068, %f8065, %f8008;
	max.f32 	%f8069, %f8068, %f8009;
	max.f32 	%f8070, %f8067, %f8010;
	max.f32 	%f8071, %f8070, %f8011;
	max.f32 	%f8072, %f8069, %f8012;
	max.f32 	%f8073, %f8072, %f8013;
	max.f32 	%f8074, %f8071, %f8014;
	max.f32 	%f8075, %f8074, %f8015;
	max.f32 	%f8076, %f8073, %f8016;
	max.f32 	%f8077, %f8076, %f8017;
	max.f32 	%f8078, %f8075, %f8018;
	max.f32 	%f8079, %f8078, %f8019;
	max.f32 	%f8080, %f8077, %f8020;
	max.f32 	%f8081, %f8080, %f8021;
	max.f32 	%f8082, %f8079, %f8022;
	max.f32 	%f8083, %f8082, %f8023;
	max.f32 	%f8084, %f8081, %f8024;
	max.f32 	%f8085, %f8084, %f8025;
	max.f32 	%f8086, %f8083, %f8026;
	max.f32 	%f8087, %f8086, %f8027;
	max.f32 	%f8088, %f8085, %f8028;
	max.f32 	%f8089, %f8088, %f8029;
	max.f32 	%f8090, %f8087, %f8030;
	max.f32 	%f8091, %f8090, %f8031;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r6488, %f8059;
	shfl.sync.bfly.b32	%r6489, %r6488, 2, 31, -1;
	mov.b32 	%f8092, %r6489;
	mov.b32 	%r6490, %f8061;
	mov.b32 	%r6491, %f8089;
	mov.b32 	%r6492, %f8091;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f8093, %f8059, %f8092;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r6493, %f8093;
	shfl.sync.bfly.b32	%r6494, %r6493, 1, 31, -1;
	shfl.sync.bfly.b32	%r6495, %r6490, 2, 31, -1;
	mov.b32 	%f8094, %r6495;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f8095, %f8061, %f8094;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r6496, %f8095;
	shfl.sync.bfly.b32	%r6497, %r6496, 1, 31, -1;
	shfl.sync.bfly.b32	%r6498, %r6491, 2, 31, -1;
	mov.b32 	%f8096, %r6498;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f8097, %f8089, %f8096;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r6499, %f8097;
	shfl.sync.bfly.b32	%r6500, %r6499, 1, 31, -1;
	shfl.sync.bfly.b32	%r6501, %r6492, 2, 31, -1;
	mov.b32 	%f8098, %r6501;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f8099, %f8091, %f8098;
	.loc	2 184 40                        // standard.py:184:40
	mov.b32 	%r6502, %f8099;
	shfl.sync.bfly.b32	%r6503, %r6502, 1, 31, -1;
	mov.b32 	%f8100, %r6503;
	mov.b32 	%f8101, %r6500;
	mov.b32 	%f8102, %r6497;
	mov.b32 	%f8103, %r6494;
	.loc	2 163 27                        // standard.py:163:27
	max.f32 	%f8104, %f8097, %f8101;
	max.f32 	%f8105, %f8099, %f8100;
	max.f32 	%f8106, %f8093, %f8103;
	max.f32 	%f8107, %f8095, %f8102;
$L__tmp22:
	.loc	1 252 31                        // prefix_prefill.py:252:31
	max.f32 	%f2136, %f8519, %f8105;
	max.f32 	%f2135, %f8518, %f8104;
	max.f32 	%f2134, %f8517, %f8107;
	max.f32 	%f2133, %f8516, %f8106;
	.loc	1 253 24                        // prefix_prefill.py:253:24
	sub.f32 	%f8108, %f7968, %f2133;
	sub.f32 	%f8109, %f7969, %f2133;
	sub.f32 	%f8110, %f7970, %f2134;
	sub.f32 	%f8111, %f7971, %f2134;
	sub.f32 	%f8112, %f7972, %f2133;
	sub.f32 	%f8113, %f7973, %f2133;
	sub.f32 	%f8114, %f7974, %f2134;
	sub.f32 	%f8115, %f7975, %f2134;
	sub.f32 	%f8116, %f7976, %f2133;
	sub.f32 	%f8117, %f7977, %f2133;
	sub.f32 	%f8118, %f7978, %f2134;
	sub.f32 	%f8119, %f7979, %f2134;
	sub.f32 	%f8120, %f7980, %f2133;
	sub.f32 	%f8121, %f7981, %f2133;
	sub.f32 	%f8122, %f7982, %f2134;
	sub.f32 	%f8123, %f7983, %f2134;
	sub.f32 	%f8124, %f7984, %f2133;
	sub.f32 	%f8125, %f7985, %f2133;
	sub.f32 	%f8126, %f7986, %f2134;
	sub.f32 	%f8127, %f7987, %f2134;
	sub.f32 	%f8128, %f7988, %f2133;
	sub.f32 	%f8129, %f7989, %f2133;
	sub.f32 	%f8130, %f7990, %f2134;
	sub.f32 	%f8131, %f7991, %f2134;
	sub.f32 	%f8132, %f7992, %f2133;
	sub.f32 	%f8133, %f7993, %f2133;
	sub.f32 	%f8134, %f7994, %f2134;
	sub.f32 	%f8135, %f7995, %f2134;
	sub.f32 	%f8136, %f7996, %f2133;
	sub.f32 	%f8137, %f7997, %f2133;
	sub.f32 	%f8138, %f7998, %f2134;
	sub.f32 	%f8139, %f7999, %f2134;
	sub.f32 	%f8140, %f8000, %f2135;
	sub.f32 	%f8141, %f8001, %f2135;
	sub.f32 	%f8142, %f8002, %f2136;
	sub.f32 	%f8143, %f8003, %f2136;
	sub.f32 	%f8144, %f8004, %f2135;
	sub.f32 	%f8145, %f8005, %f2135;
	sub.f32 	%f8146, %f8006, %f2136;
	sub.f32 	%f8147, %f8007, %f2136;
	sub.f32 	%f8148, %f8008, %f2135;
	sub.f32 	%f8149, %f8009, %f2135;
	sub.f32 	%f8150, %f8010, %f2136;
	sub.f32 	%f8151, %f8011, %f2136;
	sub.f32 	%f8152, %f8012, %f2135;
	sub.f32 	%f8153, %f8013, %f2135;
	sub.f32 	%f8154, %f8014, %f2136;
	sub.f32 	%f8155, %f8015, %f2136;
	sub.f32 	%f8156, %f8016, %f2135;
	sub.f32 	%f8157, %f8017, %f2135;
	sub.f32 	%f8158, %f8018, %f2136;
	sub.f32 	%f8159, %f8019, %f2136;
	sub.f32 	%f8160, %f8020, %f2135;
	sub.f32 	%f8161, %f8021, %f2135;
	sub.f32 	%f8162, %f8022, %f2136;
	sub.f32 	%f8163, %f8023, %f2136;
	sub.f32 	%f8164, %f8024, %f2135;
	sub.f32 	%f8165, %f8025, %f2135;
	sub.f32 	%f8166, %f8026, %f2136;
	sub.f32 	%f8167, %f8027, %f2136;
	sub.f32 	%f8168, %f8028, %f2135;
	sub.f32 	%f8169, %f8029, %f2135;
	sub.f32 	%f8170, %f8030, %f2136;
	sub.f32 	%f8171, %f8031, %f2136;
	.loc	1 253 19                        // prefix_prefill.py:253:19
	mul.f32 	%f6745, %f8108, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6744, %f6745;
	// end inline asm
	mul.f32 	%f6747, %f8109, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6746, %f6747;
	// end inline asm
	mul.f32 	%f6749, %f8110, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6748, %f6749;
	// end inline asm
	mul.f32 	%f6751, %f8111, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6750, %f6751;
	// end inline asm
	mul.f32 	%f6753, %f8112, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6752, %f6753;
	// end inline asm
	mul.f32 	%f6755, %f8113, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6754, %f6755;
	// end inline asm
	mul.f32 	%f6757, %f8114, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6756, %f6757;
	// end inline asm
	mul.f32 	%f6759, %f8115, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6758, %f6759;
	// end inline asm
	mul.f32 	%f6761, %f8116, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6760, %f6761;
	// end inline asm
	mul.f32 	%f6763, %f8117, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6762, %f6763;
	// end inline asm
	mul.f32 	%f6765, %f8118, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6764, %f6765;
	// end inline asm
	mul.f32 	%f6767, %f8119, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6766, %f6767;
	// end inline asm
	mul.f32 	%f6769, %f8120, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6768, %f6769;
	// end inline asm
	mul.f32 	%f6771, %f8121, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6770, %f6771;
	// end inline asm
	mul.f32 	%f6773, %f8122, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6772, %f6773;
	// end inline asm
	mul.f32 	%f6775, %f8123, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6774, %f6775;
	// end inline asm
	mul.f32 	%f6777, %f8124, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6776, %f6777;
	// end inline asm
	mul.f32 	%f6779, %f8125, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6778, %f6779;
	// end inline asm
	mul.f32 	%f6781, %f8126, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6780, %f6781;
	// end inline asm
	mul.f32 	%f6783, %f8127, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6782, %f6783;
	// end inline asm
	mul.f32 	%f6785, %f8128, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6784, %f6785;
	// end inline asm
	mul.f32 	%f6787, %f8129, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6786, %f6787;
	// end inline asm
	mul.f32 	%f6789, %f8130, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6788, %f6789;
	// end inline asm
	mul.f32 	%f6791, %f8131, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6790, %f6791;
	// end inline asm
	mul.f32 	%f6793, %f8132, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6792, %f6793;
	// end inline asm
	mul.f32 	%f6795, %f8133, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6794, %f6795;
	// end inline asm
	mul.f32 	%f6797, %f8134, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6796, %f6797;
	// end inline asm
	mul.f32 	%f6799, %f8135, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6798, %f6799;
	// end inline asm
	mul.f32 	%f6801, %f8136, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6800, %f6801;
	// end inline asm
	mul.f32 	%f6803, %f8137, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6802, %f6803;
	// end inline asm
	mul.f32 	%f6805, %f8138, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6804, %f6805;
	// end inline asm
	mul.f32 	%f6807, %f8139, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6806, %f6807;
	// end inline asm
	mul.f32 	%f6809, %f8140, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6808, %f6809;
	// end inline asm
	mul.f32 	%f6811, %f8141, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6810, %f6811;
	// end inline asm
	mul.f32 	%f6813, %f8142, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6812, %f6813;
	// end inline asm
	mul.f32 	%f6815, %f8143, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6814, %f6815;
	// end inline asm
	mul.f32 	%f6817, %f8144, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6816, %f6817;
	// end inline asm
	mul.f32 	%f6819, %f8145, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6818, %f6819;
	// end inline asm
	mul.f32 	%f6821, %f8146, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6820, %f6821;
	// end inline asm
	mul.f32 	%f6823, %f8147, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6822, %f6823;
	// end inline asm
	mul.f32 	%f6825, %f8148, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6824, %f6825;
	// end inline asm
	mul.f32 	%f6827, %f8149, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6826, %f6827;
	// end inline asm
	mul.f32 	%f6829, %f8150, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6828, %f6829;
	// end inline asm
	mul.f32 	%f6831, %f8151, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6830, %f6831;
	// end inline asm
	mul.f32 	%f6833, %f8152, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6832, %f6833;
	// end inline asm
	mul.f32 	%f6835, %f8153, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6834, %f6835;
	// end inline asm
	mul.f32 	%f6837, %f8154, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6836, %f6837;
	// end inline asm
	mul.f32 	%f6839, %f8155, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6838, %f6839;
	// end inline asm
	mul.f32 	%f6841, %f8156, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6840, %f6841;
	// end inline asm
	mul.f32 	%f6843, %f8157, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6842, %f6843;
	// end inline asm
	mul.f32 	%f6845, %f8158, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6844, %f6845;
	// end inline asm
	mul.f32 	%f6847, %f8159, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6846, %f6847;
	// end inline asm
	mul.f32 	%f6849, %f8160, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6848, %f6849;
	// end inline asm
	mul.f32 	%f6851, %f8161, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6850, %f6851;
	// end inline asm
	mul.f32 	%f6853, %f8162, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6852, %f6853;
	// end inline asm
	mul.f32 	%f6855, %f8163, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6854, %f6855;
	// end inline asm
	mul.f32 	%f6857, %f8164, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6856, %f6857;
	// end inline asm
	mul.f32 	%f6859, %f8165, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6858, %f6859;
	// end inline asm
	mul.f32 	%f6861, %f8166, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6860, %f6861;
	// end inline asm
	mul.f32 	%f6863, %f8167, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6862, %f6863;
	// end inline asm
	mul.f32 	%f6865, %f8168, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6864, %f6865;
	// end inline asm
	mul.f32 	%f6867, %f8169, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6866, %f6867;
	// end inline asm
	mul.f32 	%f6869, %f8170, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6868, %f6869;
	// end inline asm
	mul.f32 	%f6871, %f8171, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6870, %f6871;
	// end inline asm
$L__tmp23:
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f8172, %f6744, %f6746;
	add.f32 	%f8173, %f6748, %f6750;
	add.f32 	%f8174, %f8172, %f6752;
	add.f32 	%f8175, %f8174, %f6754;
	add.f32 	%f8176, %f8173, %f6756;
	add.f32 	%f8177, %f8176, %f6758;
	add.f32 	%f8178, %f8175, %f6760;
	add.f32 	%f8179, %f8178, %f6762;
	add.f32 	%f8180, %f8177, %f6764;
	add.f32 	%f8181, %f8180, %f6766;
	add.f32 	%f8182, %f8179, %f6768;
	add.f32 	%f8183, %f8182, %f6770;
	add.f32 	%f8184, %f8181, %f6772;
	add.f32 	%f8185, %f8184, %f6774;
	add.f32 	%f8186, %f8183, %f6776;
	add.f32 	%f8187, %f8186, %f6778;
	add.f32 	%f8188, %f8185, %f6780;
	add.f32 	%f8189, %f8188, %f6782;
	add.f32 	%f8190, %f8187, %f6784;
	add.f32 	%f8191, %f8190, %f6786;
	add.f32 	%f8192, %f8189, %f6788;
	add.f32 	%f8193, %f8192, %f6790;
	add.f32 	%f8194, %f8191, %f6792;
	add.f32 	%f8195, %f8194, %f6794;
	add.f32 	%f8196, %f8193, %f6796;
	add.f32 	%f8197, %f8196, %f6798;
	add.f32 	%f8198, %f8195, %f6800;
	add.f32 	%f8199, %f8198, %f6802;
	add.f32 	%f8200, %f8197, %f6804;
	add.f32 	%f8201, %f8200, %f6806;
	add.f32 	%f8202, %f6808, %f6810;
	add.f32 	%f8203, %f6812, %f6814;
	add.f32 	%f8204, %f8202, %f6816;
	add.f32 	%f8205, %f8204, %f6818;
	add.f32 	%f8206, %f8203, %f6820;
	add.f32 	%f8207, %f8206, %f6822;
	add.f32 	%f8208, %f8205, %f6824;
	add.f32 	%f8209, %f8208, %f6826;
	add.f32 	%f8210, %f8207, %f6828;
	add.f32 	%f8211, %f8210, %f6830;
	add.f32 	%f8212, %f8209, %f6832;
	add.f32 	%f8213, %f8212, %f6834;
	add.f32 	%f8214, %f8211, %f6836;
	add.f32 	%f8215, %f8214, %f6838;
	add.f32 	%f8216, %f8213, %f6840;
	add.f32 	%f8217, %f8216, %f6842;
	add.f32 	%f8218, %f8215, %f6844;
	add.f32 	%f8219, %f8218, %f6846;
	add.f32 	%f8220, %f8217, %f6848;
	add.f32 	%f8221, %f8220, %f6850;
	add.f32 	%f8222, %f8219, %f6852;
	add.f32 	%f8223, %f8222, %f6854;
	add.f32 	%f8224, %f8221, %f6856;
	add.f32 	%f8225, %f8224, %f6858;
	add.f32 	%f8226, %f8223, %f6860;
	add.f32 	%f8227, %f8226, %f6862;
	add.f32 	%f8228, %f8225, %f6864;
	add.f32 	%f8229, %f8228, %f6866;
	add.f32 	%f8230, %f8227, %f6868;
	add.f32 	%f8231, %f8230, %f6870;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r6504, %f8199;
	shfl.sync.bfly.b32	%r6505, %r6504, 2, 31, -1;
	mov.b32 	%f8232, %r6505;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f8233, %f8199, %f8232;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r6506, %f8233;
	shfl.sync.bfly.b32	%r6507, %r6506, 1, 31, -1;
	mov.b32 	%r6508, %f8201;
	shfl.sync.bfly.b32	%r6509, %r6508, 2, 31, -1;
	mov.b32 	%f8234, %r6509;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f8235, %f8201, %f8234;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r6510, %f8235;
	shfl.sync.bfly.b32	%r6511, %r6510, 1, 31, -1;
	mov.b32 	%r6512, %f8229;
	shfl.sync.bfly.b32	%r6513, %r6512, 2, 31, -1;
	mov.b32 	%f8236, %r6513;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f8237, %f8229, %f8236;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r6514, %f8237;
	shfl.sync.bfly.b32	%r6515, %r6514, 1, 31, -1;
	mov.b32 	%r6516, %f8231;
	shfl.sync.bfly.b32	%r6517, %r6516, 2, 31, -1;
	mov.b32 	%f8238, %r6517;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f8239, %f8231, %f8238;
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%r6518, %f8239;
	shfl.sync.bfly.b32	%r6519, %r6518, 1, 31, -1;
$L__tmp24:
	.loc	1 255 29                        // prefix_prefill.py:255:29
	sub.f32 	%f8240, %f8519, %f2136;
	sub.f32 	%f8241, %f8518, %f2135;
	sub.f32 	%f8242, %f8517, %f2134;
	sub.f32 	%f8243, %f8516, %f2133;
	.loc	1 255 23                        // prefix_prefill.py:255:23
	mul.f32 	%f6873, %f8243, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6872, %f6873;
	// end inline asm
	mul.f32 	%f6875, %f8242, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6874, %f6875;
	// end inline asm
	mul.f32 	%f6877, %f8241, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6876, %f6877;
	// end inline asm
	mul.f32 	%f6879, %f8240, 0f3FB8AA3B;
	// begin inline asm
	ex2.approx.f32 %f6878, %f6879;
	// end inline asm
	.loc	1 256 20                        // prefix_prefill.py:256:20
	mul.f32 	%f8524, %f8524, %f6872;
	mul.f32 	%f8525, %f8525, %f6872;
	mul.f32 	%f8526, %f8526, %f6874;
	mul.f32 	%f8527, %f8527, %f6874;
	mul.f32 	%f8528, %f8528, %f6872;
	mul.f32 	%f8529, %f8529, %f6872;
	mul.f32 	%f8530, %f8530, %f6874;
	mul.f32 	%f8531, %f8531, %f6874;
	mul.f32 	%f8532, %f8532, %f6872;
	mul.f32 	%f8533, %f8533, %f6872;
	mul.f32 	%f8534, %f8534, %f6874;
	mul.f32 	%f8535, %f8535, %f6874;
	mul.f32 	%f8536, %f8536, %f6872;
	mul.f32 	%f8537, %f8537, %f6872;
	mul.f32 	%f8538, %f8538, %f6874;
	mul.f32 	%f8539, %f8539, %f6874;
	mul.f32 	%f8540, %f8540, %f6872;
	mul.f32 	%f8541, %f8541, %f6872;
	mul.f32 	%f8542, %f8542, %f6874;
	mul.f32 	%f8543, %f8543, %f6874;
	mul.f32 	%f8544, %f8544, %f6872;
	mul.f32 	%f8545, %f8545, %f6872;
	mul.f32 	%f8546, %f8546, %f6874;
	mul.f32 	%f8547, %f8547, %f6874;
	mul.f32 	%f8548, %f8548, %f6872;
	mul.f32 	%f8549, %f8549, %f6872;
	mul.f32 	%f8550, %f8550, %f6874;
	mul.f32 	%f8551, %f8551, %f6874;
	mul.f32 	%f8552, %f8552, %f6872;
	mul.f32 	%f8553, %f8553, %f6872;
	mul.f32 	%f8554, %f8554, %f6874;
	mul.f32 	%f8555, %f8555, %f6874;
	mul.f32 	%f8556, %f8556, %f6872;
	mul.f32 	%f8557, %f8557, %f6872;
	mul.f32 	%f8558, %f8558, %f6874;
	mul.f32 	%f8559, %f8559, %f6874;
	mul.f32 	%f8560, %f8560, %f6872;
	mul.f32 	%f8561, %f8561, %f6872;
	mul.f32 	%f8562, %f8562, %f6874;
	mul.f32 	%f8563, %f8563, %f6874;
	mul.f32 	%f8564, %f8564, %f6872;
	mul.f32 	%f8565, %f8565, %f6872;
	mul.f32 	%f8566, %f8566, %f6874;
	mul.f32 	%f8567, %f8567, %f6874;
	mul.f32 	%f8568, %f8568, %f6872;
	mul.f32 	%f8569, %f8569, %f6872;
	mul.f32 	%f8570, %f8570, %f6874;
	mul.f32 	%f8571, %f8571, %f6874;
	mul.f32 	%f8572, %f8572, %f6872;
	mul.f32 	%f8573, %f8573, %f6872;
	mul.f32 	%f8574, %f8574, %f6874;
	mul.f32 	%f8575, %f8575, %f6874;
	mul.f32 	%f8576, %f8576, %f6872;
	mul.f32 	%f8577, %f8577, %f6872;
	mul.f32 	%f8578, %f8578, %f6874;
	mul.f32 	%f8579, %f8579, %f6874;
	mul.f32 	%f8580, %f8580, %f6872;
	mul.f32 	%f8581, %f8581, %f6872;
	mul.f32 	%f8582, %f8582, %f6874;
	mul.f32 	%f8583, %f8583, %f6874;
	mul.f32 	%f8584, %f8584, %f6872;
	mul.f32 	%f8585, %f8585, %f6872;
	mul.f32 	%f8586, %f8586, %f6874;
	mul.f32 	%f8587, %f8587, %f6874;
	mul.f32 	%f8588, %f8588, %f6876;
	mul.f32 	%f8589, %f8589, %f6876;
	mul.f32 	%f8590, %f8590, %f6878;
	mul.f32 	%f8591, %f8591, %f6878;
	mul.f32 	%f8592, %f8592, %f6876;
	mul.f32 	%f8593, %f8593, %f6876;
	mul.f32 	%f8594, %f8594, %f6878;
	mul.f32 	%f8595, %f8595, %f6878;
	mul.f32 	%f8596, %f8596, %f6876;
	mul.f32 	%f8597, %f8597, %f6876;
	mul.f32 	%f8598, %f8598, %f6878;
	mul.f32 	%f8599, %f8599, %f6878;
	mul.f32 	%f8600, %f8600, %f6876;
	mul.f32 	%f8601, %f8601, %f6876;
	mul.f32 	%f8602, %f8602, %f6878;
	mul.f32 	%f8603, %f8603, %f6878;
	mul.f32 	%f8604, %f8604, %f6876;
	mul.f32 	%f8605, %f8605, %f6876;
	mul.f32 	%f8606, %f8606, %f6878;
	mul.f32 	%f8607, %f8607, %f6878;
	mul.f32 	%f8608, %f8608, %f6876;
	mul.f32 	%f8609, %f8609, %f6876;
	mul.f32 	%f8610, %f8610, %f6878;
	mul.f32 	%f8611, %f8611, %f6878;
	mul.f32 	%f8612, %f8612, %f6876;
	mul.f32 	%f8613, %f8613, %f6876;
	mul.f32 	%f8614, %f8614, %f6878;
	mul.f32 	%f8615, %f8615, %f6878;
	mul.f32 	%f8616, %f8616, %f6876;
	mul.f32 	%f8617, %f8617, %f6876;
	mul.f32 	%f8618, %f8618, %f6878;
	mul.f32 	%f8619, %f8619, %f6878;
	mul.f32 	%f8620, %f8620, %f6876;
	mul.f32 	%f8621, %f8621, %f6876;
	mul.f32 	%f8622, %f8622, %f6878;
	mul.f32 	%f8623, %f8623, %f6878;
	mul.f32 	%f8624, %f8624, %f6876;
	mul.f32 	%f8625, %f8625, %f6876;
	mul.f32 	%f8626, %f8626, %f6878;
	mul.f32 	%f8627, %f8627, %f6878;
	mul.f32 	%f8628, %f8628, %f6876;
	mul.f32 	%f8629, %f8629, %f6876;
	mul.f32 	%f8630, %f8630, %f6878;
	mul.f32 	%f8631, %f8631, %f6878;
	mul.f32 	%f8632, %f8632, %f6876;
	mul.f32 	%f8633, %f8633, %f6876;
	mul.f32 	%f8634, %f8634, %f6878;
	mul.f32 	%f8635, %f8635, %f6878;
	mul.f32 	%f8636, %f8636, %f6876;
	mul.f32 	%f8637, %f8637, %f6876;
	mul.f32 	%f8638, %f8638, %f6878;
	mul.f32 	%f8639, %f8639, %f6878;
	mul.f32 	%f8640, %f8640, %f6876;
	mul.f32 	%f8641, %f8641, %f6876;
	mul.f32 	%f8642, %f8642, %f6878;
	mul.f32 	%f8643, %f8643, %f6878;
	mul.f32 	%f8644, %f8644, %f6876;
	mul.f32 	%f8645, %f8645, %f6876;
	mul.f32 	%f8646, %f8646, %f6878;
	mul.f32 	%f8647, %f8647, %f6878;
	mul.f32 	%f8648, %f8648, %f6876;
	mul.f32 	%f8649, %f8649, %f6876;
	mul.f32 	%f8650, %f8650, %f6878;
	mul.f32 	%f8651, %f8651, %f6878;
	.loc	1 260 20                        // prefix_prefill.py:260:20
	mul.wide.s32 	%rd501, %r7409, 2;
	add.s64 	%rd405, %rd12, %rd501;
	add.s64 	%rd406, %rd13, %rd501;
	add.s64 	%rd407, %rd14, %rd501;
	add.s64 	%rd408, %rd15, %rd501;
	add.s64 	%rd409, %rd16, %rd501;
	add.s64 	%rd410, %rd17, %rd501;
	add.s64 	%rd411, %rd18, %rd501;
	add.s64 	%rd412, %rd19, %rd501;
	.loc	1 259 20                        // prefix_prefill.py:259:20
	// begin inline asm
	mov.u32 %r5365, 0x0;
	mov.u32 %r5366, 0x0;
	mov.u32 %r5367, 0x0;
	mov.u32 %r5368, 0x0;
	@%p356 ld.global.v4.b32 { %r5365, %r5366, %r5367, %r5368 }, [ %rd405 + 0 ];
	@!%p356 mov.u32 %r5365, %r684;
	@!%p356 mov.u32 %r5366, %r684;
	@!%p356 mov.u32 %r5367, %r684;
	@!%p356 mov.u32 %r5368, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r5373, 0x0;
	mov.u32 %r5374, 0x0;
	mov.u32 %r5375, 0x0;
	mov.u32 %r5376, 0x0;
	@%p361 ld.global.v4.b32 { %r5373, %r5374, %r5375, %r5376 }, [ %rd406 + 0 ];
	@!%p361 mov.u32 %r5373, %r684;
	@!%p361 mov.u32 %r5374, %r684;
	@!%p361 mov.u32 %r5375, %r684;
	@!%p361 mov.u32 %r5376, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r5381, 0x0;
	mov.u32 %r5382, 0x0;
	mov.u32 %r5383, 0x0;
	mov.u32 %r5384, 0x0;
	@%p366 ld.global.v4.b32 { %r5381, %r5382, %r5383, %r5384 }, [ %rd407 + 0 ];
	@!%p366 mov.u32 %r5381, %r684;
	@!%p366 mov.u32 %r5382, %r684;
	@!%p366 mov.u32 %r5383, %r684;
	@!%p366 mov.u32 %r5384, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r5389, 0x0;
	mov.u32 %r5390, 0x0;
	mov.u32 %r5391, 0x0;
	mov.u32 %r5392, 0x0;
	@%p371 ld.global.v4.b32 { %r5389, %r5390, %r5391, %r5392 }, [ %rd408 + 0 ];
	@!%p371 mov.u32 %r5389, %r684;
	@!%p371 mov.u32 %r5390, %r684;
	@!%p371 mov.u32 %r5391, %r684;
	@!%p371 mov.u32 %r5392, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r5397, 0x0;
	mov.u32 %r5398, 0x0;
	mov.u32 %r5399, 0x0;
	mov.u32 %r5400, 0x0;
	@%p376 ld.global.v4.b32 { %r5397, %r5398, %r5399, %r5400 }, [ %rd409 + 0 ];
	@!%p376 mov.u32 %r5397, %r684;
	@!%p376 mov.u32 %r5398, %r684;
	@!%p376 mov.u32 %r5399, %r684;
	@!%p376 mov.u32 %r5400, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r5405, 0x0;
	mov.u32 %r5406, 0x0;
	mov.u32 %r5407, 0x0;
	mov.u32 %r5408, 0x0;
	@%p381 ld.global.v4.b32 { %r5405, %r5406, %r5407, %r5408 }, [ %rd410 + 0 ];
	@!%p381 mov.u32 %r5405, %r684;
	@!%p381 mov.u32 %r5406, %r684;
	@!%p381 mov.u32 %r5407, %r684;
	@!%p381 mov.u32 %r5408, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r5413, 0x0;
	mov.u32 %r5414, 0x0;
	mov.u32 %r5415, 0x0;
	mov.u32 %r5416, 0x0;
	@%p386 ld.global.v4.b32 { %r5413, %r5414, %r5415, %r5416 }, [ %rd411 + 0 ];
	@!%p386 mov.u32 %r5413, %r684;
	@!%p386 mov.u32 %r5414, %r684;
	@!%p386 mov.u32 %r5415, %r684;
	@!%p386 mov.u32 %r5416, %r684;
	// end inline asm
	// begin inline asm
	mov.u32 %r5421, 0x0;
	mov.u32 %r5422, 0x0;
	mov.u32 %r5423, 0x0;
	mov.u32 %r5424, 0x0;
	@%p391 ld.global.v4.b32 { %r5421, %r5422, %r5423, %r5424 }, [ %rd412 + 0 ];
	@!%p391 mov.u32 %r5421, %r684;
	@!%p391 mov.u32 %r5422, %r684;
	@!%p391 mov.u32 %r5423, %r684;
	@!%p391 mov.u32 %r5424, %r684;
	// end inline asm
	bar.sync 	0;
	st.shared.v4.b32 	[%r577], {%r5365, %r5366, %r5367, %r5368};
	st.shared.v4.b32 	[%r577+2048], {%r5373, %r5374, %r5375, %r5376};
	st.shared.v4.b32 	[%r577+4096], {%r5381, %r5382, %r5383, %r5384};
	st.shared.v4.b32 	[%r577+6144], {%r5389, %r5390, %r5391, %r5392};
	st.shared.v4.b32 	[%r577+8192], {%r5397, %r5398, %r5399, %r5400};
	st.shared.v4.b32 	[%r577+10240], {%r5405, %r5406, %r5407, %r5408};
	st.shared.v4.b32 	[%r577+12288], {%r5413, %r5414, %r5415, %r5416};
	st.shared.v4.b32 	[%r577+14336], {%r5421, %r5422, %r5423, %r5424};
	.loc	1 264 17                        // prefix_prefill.py:264:17
	mov.b32 	%r5429, %f6744;
	// begin inline asm
	cvt.rn.bf16.f32 %rs321, %r5429;
	// end inline asm
	mov.b32 	%r5430, %f6746;
	// begin inline asm
	cvt.rn.bf16.f32 %rs322, %r5430;
	// end inline asm
	mov.b32 	%r5431, %f6748;
	// begin inline asm
	cvt.rn.bf16.f32 %rs323, %r5431;
	// end inline asm
	mov.b32 	%r5432, %f6750;
	// begin inline asm
	cvt.rn.bf16.f32 %rs324, %r5432;
	// end inline asm
	mov.b32 	%r5433, %f6752;
	// begin inline asm
	cvt.rn.bf16.f32 %rs325, %r5433;
	// end inline asm
	mov.b32 	%r5434, %f6754;
	// begin inline asm
	cvt.rn.bf16.f32 %rs326, %r5434;
	// end inline asm
	mov.b32 	%r5435, %f6756;
	// begin inline asm
	cvt.rn.bf16.f32 %rs327, %r5435;
	// end inline asm
	mov.b32 	%r5436, %f6758;
	// begin inline asm
	cvt.rn.bf16.f32 %rs328, %r5436;
	// end inline asm
	mov.b32 	%r5437, %f6760;
	// begin inline asm
	cvt.rn.bf16.f32 %rs329, %r5437;
	// end inline asm
	mov.b32 	%r5438, %f6762;
	// begin inline asm
	cvt.rn.bf16.f32 %rs330, %r5438;
	// end inline asm
	mov.b32 	%r5439, %f6764;
	// begin inline asm
	cvt.rn.bf16.f32 %rs331, %r5439;
	// end inline asm
	mov.b32 	%r5440, %f6766;
	// begin inline asm
	cvt.rn.bf16.f32 %rs332, %r5440;
	// end inline asm
	mov.b32 	%r5441, %f6768;
	// begin inline asm
	cvt.rn.bf16.f32 %rs333, %r5441;
	// end inline asm
	mov.b32 	%r5442, %f6770;
	// begin inline asm
	cvt.rn.bf16.f32 %rs334, %r5442;
	// end inline asm
	mov.b32 	%r5443, %f6772;
	// begin inline asm
	cvt.rn.bf16.f32 %rs335, %r5443;
	// end inline asm
	mov.b32 	%r5444, %f6774;
	// begin inline asm
	cvt.rn.bf16.f32 %rs336, %r5444;
	// end inline asm
	mov.b32 	%r5445, %f6776;
	// begin inline asm
	cvt.rn.bf16.f32 %rs337, %r5445;
	// end inline asm
	mov.b32 	%r5446, %f6778;
	// begin inline asm
	cvt.rn.bf16.f32 %rs338, %r5446;
	// end inline asm
	mov.b32 	%r5447, %f6780;
	// begin inline asm
	cvt.rn.bf16.f32 %rs339, %r5447;
	// end inline asm
	mov.b32 	%r5448, %f6782;
	// begin inline asm
	cvt.rn.bf16.f32 %rs340, %r5448;
	// end inline asm
	mov.b32 	%r5449, %f6784;
	// begin inline asm
	cvt.rn.bf16.f32 %rs341, %r5449;
	// end inline asm
	mov.b32 	%r5450, %f6786;
	// begin inline asm
	cvt.rn.bf16.f32 %rs342, %r5450;
	// end inline asm
	mov.b32 	%r5451, %f6788;
	// begin inline asm
	cvt.rn.bf16.f32 %rs343, %r5451;
	// end inline asm
	mov.b32 	%r5452, %f6790;
	// begin inline asm
	cvt.rn.bf16.f32 %rs344, %r5452;
	// end inline asm
	mov.b32 	%r5453, %f6792;
	// begin inline asm
	cvt.rn.bf16.f32 %rs345, %r5453;
	// end inline asm
	mov.b32 	%r5454, %f6794;
	// begin inline asm
	cvt.rn.bf16.f32 %rs346, %r5454;
	// end inline asm
	mov.b32 	%r5455, %f6796;
	// begin inline asm
	cvt.rn.bf16.f32 %rs347, %r5455;
	// end inline asm
	mov.b32 	%r5456, %f6798;
	// begin inline asm
	cvt.rn.bf16.f32 %rs348, %r5456;
	// end inline asm
	mov.b32 	%r5457, %f6800;
	// begin inline asm
	cvt.rn.bf16.f32 %rs349, %r5457;
	// end inline asm
	mov.b32 	%r5458, %f6802;
	// begin inline asm
	cvt.rn.bf16.f32 %rs350, %r5458;
	// end inline asm
	mov.b32 	%r5459, %f6804;
	// begin inline asm
	cvt.rn.bf16.f32 %rs351, %r5459;
	// end inline asm
	mov.b32 	%r5460, %f6806;
	// begin inline asm
	cvt.rn.bf16.f32 %rs352, %r5460;
	// end inline asm
	mov.b32 	%r5461, %f6808;
	// begin inline asm
	cvt.rn.bf16.f32 %rs353, %r5461;
	// end inline asm
	mov.b32 	%r5462, %f6810;
	// begin inline asm
	cvt.rn.bf16.f32 %rs354, %r5462;
	// end inline asm
	mov.b32 	%r5463, %f6812;
	// begin inline asm
	cvt.rn.bf16.f32 %rs355, %r5463;
	// end inline asm
	mov.b32 	%r5464, %f6814;
	// begin inline asm
	cvt.rn.bf16.f32 %rs356, %r5464;
	// end inline asm
	mov.b32 	%r5465, %f6816;
	// begin inline asm
	cvt.rn.bf16.f32 %rs357, %r5465;
	// end inline asm
	mov.b32 	%r5466, %f6818;
	// begin inline asm
	cvt.rn.bf16.f32 %rs358, %r5466;
	// end inline asm
	mov.b32 	%r5467, %f6820;
	// begin inline asm
	cvt.rn.bf16.f32 %rs359, %r5467;
	// end inline asm
	mov.b32 	%r5468, %f6822;
	// begin inline asm
	cvt.rn.bf16.f32 %rs360, %r5468;
	// end inline asm
	mov.b32 	%r5469, %f6824;
	// begin inline asm
	cvt.rn.bf16.f32 %rs361, %r5469;
	// end inline asm
	mov.b32 	%r5470, %f6826;
	// begin inline asm
	cvt.rn.bf16.f32 %rs362, %r5470;
	// end inline asm
	mov.b32 	%r5471, %f6828;
	// begin inline asm
	cvt.rn.bf16.f32 %rs363, %r5471;
	// end inline asm
	mov.b32 	%r5472, %f6830;
	// begin inline asm
	cvt.rn.bf16.f32 %rs364, %r5472;
	// end inline asm
	mov.b32 	%r5473, %f6832;
	// begin inline asm
	cvt.rn.bf16.f32 %rs365, %r5473;
	// end inline asm
	mov.b32 	%r5474, %f6834;
	// begin inline asm
	cvt.rn.bf16.f32 %rs366, %r5474;
	// end inline asm
	mov.b32 	%r5475, %f6836;
	// begin inline asm
	cvt.rn.bf16.f32 %rs367, %r5475;
	// end inline asm
	mov.b32 	%r5476, %f6838;
	// begin inline asm
	cvt.rn.bf16.f32 %rs368, %r5476;
	// end inline asm
	mov.b32 	%r5477, %f6840;
	// begin inline asm
	cvt.rn.bf16.f32 %rs369, %r5477;
	// end inline asm
	mov.b32 	%r5478, %f6842;
	// begin inline asm
	cvt.rn.bf16.f32 %rs370, %r5478;
	// end inline asm
	mov.b32 	%r5479, %f6844;
	// begin inline asm
	cvt.rn.bf16.f32 %rs371, %r5479;
	// end inline asm
	mov.b32 	%r5480, %f6846;
	// begin inline asm
	cvt.rn.bf16.f32 %rs372, %r5480;
	// end inline asm
	mov.b32 	%r5481, %f6848;
	// begin inline asm
	cvt.rn.bf16.f32 %rs373, %r5481;
	// end inline asm
	mov.b32 	%r5482, %f6850;
	// begin inline asm
	cvt.rn.bf16.f32 %rs374, %r5482;
	// end inline asm
	mov.b32 	%r5483, %f6852;
	// begin inline asm
	cvt.rn.bf16.f32 %rs375, %r5483;
	// end inline asm
	mov.b32 	%r5484, %f6854;
	// begin inline asm
	cvt.rn.bf16.f32 %rs376, %r5484;
	// end inline asm
	mov.b32 	%r5485, %f6856;
	// begin inline asm
	cvt.rn.bf16.f32 %rs377, %r5485;
	// end inline asm
	mov.b32 	%r5486, %f6858;
	// begin inline asm
	cvt.rn.bf16.f32 %rs378, %r5486;
	// end inline asm
	mov.b32 	%r5487, %f6860;
	// begin inline asm
	cvt.rn.bf16.f32 %rs379, %r5487;
	// end inline asm
	mov.b32 	%r5488, %f6862;
	// begin inline asm
	cvt.rn.bf16.f32 %rs380, %r5488;
	// end inline asm
	mov.b32 	%r5489, %f6864;
	// begin inline asm
	cvt.rn.bf16.f32 %rs381, %r5489;
	// end inline asm
	mov.b32 	%r5490, %f6866;
	// begin inline asm
	cvt.rn.bf16.f32 %rs382, %r5490;
	// end inline asm
	mov.b32 	%r5491, %f6868;
	// begin inline asm
	cvt.rn.bf16.f32 %rs383, %r5491;
	// end inline asm
	mov.b32 	%r5492, %f6870;
	// begin inline asm
	cvt.rn.bf16.f32 %rs384, %r5492;
	// end inline asm
	mov.b32 	%r5653, {%rs321, %rs322};
	mov.b32 	%r5654, {%rs323, %rs324};
	mov.b32 	%r5655, {%rs325, %rs326};
	mov.b32 	%r5656, {%rs327, %rs328};
	mov.b32 	%r5845, {%rs329, %rs330};
	mov.b32 	%r5846, {%rs331, %rs332};
	mov.b32 	%r5847, {%rs333, %rs334};
	mov.b32 	%r5848, {%rs335, %rs336};
	mov.b32 	%r6037, {%rs337, %rs338};
	mov.b32 	%r6038, {%rs339, %rs340};
	mov.b32 	%r6039, {%rs341, %rs342};
	mov.b32 	%r6040, {%rs343, %rs344};
	mov.b32 	%r6229, {%rs345, %rs346};
	mov.b32 	%r6230, {%rs347, %rs348};
	mov.b32 	%r6231, {%rs349, %rs350};
	mov.b32 	%r6232, {%rs351, %rs352};
	mov.b32 	%r5749, {%rs353, %rs354};
	mov.b32 	%r5750, {%rs355, %rs356};
	mov.b32 	%r5751, {%rs357, %rs358};
	mov.b32 	%r5752, {%rs359, %rs360};
	mov.b32 	%r5941, {%rs361, %rs362};
	mov.b32 	%r5942, {%rs363, %rs364};
	mov.b32 	%r5943, {%rs365, %rs366};
	mov.b32 	%r5944, {%rs367, %rs368};
	mov.b32 	%r6133, {%rs369, %rs370};
	mov.b32 	%r6134, {%rs371, %rs372};
	mov.b32 	%r6135, {%rs373, %rs374};
	mov.b32 	%r6136, {%rs375, %rs376};
	mov.b32 	%r6325, {%rs377, %rs378};
	mov.b32 	%r6326, {%rs379, %rs380};
	mov.b32 	%r6327, {%rs381, %rs382};
	mov.b32 	%r6328, {%rs383, %rs384};
	.loc	1 259 20                        // prefix_prefill.py:259:20
	bar.sync 	0;
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r5657, %r5658, %r5663, %r5664 }, [ %r5497 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r5849, %r5850, %r5855, %r5856 }, [ %r5502 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r6041, %r6042, %r6047, %r6048 }, [ %r5507 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r6233, %r6234, %r6239, %r6240 }, [ %r5512 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r5669, %r5670, %r5675, %r5676 }, [ %r5517 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r5861, %r5862, %r5867, %r5868 }, [ %r5522 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r6053, %r6054, %r6059, %r6060 }, [ %r5527 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r6245, %r6246, %r6251, %r6252 }, [ %r5532 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r5681, %r5682, %r5687, %r5688 }, [ %r5537 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r5873, %r5874, %r5879, %r5880 }, [ %r5542 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r6065, %r6066, %r6071, %r6072 }, [ %r5547 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r6257, %r6258, %r6263, %r6264 }, [ %r5552 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r5693, %r5694, %r5699, %r5700 }, [ %r5557 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r5885, %r5886, %r5891, %r5892 }, [ %r5562 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r6077, %r6078, %r6083, %r6084 }, [ %r5567 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r6269, %r6270, %r6275, %r6276 }, [ %r5572 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r5705, %r5706, %r5711, %r5712 }, [ %r5577 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r5897, %r5898, %r5903, %r5904 }, [ %r5582 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r6089, %r6090, %r6095, %r6096 }, [ %r5587 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r6281, %r6282, %r6287, %r6288 }, [ %r5592 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r5717, %r5718, %r5723, %r5724 }, [ %r5597 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r5909, %r5910, %r5915, %r5916 }, [ %r5602 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r6101, %r6102, %r6107, %r6108 }, [ %r5607 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r6293, %r6294, %r6299, %r6300 }, [ %r5612 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r5729, %r5730, %r5735, %r5736 }, [ %r5617 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r5921, %r5922, %r5927, %r5928 }, [ %r5622 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r6113, %r6114, %r6119, %r6120 }, [ %r5627 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r6305, %r6306, %r6311, %r6312 }, [ %r5632 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r5741, %r5742, %r5747, %r5748 }, [ %r5637 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r5933, %r5934, %r5939, %r5940 }, [ %r5642 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r6125, %r6126, %r6131, %r6132 }, [ %r5647 + 0 ];
	// end inline asm
	// begin inline asm
	ldmatrix.sync.aligned.m8n8.x4.trans.shared.b16 { %r6317, %r6318, %r6323, %r6324 }, [ %r5652 + 0 ];
	// end inline asm
	.loc	1 266 24                        // prefix_prefill.py:266:24
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8524, %f8525, %f8526, %f8527 }, { %r5653, %r5654, %r5655, %r5656 }, { %r5657, %r5658 }, { %f8524, %f8525, %f8526, %f8527 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8528, %f8529, %f8530, %f8531 }, { %r5653, %r5654, %r5655, %r5656 }, { %r5663, %r5664 }, { %f8528, %f8529, %f8530, %f8531 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8532, %f8533, %f8534, %f8535 }, { %r5653, %r5654, %r5655, %r5656 }, { %r5669, %r5670 }, { %f8532, %f8533, %f8534, %f8535 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8536, %f8537, %f8538, %f8539 }, { %r5653, %r5654, %r5655, %r5656 }, { %r5675, %r5676 }, { %f8536, %f8537, %f8538, %f8539 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8540, %f8541, %f8542, %f8543 }, { %r5653, %r5654, %r5655, %r5656 }, { %r5681, %r5682 }, { %f8540, %f8541, %f8542, %f8543 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8544, %f8545, %f8546, %f8547 }, { %r5653, %r5654, %r5655, %r5656 }, { %r5687, %r5688 }, { %f8544, %f8545, %f8546, %f8547 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8548, %f8549, %f8550, %f8551 }, { %r5653, %r5654, %r5655, %r5656 }, { %r5693, %r5694 }, { %f8548, %f8549, %f8550, %f8551 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8552, %f8553, %f8554, %f8555 }, { %r5653, %r5654, %r5655, %r5656 }, { %r5699, %r5700 }, { %f8552, %f8553, %f8554, %f8555 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8556, %f8557, %f8558, %f8559 }, { %r5653, %r5654, %r5655, %r5656 }, { %r5705, %r5706 }, { %f8556, %f8557, %f8558, %f8559 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8560, %f8561, %f8562, %f8563 }, { %r5653, %r5654, %r5655, %r5656 }, { %r5711, %r5712 }, { %f8560, %f8561, %f8562, %f8563 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8564, %f8565, %f8566, %f8567 }, { %r5653, %r5654, %r5655, %r5656 }, { %r5717, %r5718 }, { %f8564, %f8565, %f8566, %f8567 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8568, %f8569, %f8570, %f8571 }, { %r5653, %r5654, %r5655, %r5656 }, { %r5723, %r5724 }, { %f8568, %f8569, %f8570, %f8571 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8572, %f8573, %f8574, %f8575 }, { %r5653, %r5654, %r5655, %r5656 }, { %r5729, %r5730 }, { %f8572, %f8573, %f8574, %f8575 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8576, %f8577, %f8578, %f8579 }, { %r5653, %r5654, %r5655, %r5656 }, { %r5735, %r5736 }, { %f8576, %f8577, %f8578, %f8579 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8580, %f8581, %f8582, %f8583 }, { %r5653, %r5654, %r5655, %r5656 }, { %r5741, %r5742 }, { %f8580, %f8581, %f8582, %f8583 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8584, %f8585, %f8586, %f8587 }, { %r5653, %r5654, %r5655, %r5656 }, { %r5747, %r5748 }, { %f8584, %f8585, %f8586, %f8587 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8588, %f8589, %f8590, %f8591 }, { %r5749, %r5750, %r5751, %r5752 }, { %r5657, %r5658 }, { %f8588, %f8589, %f8590, %f8591 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8592, %f8593, %f8594, %f8595 }, { %r5749, %r5750, %r5751, %r5752 }, { %r5663, %r5664 }, { %f8592, %f8593, %f8594, %f8595 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8596, %f8597, %f8598, %f8599 }, { %r5749, %r5750, %r5751, %r5752 }, { %r5669, %r5670 }, { %f8596, %f8597, %f8598, %f8599 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8600, %f8601, %f8602, %f8603 }, { %r5749, %r5750, %r5751, %r5752 }, { %r5675, %r5676 }, { %f8600, %f8601, %f8602, %f8603 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8604, %f8605, %f8606, %f8607 }, { %r5749, %r5750, %r5751, %r5752 }, { %r5681, %r5682 }, { %f8604, %f8605, %f8606, %f8607 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8608, %f8609, %f8610, %f8611 }, { %r5749, %r5750, %r5751, %r5752 }, { %r5687, %r5688 }, { %f8608, %f8609, %f8610, %f8611 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8612, %f8613, %f8614, %f8615 }, { %r5749, %r5750, %r5751, %r5752 }, { %r5693, %r5694 }, { %f8612, %f8613, %f8614, %f8615 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8616, %f8617, %f8618, %f8619 }, { %r5749, %r5750, %r5751, %r5752 }, { %r5699, %r5700 }, { %f8616, %f8617, %f8618, %f8619 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8620, %f8621, %f8622, %f8623 }, { %r5749, %r5750, %r5751, %r5752 }, { %r5705, %r5706 }, { %f8620, %f8621, %f8622, %f8623 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8624, %f8625, %f8626, %f8627 }, { %r5749, %r5750, %r5751, %r5752 }, { %r5711, %r5712 }, { %f8624, %f8625, %f8626, %f8627 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8628, %f8629, %f8630, %f8631 }, { %r5749, %r5750, %r5751, %r5752 }, { %r5717, %r5718 }, { %f8628, %f8629, %f8630, %f8631 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8632, %f8633, %f8634, %f8635 }, { %r5749, %r5750, %r5751, %r5752 }, { %r5723, %r5724 }, { %f8632, %f8633, %f8634, %f8635 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8636, %f8637, %f8638, %f8639 }, { %r5749, %r5750, %r5751, %r5752 }, { %r5729, %r5730 }, { %f8636, %f8637, %f8638, %f8639 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8640, %f8641, %f8642, %f8643 }, { %r5749, %r5750, %r5751, %r5752 }, { %r5735, %r5736 }, { %f8640, %f8641, %f8642, %f8643 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8644, %f8645, %f8646, %f8647 }, { %r5749, %r5750, %r5751, %r5752 }, { %r5741, %r5742 }, { %f8644, %f8645, %f8646, %f8647 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8648, %f8649, %f8650, %f8651 }, { %r5749, %r5750, %r5751, %r5752 }, { %r5747, %r5748 }, { %f8648, %f8649, %f8650, %f8651 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8524, %f8525, %f8526, %f8527 }, { %r5845, %r5846, %r5847, %r5848 }, { %r5849, %r5850 }, { %f8524, %f8525, %f8526, %f8527 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8528, %f8529, %f8530, %f8531 }, { %r5845, %r5846, %r5847, %r5848 }, { %r5855, %r5856 }, { %f8528, %f8529, %f8530, %f8531 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8532, %f8533, %f8534, %f8535 }, { %r5845, %r5846, %r5847, %r5848 }, { %r5861, %r5862 }, { %f8532, %f8533, %f8534, %f8535 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8536, %f8537, %f8538, %f8539 }, { %r5845, %r5846, %r5847, %r5848 }, { %r5867, %r5868 }, { %f8536, %f8537, %f8538, %f8539 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8540, %f8541, %f8542, %f8543 }, { %r5845, %r5846, %r5847, %r5848 }, { %r5873, %r5874 }, { %f8540, %f8541, %f8542, %f8543 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8544, %f8545, %f8546, %f8547 }, { %r5845, %r5846, %r5847, %r5848 }, { %r5879, %r5880 }, { %f8544, %f8545, %f8546, %f8547 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8548, %f8549, %f8550, %f8551 }, { %r5845, %r5846, %r5847, %r5848 }, { %r5885, %r5886 }, { %f8548, %f8549, %f8550, %f8551 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8552, %f8553, %f8554, %f8555 }, { %r5845, %r5846, %r5847, %r5848 }, { %r5891, %r5892 }, { %f8552, %f8553, %f8554, %f8555 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8556, %f8557, %f8558, %f8559 }, { %r5845, %r5846, %r5847, %r5848 }, { %r5897, %r5898 }, { %f8556, %f8557, %f8558, %f8559 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8560, %f8561, %f8562, %f8563 }, { %r5845, %r5846, %r5847, %r5848 }, { %r5903, %r5904 }, { %f8560, %f8561, %f8562, %f8563 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8564, %f8565, %f8566, %f8567 }, { %r5845, %r5846, %r5847, %r5848 }, { %r5909, %r5910 }, { %f8564, %f8565, %f8566, %f8567 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8568, %f8569, %f8570, %f8571 }, { %r5845, %r5846, %r5847, %r5848 }, { %r5915, %r5916 }, { %f8568, %f8569, %f8570, %f8571 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8572, %f8573, %f8574, %f8575 }, { %r5845, %r5846, %r5847, %r5848 }, { %r5921, %r5922 }, { %f8572, %f8573, %f8574, %f8575 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8576, %f8577, %f8578, %f8579 }, { %r5845, %r5846, %r5847, %r5848 }, { %r5927, %r5928 }, { %f8576, %f8577, %f8578, %f8579 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8580, %f8581, %f8582, %f8583 }, { %r5845, %r5846, %r5847, %r5848 }, { %r5933, %r5934 }, { %f8580, %f8581, %f8582, %f8583 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8584, %f8585, %f8586, %f8587 }, { %r5845, %r5846, %r5847, %r5848 }, { %r5939, %r5940 }, { %f8584, %f8585, %f8586, %f8587 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8588, %f8589, %f8590, %f8591 }, { %r5941, %r5942, %r5943, %r5944 }, { %r5849, %r5850 }, { %f8588, %f8589, %f8590, %f8591 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8592, %f8593, %f8594, %f8595 }, { %r5941, %r5942, %r5943, %r5944 }, { %r5855, %r5856 }, { %f8592, %f8593, %f8594, %f8595 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8596, %f8597, %f8598, %f8599 }, { %r5941, %r5942, %r5943, %r5944 }, { %r5861, %r5862 }, { %f8596, %f8597, %f8598, %f8599 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8600, %f8601, %f8602, %f8603 }, { %r5941, %r5942, %r5943, %r5944 }, { %r5867, %r5868 }, { %f8600, %f8601, %f8602, %f8603 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8604, %f8605, %f8606, %f8607 }, { %r5941, %r5942, %r5943, %r5944 }, { %r5873, %r5874 }, { %f8604, %f8605, %f8606, %f8607 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8608, %f8609, %f8610, %f8611 }, { %r5941, %r5942, %r5943, %r5944 }, { %r5879, %r5880 }, { %f8608, %f8609, %f8610, %f8611 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8612, %f8613, %f8614, %f8615 }, { %r5941, %r5942, %r5943, %r5944 }, { %r5885, %r5886 }, { %f8612, %f8613, %f8614, %f8615 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8616, %f8617, %f8618, %f8619 }, { %r5941, %r5942, %r5943, %r5944 }, { %r5891, %r5892 }, { %f8616, %f8617, %f8618, %f8619 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8620, %f8621, %f8622, %f8623 }, { %r5941, %r5942, %r5943, %r5944 }, { %r5897, %r5898 }, { %f8620, %f8621, %f8622, %f8623 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8624, %f8625, %f8626, %f8627 }, { %r5941, %r5942, %r5943, %r5944 }, { %r5903, %r5904 }, { %f8624, %f8625, %f8626, %f8627 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8628, %f8629, %f8630, %f8631 }, { %r5941, %r5942, %r5943, %r5944 }, { %r5909, %r5910 }, { %f8628, %f8629, %f8630, %f8631 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8632, %f8633, %f8634, %f8635 }, { %r5941, %r5942, %r5943, %r5944 }, { %r5915, %r5916 }, { %f8632, %f8633, %f8634, %f8635 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8636, %f8637, %f8638, %f8639 }, { %r5941, %r5942, %r5943, %r5944 }, { %r5921, %r5922 }, { %f8636, %f8637, %f8638, %f8639 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8640, %f8641, %f8642, %f8643 }, { %r5941, %r5942, %r5943, %r5944 }, { %r5927, %r5928 }, { %f8640, %f8641, %f8642, %f8643 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8644, %f8645, %f8646, %f8647 }, { %r5941, %r5942, %r5943, %r5944 }, { %r5933, %r5934 }, { %f8644, %f8645, %f8646, %f8647 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8648, %f8649, %f8650, %f8651 }, { %r5941, %r5942, %r5943, %r5944 }, { %r5939, %r5940 }, { %f8648, %f8649, %f8650, %f8651 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8524, %f8525, %f8526, %f8527 }, { %r6037, %r6038, %r6039, %r6040 }, { %r6041, %r6042 }, { %f8524, %f8525, %f8526, %f8527 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8528, %f8529, %f8530, %f8531 }, { %r6037, %r6038, %r6039, %r6040 }, { %r6047, %r6048 }, { %f8528, %f8529, %f8530, %f8531 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8532, %f8533, %f8534, %f8535 }, { %r6037, %r6038, %r6039, %r6040 }, { %r6053, %r6054 }, { %f8532, %f8533, %f8534, %f8535 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8536, %f8537, %f8538, %f8539 }, { %r6037, %r6038, %r6039, %r6040 }, { %r6059, %r6060 }, { %f8536, %f8537, %f8538, %f8539 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8540, %f8541, %f8542, %f8543 }, { %r6037, %r6038, %r6039, %r6040 }, { %r6065, %r6066 }, { %f8540, %f8541, %f8542, %f8543 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8544, %f8545, %f8546, %f8547 }, { %r6037, %r6038, %r6039, %r6040 }, { %r6071, %r6072 }, { %f8544, %f8545, %f8546, %f8547 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8548, %f8549, %f8550, %f8551 }, { %r6037, %r6038, %r6039, %r6040 }, { %r6077, %r6078 }, { %f8548, %f8549, %f8550, %f8551 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8552, %f8553, %f8554, %f8555 }, { %r6037, %r6038, %r6039, %r6040 }, { %r6083, %r6084 }, { %f8552, %f8553, %f8554, %f8555 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8556, %f8557, %f8558, %f8559 }, { %r6037, %r6038, %r6039, %r6040 }, { %r6089, %r6090 }, { %f8556, %f8557, %f8558, %f8559 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8560, %f8561, %f8562, %f8563 }, { %r6037, %r6038, %r6039, %r6040 }, { %r6095, %r6096 }, { %f8560, %f8561, %f8562, %f8563 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8564, %f8565, %f8566, %f8567 }, { %r6037, %r6038, %r6039, %r6040 }, { %r6101, %r6102 }, { %f8564, %f8565, %f8566, %f8567 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8568, %f8569, %f8570, %f8571 }, { %r6037, %r6038, %r6039, %r6040 }, { %r6107, %r6108 }, { %f8568, %f8569, %f8570, %f8571 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8572, %f8573, %f8574, %f8575 }, { %r6037, %r6038, %r6039, %r6040 }, { %r6113, %r6114 }, { %f8572, %f8573, %f8574, %f8575 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8576, %f8577, %f8578, %f8579 }, { %r6037, %r6038, %r6039, %r6040 }, { %r6119, %r6120 }, { %f8576, %f8577, %f8578, %f8579 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8580, %f8581, %f8582, %f8583 }, { %r6037, %r6038, %r6039, %r6040 }, { %r6125, %r6126 }, { %f8580, %f8581, %f8582, %f8583 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8584, %f8585, %f8586, %f8587 }, { %r6037, %r6038, %r6039, %r6040 }, { %r6131, %r6132 }, { %f8584, %f8585, %f8586, %f8587 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8588, %f8589, %f8590, %f8591 }, { %r6133, %r6134, %r6135, %r6136 }, { %r6041, %r6042 }, { %f8588, %f8589, %f8590, %f8591 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8592, %f8593, %f8594, %f8595 }, { %r6133, %r6134, %r6135, %r6136 }, { %r6047, %r6048 }, { %f8592, %f8593, %f8594, %f8595 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8596, %f8597, %f8598, %f8599 }, { %r6133, %r6134, %r6135, %r6136 }, { %r6053, %r6054 }, { %f8596, %f8597, %f8598, %f8599 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8600, %f8601, %f8602, %f8603 }, { %r6133, %r6134, %r6135, %r6136 }, { %r6059, %r6060 }, { %f8600, %f8601, %f8602, %f8603 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8604, %f8605, %f8606, %f8607 }, { %r6133, %r6134, %r6135, %r6136 }, { %r6065, %r6066 }, { %f8604, %f8605, %f8606, %f8607 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8608, %f8609, %f8610, %f8611 }, { %r6133, %r6134, %r6135, %r6136 }, { %r6071, %r6072 }, { %f8608, %f8609, %f8610, %f8611 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8612, %f8613, %f8614, %f8615 }, { %r6133, %r6134, %r6135, %r6136 }, { %r6077, %r6078 }, { %f8612, %f8613, %f8614, %f8615 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8616, %f8617, %f8618, %f8619 }, { %r6133, %r6134, %r6135, %r6136 }, { %r6083, %r6084 }, { %f8616, %f8617, %f8618, %f8619 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8620, %f8621, %f8622, %f8623 }, { %r6133, %r6134, %r6135, %r6136 }, { %r6089, %r6090 }, { %f8620, %f8621, %f8622, %f8623 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8624, %f8625, %f8626, %f8627 }, { %r6133, %r6134, %r6135, %r6136 }, { %r6095, %r6096 }, { %f8624, %f8625, %f8626, %f8627 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8628, %f8629, %f8630, %f8631 }, { %r6133, %r6134, %r6135, %r6136 }, { %r6101, %r6102 }, { %f8628, %f8629, %f8630, %f8631 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8632, %f8633, %f8634, %f8635 }, { %r6133, %r6134, %r6135, %r6136 }, { %r6107, %r6108 }, { %f8632, %f8633, %f8634, %f8635 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8636, %f8637, %f8638, %f8639 }, { %r6133, %r6134, %r6135, %r6136 }, { %r6113, %r6114 }, { %f8636, %f8637, %f8638, %f8639 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8640, %f8641, %f8642, %f8643 }, { %r6133, %r6134, %r6135, %r6136 }, { %r6119, %r6120 }, { %f8640, %f8641, %f8642, %f8643 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8644, %f8645, %f8646, %f8647 }, { %r6133, %r6134, %r6135, %r6136 }, { %r6125, %r6126 }, { %f8644, %f8645, %f8646, %f8647 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8648, %f8649, %f8650, %f8651 }, { %r6133, %r6134, %r6135, %r6136 }, { %r6131, %r6132 }, { %f8648, %f8649, %f8650, %f8651 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8524, %f8525, %f8526, %f8527 }, { %r6229, %r6230, %r6231, %r6232 }, { %r6233, %r6234 }, { %f8524, %f8525, %f8526, %f8527 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8528, %f8529, %f8530, %f8531 }, { %r6229, %r6230, %r6231, %r6232 }, { %r6239, %r6240 }, { %f8528, %f8529, %f8530, %f8531 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8532, %f8533, %f8534, %f8535 }, { %r6229, %r6230, %r6231, %r6232 }, { %r6245, %r6246 }, { %f8532, %f8533, %f8534, %f8535 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8536, %f8537, %f8538, %f8539 }, { %r6229, %r6230, %r6231, %r6232 }, { %r6251, %r6252 }, { %f8536, %f8537, %f8538, %f8539 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8540, %f8541, %f8542, %f8543 }, { %r6229, %r6230, %r6231, %r6232 }, { %r6257, %r6258 }, { %f8540, %f8541, %f8542, %f8543 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8544, %f8545, %f8546, %f8547 }, { %r6229, %r6230, %r6231, %r6232 }, { %r6263, %r6264 }, { %f8544, %f8545, %f8546, %f8547 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8548, %f8549, %f8550, %f8551 }, { %r6229, %r6230, %r6231, %r6232 }, { %r6269, %r6270 }, { %f8548, %f8549, %f8550, %f8551 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8552, %f8553, %f8554, %f8555 }, { %r6229, %r6230, %r6231, %r6232 }, { %r6275, %r6276 }, { %f8552, %f8553, %f8554, %f8555 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8556, %f8557, %f8558, %f8559 }, { %r6229, %r6230, %r6231, %r6232 }, { %r6281, %r6282 }, { %f8556, %f8557, %f8558, %f8559 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8560, %f8561, %f8562, %f8563 }, { %r6229, %r6230, %r6231, %r6232 }, { %r6287, %r6288 }, { %f8560, %f8561, %f8562, %f8563 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8564, %f8565, %f8566, %f8567 }, { %r6229, %r6230, %r6231, %r6232 }, { %r6293, %r6294 }, { %f8564, %f8565, %f8566, %f8567 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8568, %f8569, %f8570, %f8571 }, { %r6229, %r6230, %r6231, %r6232 }, { %r6299, %r6300 }, { %f8568, %f8569, %f8570, %f8571 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8572, %f8573, %f8574, %f8575 }, { %r6229, %r6230, %r6231, %r6232 }, { %r6305, %r6306 }, { %f8572, %f8573, %f8574, %f8575 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8576, %f8577, %f8578, %f8579 }, { %r6229, %r6230, %r6231, %r6232 }, { %r6311, %r6312 }, { %f8576, %f8577, %f8578, %f8579 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8580, %f8581, %f8582, %f8583 }, { %r6229, %r6230, %r6231, %r6232 }, { %r6317, %r6318 }, { %f8580, %f8581, %f8582, %f8583 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8584, %f8585, %f8586, %f8587 }, { %r6229, %r6230, %r6231, %r6232 }, { %r6323, %r6324 }, { %f8584, %f8585, %f8586, %f8587 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8588, %f8589, %f8590, %f8591 }, { %r6325, %r6326, %r6327, %r6328 }, { %r6233, %r6234 }, { %f8588, %f8589, %f8590, %f8591 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8592, %f8593, %f8594, %f8595 }, { %r6325, %r6326, %r6327, %r6328 }, { %r6239, %r6240 }, { %f8592, %f8593, %f8594, %f8595 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8596, %f8597, %f8598, %f8599 }, { %r6325, %r6326, %r6327, %r6328 }, { %r6245, %r6246 }, { %f8596, %f8597, %f8598, %f8599 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8600, %f8601, %f8602, %f8603 }, { %r6325, %r6326, %r6327, %r6328 }, { %r6251, %r6252 }, { %f8600, %f8601, %f8602, %f8603 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8604, %f8605, %f8606, %f8607 }, { %r6325, %r6326, %r6327, %r6328 }, { %r6257, %r6258 }, { %f8604, %f8605, %f8606, %f8607 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8608, %f8609, %f8610, %f8611 }, { %r6325, %r6326, %r6327, %r6328 }, { %r6263, %r6264 }, { %f8608, %f8609, %f8610, %f8611 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8612, %f8613, %f8614, %f8615 }, { %r6325, %r6326, %r6327, %r6328 }, { %r6269, %r6270 }, { %f8612, %f8613, %f8614, %f8615 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8616, %f8617, %f8618, %f8619 }, { %r6325, %r6326, %r6327, %r6328 }, { %r6275, %r6276 }, { %f8616, %f8617, %f8618, %f8619 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8620, %f8621, %f8622, %f8623 }, { %r6325, %r6326, %r6327, %r6328 }, { %r6281, %r6282 }, { %f8620, %f8621, %f8622, %f8623 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8624, %f8625, %f8626, %f8627 }, { %r6325, %r6326, %r6327, %r6328 }, { %r6287, %r6288 }, { %f8624, %f8625, %f8626, %f8627 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8628, %f8629, %f8630, %f8631 }, { %r6325, %r6326, %r6327, %r6328 }, { %r6293, %r6294 }, { %f8628, %f8629, %f8630, %f8631 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8632, %f8633, %f8634, %f8635 }, { %r6325, %r6326, %r6327, %r6328 }, { %r6299, %r6300 }, { %f8632, %f8633, %f8634, %f8635 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8636, %f8637, %f8638, %f8639 }, { %r6325, %r6326, %r6327, %r6328 }, { %r6305, %r6306 }, { %f8636, %f8637, %f8638, %f8639 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8640, %f8641, %f8642, %f8643 }, { %r6325, %r6326, %r6327, %r6328 }, { %r6311, %r6312 }, { %f8640, %f8641, %f8642, %f8643 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8644, %f8645, %f8646, %f8647 }, { %r6325, %r6326, %r6327, %r6328 }, { %r6317, %r6318 }, { %f8644, %f8645, %f8646, %f8647 };
	// end inline asm
	// begin inline asm
	mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32 { %f8648, %f8649, %f8650, %f8651 }, { %r6325, %r6326, %r6327, %r6328 }, { %r6323, %r6324 }, { %f8648, %f8649, %f8650, %f8651 };
	// end inline asm
$L__tmp25:
	.loc	2 267 36                        // standard.py:267:36
	mov.b32 	%f8244, %r6515;
	mov.b32 	%f8245, %r6519;
	mov.b32 	%f8246, %r6511;
	mov.b32 	%f8247, %r6507;
	.loc	2 256 15                        // standard.py:256:15
	add.f32 	%f8248, %f8239, %f8245;
	add.f32 	%f8249, %f8237, %f8244;
	add.f32 	%f8250, %f8233, %f8247;
	add.f32 	%f8251, %f8235, %f8246;
$L__tmp26:
	.loc	1 268 28                        // prefix_prefill.py:268:28
	fma.rn.f32 	%f8790, %f8790, %f6876, %f8249;
	fma.rn.f32 	%f8791, %f8791, %f6878, %f8248;
	fma.rn.f32 	%f8789, %f8789, %f6874, %f8251;
	fma.rn.f32 	%f8788, %f8788, %f6872, %f8250;
	.loc	1 231 24                        // prefix_prefill.py:231:24
	add.s64 	%rd551, %rd551, 64;
	add.s32 	%r7409, %r7409, %r659;
	add.s32 	%r7408, %r7408, %r661;
	setp.lt.u64 	%p545, %rd551, %rd29;
	mov.f32 	%f8516, %f2133;
	mov.f32 	%f8517, %f2134;
	mov.f32 	%f8518, %f2135;
	mov.f32 	%f8519, %f2136;
	@%p545 bra 	$L__BB0_38;
$L__BB0_39:                             // %._crit_edge733
	.loc	1 271 16                        // prefix_prefill.py:271:16
	mov.b32 	%r6585, %f8524;
	mov.b32 	%r6586, %f8788;
	// begin inline asm
	div.full.f32 %r6968, %r6585, %r6586;
	// end inline asm
	mov.b32 	%r6588, %f8525;
	// begin inline asm
	div.full.f32 %r6969, %r6588, %r6586;
	// end inline asm
	mov.b32 	%r6591, %f8526;
	mov.b32 	%r6592, %f8789;
	// begin inline asm
	div.full.f32 %r6970, %r6591, %r6592;
	// end inline asm
	mov.b32 	%r6594, %f8527;
	// begin inline asm
	div.full.f32 %r6971, %r6594, %r6592;
	// end inline asm
	mov.b32 	%r6597, %f8528;
	// begin inline asm
	div.full.f32 %r6972, %r6597, %r6586;
	// end inline asm
	mov.b32 	%r6600, %f8529;
	// begin inline asm
	div.full.f32 %r6973, %r6600, %r6586;
	// end inline asm
	mov.b32 	%r6603, %f8530;
	// begin inline asm
	div.full.f32 %r6974, %r6603, %r6592;
	// end inline asm
	mov.b32 	%r6606, %f8531;
	// begin inline asm
	div.full.f32 %r6975, %r6606, %r6592;
	// end inline asm
	mov.b32 	%r6609, %f8532;
	// begin inline asm
	div.full.f32 %r6976, %r6609, %r6586;
	// end inline asm
	mov.b32 	%r6612, %f8533;
	// begin inline asm
	div.full.f32 %r6977, %r6612, %r6586;
	// end inline asm
	mov.b32 	%r6615, %f8534;
	// begin inline asm
	div.full.f32 %r6978, %r6615, %r6592;
	// end inline asm
	mov.b32 	%r6618, %f8535;
	// begin inline asm
	div.full.f32 %r6979, %r6618, %r6592;
	// end inline asm
	mov.b32 	%r6621, %f8536;
	// begin inline asm
	div.full.f32 %r6980, %r6621, %r6586;
	// end inline asm
	mov.b32 	%r6624, %f8537;
	// begin inline asm
	div.full.f32 %r6981, %r6624, %r6586;
	// end inline asm
	mov.b32 	%r6627, %f8538;
	// begin inline asm
	div.full.f32 %r6982, %r6627, %r6592;
	// end inline asm
	mov.b32 	%r6630, %f8539;
	// begin inline asm
	div.full.f32 %r6983, %r6630, %r6592;
	// end inline asm
	mov.b32 	%r6633, %f8540;
	// begin inline asm
	div.full.f32 %r6984, %r6633, %r6586;
	// end inline asm
	mov.b32 	%r6636, %f8541;
	// begin inline asm
	div.full.f32 %r6985, %r6636, %r6586;
	// end inline asm
	mov.b32 	%r6639, %f8542;
	// begin inline asm
	div.full.f32 %r6986, %r6639, %r6592;
	// end inline asm
	mov.b32 	%r6642, %f8543;
	// begin inline asm
	div.full.f32 %r6987, %r6642, %r6592;
	// end inline asm
	mov.b32 	%r6645, %f8544;
	// begin inline asm
	div.full.f32 %r6988, %r6645, %r6586;
	// end inline asm
	mov.b32 	%r6648, %f8545;
	// begin inline asm
	div.full.f32 %r6989, %r6648, %r6586;
	// end inline asm
	mov.b32 	%r6651, %f8546;
	// begin inline asm
	div.full.f32 %r6990, %r6651, %r6592;
	// end inline asm
	mov.b32 	%r6654, %f8547;
	// begin inline asm
	div.full.f32 %r6991, %r6654, %r6592;
	// end inline asm
	mov.b32 	%r6657, %f8548;
	// begin inline asm
	div.full.f32 %r6992, %r6657, %r6586;
	// end inline asm
	mov.b32 	%r6660, %f8549;
	// begin inline asm
	div.full.f32 %r6993, %r6660, %r6586;
	// end inline asm
	mov.b32 	%r6663, %f8550;
	// begin inline asm
	div.full.f32 %r6994, %r6663, %r6592;
	// end inline asm
	mov.b32 	%r6666, %f8551;
	// begin inline asm
	div.full.f32 %r6995, %r6666, %r6592;
	// end inline asm
	mov.b32 	%r6669, %f8552;
	// begin inline asm
	div.full.f32 %r6996, %r6669, %r6586;
	// end inline asm
	mov.b32 	%r6672, %f8553;
	// begin inline asm
	div.full.f32 %r6997, %r6672, %r6586;
	// end inline asm
	mov.b32 	%r6675, %f8554;
	// begin inline asm
	div.full.f32 %r6998, %r6675, %r6592;
	// end inline asm
	mov.b32 	%r6678, %f8555;
	// begin inline asm
	div.full.f32 %r6999, %r6678, %r6592;
	// end inline asm
	mov.b32 	%r6681, %f8556;
	// begin inline asm
	div.full.f32 %r7000, %r6681, %r6586;
	// end inline asm
	mov.b32 	%r6684, %f8557;
	// begin inline asm
	div.full.f32 %r7001, %r6684, %r6586;
	// end inline asm
	mov.b32 	%r6687, %f8558;
	// begin inline asm
	div.full.f32 %r7002, %r6687, %r6592;
	// end inline asm
	mov.b32 	%r6690, %f8559;
	// begin inline asm
	div.full.f32 %r7003, %r6690, %r6592;
	// end inline asm
	mov.b32 	%r6693, %f8560;
	// begin inline asm
	div.full.f32 %r7004, %r6693, %r6586;
	// end inline asm
	mov.b32 	%r6696, %f8561;
	// begin inline asm
	div.full.f32 %r7005, %r6696, %r6586;
	// end inline asm
	mov.b32 	%r6699, %f8562;
	// begin inline asm
	div.full.f32 %r7006, %r6699, %r6592;
	// end inline asm
	mov.b32 	%r6702, %f8563;
	// begin inline asm
	div.full.f32 %r7007, %r6702, %r6592;
	// end inline asm
	mov.b32 	%r6705, %f8564;
	// begin inline asm
	div.full.f32 %r7008, %r6705, %r6586;
	// end inline asm
	mov.b32 	%r6708, %f8565;
	// begin inline asm
	div.full.f32 %r7009, %r6708, %r6586;
	// end inline asm
	mov.b32 	%r6711, %f8566;
	// begin inline asm
	div.full.f32 %r7010, %r6711, %r6592;
	// end inline asm
	mov.b32 	%r6714, %f8567;
	// begin inline asm
	div.full.f32 %r7011, %r6714, %r6592;
	// end inline asm
	mov.b32 	%r6717, %f8568;
	// begin inline asm
	div.full.f32 %r7012, %r6717, %r6586;
	// end inline asm
	mov.b32 	%r6720, %f8569;
	// begin inline asm
	div.full.f32 %r7013, %r6720, %r6586;
	// end inline asm
	mov.b32 	%r6723, %f8570;
	// begin inline asm
	div.full.f32 %r7014, %r6723, %r6592;
	// end inline asm
	mov.b32 	%r6726, %f8571;
	// begin inline asm
	div.full.f32 %r7015, %r6726, %r6592;
	// end inline asm
	mov.b32 	%r6729, %f8572;
	// begin inline asm
	div.full.f32 %r7016, %r6729, %r6586;
	// end inline asm
	mov.b32 	%r6732, %f8573;
	// begin inline asm
	div.full.f32 %r7017, %r6732, %r6586;
	// end inline asm
	mov.b32 	%r6735, %f8574;
	// begin inline asm
	div.full.f32 %r7018, %r6735, %r6592;
	// end inline asm
	mov.b32 	%r6738, %f8575;
	// begin inline asm
	div.full.f32 %r7019, %r6738, %r6592;
	// end inline asm
	mov.b32 	%r6741, %f8576;
	// begin inline asm
	div.full.f32 %r7020, %r6741, %r6586;
	// end inline asm
	mov.b32 	%r6744, %f8577;
	// begin inline asm
	div.full.f32 %r7021, %r6744, %r6586;
	// end inline asm
	mov.b32 	%r6747, %f8578;
	// begin inline asm
	div.full.f32 %r7022, %r6747, %r6592;
	// end inline asm
	mov.b32 	%r6750, %f8579;
	// begin inline asm
	div.full.f32 %r7023, %r6750, %r6592;
	// end inline asm
	mov.b32 	%r6753, %f8580;
	// begin inline asm
	div.full.f32 %r7024, %r6753, %r6586;
	// end inline asm
	mov.b32 	%r6756, %f8581;
	// begin inline asm
	div.full.f32 %r7025, %r6756, %r6586;
	// end inline asm
	mov.b32 	%r6759, %f8582;
	// begin inline asm
	div.full.f32 %r7026, %r6759, %r6592;
	// end inline asm
	mov.b32 	%r6762, %f8583;
	// begin inline asm
	div.full.f32 %r7027, %r6762, %r6592;
	// end inline asm
	mov.b32 	%r6765, %f8584;
	// begin inline asm
	div.full.f32 %r7028, %r6765, %r6586;
	// end inline asm
	mov.b32 	%r6768, %f8585;
	// begin inline asm
	div.full.f32 %r7029, %r6768, %r6586;
	// end inline asm
	mov.b32 	%r6771, %f8586;
	// begin inline asm
	div.full.f32 %r7030, %r6771, %r6592;
	// end inline asm
	mov.b32 	%r6774, %f8587;
	// begin inline asm
	div.full.f32 %r7031, %r6774, %r6592;
	// end inline asm
	mov.b32 	%r6777, %f8588;
	mov.b32 	%r6778, %f8790;
	// begin inline asm
	div.full.f32 %r7032, %r6777, %r6778;
	// end inline asm
	mov.b32 	%r6780, %f8589;
	// begin inline asm
	div.full.f32 %r7033, %r6780, %r6778;
	// end inline asm
	mov.b32 	%r6783, %f8590;
	mov.b32 	%r6784, %f8791;
	// begin inline asm
	div.full.f32 %r7034, %r6783, %r6784;
	// end inline asm
	mov.b32 	%r6786, %f8591;
	// begin inline asm
	div.full.f32 %r7035, %r6786, %r6784;
	// end inline asm
	mov.b32 	%r6789, %f8592;
	// begin inline asm
	div.full.f32 %r7036, %r6789, %r6778;
	// end inline asm
	mov.b32 	%r6792, %f8593;
	// begin inline asm
	div.full.f32 %r7037, %r6792, %r6778;
	// end inline asm
	mov.b32 	%r6795, %f8594;
	// begin inline asm
	div.full.f32 %r7038, %r6795, %r6784;
	// end inline asm
	mov.b32 	%r6798, %f8595;
	// begin inline asm
	div.full.f32 %r7039, %r6798, %r6784;
	// end inline asm
	mov.b32 	%r6801, %f8596;
	// begin inline asm
	div.full.f32 %r7040, %r6801, %r6778;
	// end inline asm
	mov.b32 	%r6804, %f8597;
	// begin inline asm
	div.full.f32 %r7041, %r6804, %r6778;
	// end inline asm
	mov.b32 	%r6807, %f8598;
	// begin inline asm
	div.full.f32 %r7042, %r6807, %r6784;
	// end inline asm
	mov.b32 	%r6810, %f8599;
	// begin inline asm
	div.full.f32 %r7043, %r6810, %r6784;
	// end inline asm
	mov.b32 	%r6813, %f8600;
	// begin inline asm
	div.full.f32 %r7044, %r6813, %r6778;
	// end inline asm
	mov.b32 	%r6816, %f8601;
	// begin inline asm
	div.full.f32 %r7045, %r6816, %r6778;
	// end inline asm
	mov.b32 	%r6819, %f8602;
	// begin inline asm
	div.full.f32 %r7046, %r6819, %r6784;
	// end inline asm
	mov.b32 	%r6822, %f8603;
	// begin inline asm
	div.full.f32 %r7047, %r6822, %r6784;
	// end inline asm
	mov.b32 	%r6825, %f8604;
	// begin inline asm
	div.full.f32 %r7048, %r6825, %r6778;
	// end inline asm
	mov.b32 	%r6828, %f8605;
	// begin inline asm
	div.full.f32 %r7049, %r6828, %r6778;
	// end inline asm
	mov.b32 	%r6831, %f8606;
	// begin inline asm
	div.full.f32 %r7050, %r6831, %r6784;
	// end inline asm
	mov.b32 	%r6834, %f8607;
	// begin inline asm
	div.full.f32 %r7051, %r6834, %r6784;
	// end inline asm
	mov.b32 	%r6837, %f8608;
	// begin inline asm
	div.full.f32 %r7052, %r6837, %r6778;
	// end inline asm
	mov.b32 	%r6840, %f8609;
	// begin inline asm
	div.full.f32 %r7053, %r6840, %r6778;
	// end inline asm
	mov.b32 	%r6843, %f8610;
	// begin inline asm
	div.full.f32 %r7054, %r6843, %r6784;
	// end inline asm
	mov.b32 	%r6846, %f8611;
	// begin inline asm
	div.full.f32 %r7055, %r6846, %r6784;
	// end inline asm
	mov.b32 	%r6849, %f8612;
	// begin inline asm
	div.full.f32 %r7056, %r6849, %r6778;
	// end inline asm
	mov.b32 	%r6852, %f8613;
	// begin inline asm
	div.full.f32 %r7057, %r6852, %r6778;
	// end inline asm
	mov.b32 	%r6855, %f8614;
	// begin inline asm
	div.full.f32 %r7058, %r6855, %r6784;
	// end inline asm
	mov.b32 	%r6858, %f8615;
	// begin inline asm
	div.full.f32 %r7059, %r6858, %r6784;
	// end inline asm
	mov.b32 	%r6861, %f8616;
	// begin inline asm
	div.full.f32 %r7060, %r6861, %r6778;
	// end inline asm
	mov.b32 	%r6864, %f8617;
	// begin inline asm
	div.full.f32 %r7061, %r6864, %r6778;
	// end inline asm
	mov.b32 	%r6867, %f8618;
	// begin inline asm
	div.full.f32 %r7062, %r6867, %r6784;
	// end inline asm
	mov.b32 	%r6870, %f8619;
	// begin inline asm
	div.full.f32 %r7063, %r6870, %r6784;
	// end inline asm
	mov.b32 	%r6873, %f8620;
	// begin inline asm
	div.full.f32 %r7064, %r6873, %r6778;
	// end inline asm
	mov.b32 	%r6876, %f8621;
	// begin inline asm
	div.full.f32 %r7065, %r6876, %r6778;
	// end inline asm
	mov.b32 	%r6879, %f8622;
	// begin inline asm
	div.full.f32 %r7066, %r6879, %r6784;
	// end inline asm
	mov.b32 	%r6882, %f8623;
	// begin inline asm
	div.full.f32 %r7067, %r6882, %r6784;
	// end inline asm
	mov.b32 	%r6885, %f8624;
	// begin inline asm
	div.full.f32 %r7068, %r6885, %r6778;
	// end inline asm
	mov.b32 	%r6888, %f8625;
	// begin inline asm
	div.full.f32 %r7069, %r6888, %r6778;
	// end inline asm
	mov.b32 	%r6891, %f8626;
	// begin inline asm
	div.full.f32 %r7070, %r6891, %r6784;
	// end inline asm
	mov.b32 	%r6894, %f8627;
	// begin inline asm
	div.full.f32 %r7071, %r6894, %r6784;
	// end inline asm
	mov.b32 	%r6897, %f8628;
	// begin inline asm
	div.full.f32 %r7072, %r6897, %r6778;
	// end inline asm
	mov.b32 	%r6900, %f8629;
	// begin inline asm
	div.full.f32 %r7073, %r6900, %r6778;
	// end inline asm
	mov.b32 	%r6903, %f8630;
	// begin inline asm
	div.full.f32 %r7074, %r6903, %r6784;
	// end inline asm
	mov.b32 	%r6906, %f8631;
	// begin inline asm
	div.full.f32 %r7075, %r6906, %r6784;
	// end inline asm
	mov.b32 	%r6909, %f8632;
	// begin inline asm
	div.full.f32 %r7076, %r6909, %r6778;
	// end inline asm
	mov.b32 	%r6912, %f8633;
	// begin inline asm
	div.full.f32 %r7077, %r6912, %r6778;
	// end inline asm
	mov.b32 	%r6915, %f8634;
	// begin inline asm
	div.full.f32 %r7078, %r6915, %r6784;
	// end inline asm
	mov.b32 	%r6918, %f8635;
	// begin inline asm
	div.full.f32 %r7079, %r6918, %r6784;
	// end inline asm
	mov.b32 	%r6921, %f8636;
	// begin inline asm
	div.full.f32 %r7080, %r6921, %r6778;
	// end inline asm
	mov.b32 	%r6924, %f8637;
	// begin inline asm
	div.full.f32 %r7081, %r6924, %r6778;
	// end inline asm
	mov.b32 	%r6927, %f8638;
	// begin inline asm
	div.full.f32 %r7082, %r6927, %r6784;
	// end inline asm
	mov.b32 	%r6930, %f8639;
	// begin inline asm
	div.full.f32 %r7083, %r6930, %r6784;
	// end inline asm
	mov.b32 	%r6933, %f8640;
	// begin inline asm
	div.full.f32 %r7084, %r6933, %r6778;
	// end inline asm
	mov.b32 	%r6936, %f8641;
	// begin inline asm
	div.full.f32 %r7085, %r6936, %r6778;
	// end inline asm
	mov.b32 	%r6939, %f8642;
	// begin inline asm
	div.full.f32 %r7086, %r6939, %r6784;
	// end inline asm
	mov.b32 	%r6942, %f8643;
	// begin inline asm
	div.full.f32 %r7087, %r6942, %r6784;
	// end inline asm
	mov.b32 	%r6945, %f8644;
	// begin inline asm
	div.full.f32 %r7088, %r6945, %r6778;
	// end inline asm
	mov.b32 	%r6948, %f8645;
	// begin inline asm
	div.full.f32 %r7089, %r6948, %r6778;
	// end inline asm
	mov.b32 	%r6951, %f8646;
	// begin inline asm
	div.full.f32 %r7090, %r6951, %r6784;
	// end inline asm
	mov.b32 	%r6954, %f8647;
	// begin inline asm
	div.full.f32 %r7091, %r6954, %r6784;
	// end inline asm
	mov.b32 	%r6957, %f8648;
	// begin inline asm
	div.full.f32 %r7092, %r6957, %r6778;
	// end inline asm
	mov.b32 	%r6960, %f8649;
	// begin inline asm
	div.full.f32 %r7093, %r6960, %r6778;
	// end inline asm
	mov.b32 	%r6963, %f8650;
	// begin inline asm
	div.full.f32 %r7094, %r6963, %r6784;
	// end inline asm
	mov.b32 	%r6966, %f8651;
	// begin inline asm
	div.full.f32 %r7095, %r6966, %r6784;
	// end inline asm
	.loc	1 275 13                        // prefix_prefill.py:275:13
	mad.lo.s32 	%r7224, %r675, %r671, %r23;
	.loc	1 275 36                        // prefix_prefill.py:275:36
	mad.lo.s32 	%r7225, %r49, %r670, %r7224;
	mad.lo.s32 	%r7226, %r50, %r670, %r7224;
	mad.lo.s32 	%r7227, %r51, %r670, %r7224;
	mad.lo.s32 	%r7228, %r52, %r670, %r7224;
	mad.lo.s32 	%r7229, %r53, %r670, %r7224;
	mad.lo.s32 	%r7230, %r54, %r670, %r7224;
	mad.lo.s32 	%r7231, %r55, %r670, %r7224;
	mad.lo.s32 	%r7232, %r56, %r670, %r7224;
	mad.lo.s32 	%r7233, %r57, %r670, %r7224;
	mad.lo.s32 	%r7234, %r58, %r670, %r7224;
	mad.lo.s32 	%r7235, %r59, %r670, %r7224;
	mad.lo.s32 	%r7236, %r60, %r670, %r7224;
	mad.lo.s32 	%r7237, %r61, %r670, %r7224;
	mad.lo.s32 	%r7238, %r62, %r670, %r7224;
	mad.lo.s32 	%r7239, %r63, %r670, %r7224;
	mad.lo.s32 	%r7240, %r64, %r670, %r7224;
	.loc	1 276 21                        // prefix_prefill.py:276:21
	mul.wide.s32 	%rd518, %r7225, 2;
	add.s64 	%rd502, %rd112, %rd518;
	mul.wide.s32 	%rd519, %r7226, 2;
	add.s64 	%rd503, %rd112, %rd519;
	mul.wide.s32 	%rd520, %r7227, 2;
	add.s64 	%rd504, %rd112, %rd520;
	mul.wide.s32 	%rd521, %r7228, 2;
	add.s64 	%rd505, %rd112, %rd521;
	mul.wide.s32 	%rd522, %r7229, 2;
	add.s64 	%rd506, %rd112, %rd522;
	mul.wide.s32 	%rd523, %r7230, 2;
	add.s64 	%rd507, %rd112, %rd523;
	mul.wide.s32 	%rd524, %r7231, 2;
	add.s64 	%rd508, %rd112, %rd524;
	mul.wide.s32 	%rd525, %r7232, 2;
	add.s64 	%rd509, %rd112, %rd525;
	mul.wide.s32 	%rd526, %r7233, 2;
	add.s64 	%rd510, %rd112, %rd526;
	mul.wide.s32 	%rd527, %r7234, 2;
	add.s64 	%rd511, %rd112, %rd527;
	mul.wide.s32 	%rd528, %r7235, 2;
	add.s64 	%rd512, %rd112, %rd528;
	mul.wide.s32 	%rd529, %r7236, 2;
	add.s64 	%rd513, %rd112, %rd529;
	mul.wide.s32 	%rd530, %r7237, 2;
	add.s64 	%rd514, %rd112, %rd530;
	mul.wide.s32 	%rd531, %r7238, 2;
	add.s64 	%rd515, %rd112, %rd531;
	mul.wide.s32 	%rd532, %r7239, 2;
	add.s64 	%rd516, %rd112, %rd532;
	mul.wide.s32 	%rd533, %r7240, 2;
	add.s64 	%rd517, %rd112, %rd533;
	.loc	1 278 13                        // prefix_prefill.py:278:13
	// begin inline asm
	cvt.rn.bf16.f32 %rs736, %r6968;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs737, %r6969;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs738, %r6970;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs739, %r6971;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs740, %r6972;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs741, %r6973;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs742, %r6974;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs743, %r6975;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs744, %r6976;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs745, %r6977;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs746, %r6978;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs747, %r6979;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs748, %r6980;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs749, %r6981;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs750, %r6982;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs751, %r6983;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs752, %r6984;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs753, %r6985;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs754, %r6986;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs755, %r6987;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs756, %r6988;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs757, %r6989;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs758, %r6990;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs759, %r6991;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs760, %r6992;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs761, %r6993;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs762, %r6994;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs763, %r6995;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs764, %r6996;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs765, %r6997;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs766, %r6998;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs767, %r6999;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs768, %r7000;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs769, %r7001;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs770, %r7002;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs771, %r7003;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs772, %r7004;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs773, %r7005;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs774, %r7006;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs775, %r7007;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs776, %r7008;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs777, %r7009;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs778, %r7010;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs779, %r7011;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs780, %r7012;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs781, %r7013;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs782, %r7014;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs783, %r7015;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs784, %r7016;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs785, %r7017;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs786, %r7018;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs787, %r7019;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs788, %r7020;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs789, %r7021;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs790, %r7022;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs791, %r7023;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs792, %r7024;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs793, %r7025;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs794, %r7026;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs795, %r7027;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs796, %r7028;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs797, %r7029;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs798, %r7030;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs799, %r7031;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs800, %r7032;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs801, %r7033;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs802, %r7034;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs803, %r7035;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs804, %r7036;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs805, %r7037;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs806, %r7038;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs807, %r7039;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs808, %r7040;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs809, %r7041;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs810, %r7042;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs811, %r7043;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs812, %r7044;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs813, %r7045;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs814, %r7046;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs815, %r7047;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs816, %r7048;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs817, %r7049;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs818, %r7050;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs819, %r7051;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs820, %r7052;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs821, %r7053;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs822, %r7054;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs823, %r7055;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs824, %r7056;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs825, %r7057;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs826, %r7058;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs827, %r7059;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs828, %r7060;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs829, %r7061;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs830, %r7062;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs831, %r7063;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs832, %r7064;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs833, %r7065;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs834, %r7066;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs835, %r7067;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs836, %r7068;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs837, %r7069;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs838, %r7070;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs839, %r7071;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs840, %r7072;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs841, %r7073;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs842, %r7074;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs843, %r7075;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs844, %r7076;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs845, %r7077;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs846, %r7078;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs847, %r7079;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs848, %r7080;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs849, %r7081;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs850, %r7082;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs851, %r7083;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs852, %r7084;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs853, %r7085;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs854, %r7086;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs855, %r7087;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs856, %r7088;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs857, %r7089;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs858, %r7090;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs859, %r7091;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs860, %r7092;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs861, %r7093;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs862, %r7094;
	// end inline asm
	// begin inline asm
	cvt.rn.bf16.f32 %rs863, %r7095;
	// end inline asm
	bar.sync 	0;
	shl.b32 	%r7241, %r7, 5;
	and.b32  	%r7242, %r7241, 896;
	or.b32  	%r7243, %r10, %r11;
	shl.b32 	%r7244, %r7243, 6;
	or.b32  	%r7245, %r7244, %r7242;
	or.b32  	%r7246, %r7245, %r68;
	and.b32  	%r7247, %r20, 1016;
	shr.u32 	%r7248, %r7245, 4;
	add.s32 	%r7249, %r7248, %r7246;
	shl.b32 	%r7250, %r7249, 1;
	add.s32 	%r7096, %r912, %r7250;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7096 + 0 ], { %rs736, %rs737 };
	// end inline asm
	or.b32  	%r7252, %r7245, 1024;
	shr.u32 	%r7253, %r7252, 4;
	add.s32 	%r7254, %r7253, %r7246;
	shl.b32 	%r7255, %r7254, 1;
	add.s32 	%r7256, %r912, %r7255;
	add.s32 	%r7097, %r7256, 2048;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7097 + 0 ], { %rs738, %rs739 };
	// end inline asm
	add.s32 	%r7098, %r7096, 16;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7098 + 0 ], { %rs740, %rs741 };
	// end inline asm
	add.s32 	%r7099, %r7256, 2064;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7099 + 0 ], { %rs742, %rs743 };
	// end inline asm
	add.s32 	%r7100, %r7096, 32;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7100 + 0 ], { %rs744, %rs745 };
	// end inline asm
	and.b32  	%r7257, %r7253, 504;
	add.s32 	%r7258, %r7257, %r7246;
	shl.b32 	%r7259, %r7258, 1;
	add.s32 	%r7260, %r912, %r7259;
	add.s32 	%r7101, %r7260, 2080;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7101 + 0 ], { %rs746, %rs747 };
	// end inline asm
	add.s32 	%r7102, %r7096, 48;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7102 + 0 ], { %rs748, %rs749 };
	// end inline asm
	add.s32 	%r7103, %r7260, 2096;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7103 + 0 ], { %rs750, %rs751 };
	// end inline asm
	add.s32 	%r7104, %r7096, 64;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7104 + 0 ], { %rs752, %rs753 };
	// end inline asm
	add.s32 	%r7105, %r7260, 2112;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7105 + 0 ], { %rs754, %rs755 };
	// end inline asm
	add.s32 	%r7106, %r7096, 80;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7106 + 0 ], { %rs756, %rs757 };
	// end inline asm
	add.s32 	%r7107, %r7260, 2128;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7107 + 0 ], { %rs758, %rs759 };
	// end inline asm
	add.s32 	%r7108, %r7096, 96;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7108 + 0 ], { %rs760, %rs761 };
	// end inline asm
	add.s32 	%r7109, %r7260, 2144;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7109 + 0 ], { %rs762, %rs763 };
	// end inline asm
	add.s32 	%r7110, %r7096, 112;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7110 + 0 ], { %rs764, %rs765 };
	// end inline asm
	add.s32 	%r7111, %r7260, 2160;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7111 + 0 ], { %rs766, %rs767 };
	// end inline asm
	add.s32 	%r7112, %r7096, 128;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7112 + 0 ], { %rs768, %rs769 };
	// end inline asm
	add.s32 	%r7113, %r7260, 2176;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7113 + 0 ], { %rs770, %rs771 };
	// end inline asm
	add.s32 	%r7114, %r7096, 144;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7114 + 0 ], { %rs772, %rs773 };
	// end inline asm
	add.s32 	%r7115, %r7260, 2192;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7115 + 0 ], { %rs774, %rs775 };
	// end inline asm
	add.s32 	%r7116, %r7096, 160;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7116 + 0 ], { %rs776, %rs777 };
	// end inline asm
	add.s32 	%r7117, %r7260, 2208;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7117 + 0 ], { %rs778, %rs779 };
	// end inline asm
	add.s32 	%r7118, %r7096, 176;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7118 + 0 ], { %rs780, %rs781 };
	// end inline asm
	add.s32 	%r7119, %r7260, 2224;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7119 + 0 ], { %rs782, %rs783 };
	// end inline asm
	add.s32 	%r7120, %r7096, 192;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7120 + 0 ], { %rs784, %rs785 };
	// end inline asm
	add.s32 	%r7121, %r7260, 2240;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7121 + 0 ], { %rs786, %rs787 };
	// end inline asm
	add.s32 	%r7122, %r7096, 208;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7122 + 0 ], { %rs788, %rs789 };
	// end inline asm
	add.s32 	%r7123, %r7260, 2256;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7123 + 0 ], { %rs790, %rs791 };
	// end inline asm
	add.s32 	%r7124, %r7096, 224;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7124 + 0 ], { %rs792, %rs793 };
	// end inline asm
	add.s32 	%r7125, %r7260, 2272;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7125 + 0 ], { %rs794, %rs795 };
	// end inline asm
	add.s32 	%r7126, %r7096, 240;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7126 + 0 ], { %rs796, %rs797 };
	// end inline asm
	add.s32 	%r7127, %r7260, 2288;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7127 + 0 ], { %rs798, %rs799 };
	// end inline asm
	bar.sync 	0;
	shr.u32 	%r7261, %r20, 4;
	and.b32  	%r7262, %r7261, 56;
	add.s32 	%r7263, %r7262, %r7247;
	shl.b32 	%r7264, %r7263, 1;
	add.s32 	%r7265, %r912, %r7264;
	ld.shared.v4.u32 	{%r7160, %r7161, %r7162, %r7163}, [%r7265];
	or.b32  	%r7266, %r7247, 1024;
	shr.u32 	%r7267, %r7266, 4;
	and.b32  	%r7268, %r7267, 120;
	add.s32 	%r7269, %r7268, %r7247;
	shl.b32 	%r7270, %r7269, 1;
	add.s32 	%r7271, %r912, %r7270;
	ld.shared.v4.u32 	{%r7164, %r7165, %r7166, %r7167}, [%r7271+2048];
	or.b32  	%r7272, %r7247, 2048;
	shr.u32 	%r7273, %r7272, 4;
	and.b32  	%r7274, %r7273, 184;
	add.s32 	%r7275, %r7274, %r7247;
	shl.b32 	%r7276, %r7275, 1;
	add.s32 	%r7277, %r912, %r7276;
	ld.shared.v4.u32 	{%r7168, %r7169, %r7170, %r7171}, [%r7277+4096];
	or.b32  	%r7278, %r7247, 3072;
	shr.u32 	%r7279, %r7278, 4;
	and.b32  	%r7280, %r7279, 248;
	add.s32 	%r7281, %r7280, %r7247;
	shl.b32 	%r7282, %r7281, 1;
	add.s32 	%r7283, %r912, %r7282;
	ld.shared.v4.u32 	{%r7172, %r7173, %r7174, %r7175}, [%r7283+6144];
	or.b32  	%r7284, %r7247, 4096;
	shr.u32 	%r7285, %r7284, 4;
	and.b32  	%r7286, %r7285, 312;
	add.s32 	%r7287, %r7286, %r7247;
	shl.b32 	%r7288, %r7287, 1;
	add.s32 	%r7289, %r912, %r7288;
	ld.shared.v4.u32 	{%r7176, %r7177, %r7178, %r7179}, [%r7289+8192];
	or.b32  	%r7290, %r7247, 5120;
	shr.u32 	%r7291, %r7290, 4;
	and.b32  	%r7292, %r7291, 376;
	add.s32 	%r7293, %r7292, %r7247;
	shl.b32 	%r7294, %r7293, 1;
	add.s32 	%r7295, %r912, %r7294;
	ld.shared.v4.u32 	{%r7180, %r7181, %r7182, %r7183}, [%r7295+10240];
	or.b32  	%r7296, %r7247, 6144;
	shr.u32 	%r7297, %r7296, 4;
	and.b32  	%r7298, %r7297, 440;
	add.s32 	%r7299, %r7298, %r7247;
	shl.b32 	%r7300, %r7299, 1;
	add.s32 	%r7301, %r912, %r7300;
	ld.shared.v4.u32 	{%r7184, %r7185, %r7186, %r7187}, [%r7301+12288];
	or.b32  	%r7302, %r7247, 7168;
	shr.u32 	%r7303, %r7302, 4;
	and.b32  	%r7304, %r7303, 504;
	add.s32 	%r7305, %r7304, %r7247;
	shl.b32 	%r7306, %r7305, 1;
	add.s32 	%r7307, %r912, %r7306;
	ld.shared.v4.u32 	{%r7188, %r7189, %r7190, %r7191}, [%r7307+14336];
	bar.sync 	0;
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7096 + 0 ], { %rs800, %rs801 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7097 + 0 ], { %rs802, %rs803 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7098 + 0 ], { %rs804, %rs805 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7099 + 0 ], { %rs806, %rs807 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7100 + 0 ], { %rs808, %rs809 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7101 + 0 ], { %rs810, %rs811 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7102 + 0 ], { %rs812, %rs813 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7103 + 0 ], { %rs814, %rs815 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7104 + 0 ], { %rs816, %rs817 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7105 + 0 ], { %rs818, %rs819 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7106 + 0 ], { %rs820, %rs821 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7107 + 0 ], { %rs822, %rs823 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7108 + 0 ], { %rs824, %rs825 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7109 + 0 ], { %rs826, %rs827 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7110 + 0 ], { %rs828, %rs829 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7111 + 0 ], { %rs830, %rs831 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7112 + 0 ], { %rs832, %rs833 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7113 + 0 ], { %rs834, %rs835 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7114 + 0 ], { %rs836, %rs837 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7115 + 0 ], { %rs838, %rs839 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7116 + 0 ], { %rs840, %rs841 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7117 + 0 ], { %rs842, %rs843 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7118 + 0 ], { %rs844, %rs845 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7119 + 0 ], { %rs846, %rs847 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7120 + 0 ], { %rs848, %rs849 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7121 + 0 ], { %rs850, %rs851 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7122 + 0 ], { %rs852, %rs853 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7123 + 0 ], { %rs854, %rs855 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7124 + 0 ], { %rs856, %rs857 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7125 + 0 ], { %rs858, %rs859 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7126 + 0 ], { %rs860, %rs861 };
	// end inline asm
	// begin inline asm
	@%p546 st.shared.v2.b16 [ %r7127 + 0 ], { %rs862, %rs863 };
	// end inline asm
	bar.sync 	0;
	ld.shared.v4.u32 	{%r7192, %r7193, %r7194, %r7195}, [%r7265];
	ld.shared.v4.u32 	{%r7196, %r7197, %r7198, %r7199}, [%r7271+2048];
	ld.shared.v4.u32 	{%r7200, %r7201, %r7202, %r7203}, [%r7277+4096];
	ld.shared.v4.u32 	{%r7204, %r7205, %r7206, %r7207}, [%r7283+6144];
	ld.shared.v4.u32 	{%r7208, %r7209, %r7210, %r7211}, [%r7289+8192];
	ld.shared.v4.u32 	{%r7212, %r7213, %r7214, %r7215}, [%r7295+10240];
	ld.shared.v4.u32 	{%r7216, %r7217, %r7218, %r7219}, [%r7301+12288];
	ld.shared.v4.u32 	{%r7220, %r7221, %r7222, %r7223}, [%r7307+14336];
	// begin inline asm
	@%p4 st.global.v4.b32 [ %rd502 + 0 ], { %r7160, %r7161, %r7162, %r7163 };
	// end inline asm
	// begin inline asm
	@%p9 st.global.v4.b32 [ %rd503 + 0 ], { %r7164, %r7165, %r7166, %r7167 };
	// end inline asm
	// begin inline asm
	@%p14 st.global.v4.b32 [ %rd504 + 0 ], { %r7168, %r7169, %r7170, %r7171 };
	// end inline asm
	// begin inline asm
	@%p19 st.global.v4.b32 [ %rd505 + 0 ], { %r7172, %r7173, %r7174, %r7175 };
	// end inline asm
	// begin inline asm
	@%p24 st.global.v4.b32 [ %rd506 + 0 ], { %r7176, %r7177, %r7178, %r7179 };
	// end inline asm
	// begin inline asm
	@%p29 st.global.v4.b32 [ %rd507 + 0 ], { %r7180, %r7181, %r7182, %r7183 };
	// end inline asm
	// begin inline asm
	@%p34 st.global.v4.b32 [ %rd508 + 0 ], { %r7184, %r7185, %r7186, %r7187 };
	// end inline asm
	// begin inline asm
	@%p39 st.global.v4.b32 [ %rd509 + 0 ], { %r7188, %r7189, %r7190, %r7191 };
	// end inline asm
	// begin inline asm
	@%p44 st.global.v4.b32 [ %rd510 + 0 ], { %r7192, %r7193, %r7194, %r7195 };
	// end inline asm
	// begin inline asm
	@%p49 st.global.v4.b32 [ %rd511 + 0 ], { %r7196, %r7197, %r7198, %r7199 };
	// end inline asm
	// begin inline asm
	@%p54 st.global.v4.b32 [ %rd512 + 0 ], { %r7200, %r7201, %r7202, %r7203 };
	// end inline asm
	// begin inline asm
	@%p59 st.global.v4.b32 [ %rd513 + 0 ], { %r7204, %r7205, %r7206, %r7207 };
	// end inline asm
	// begin inline asm
	@%p64 st.global.v4.b32 [ %rd514 + 0 ], { %r7208, %r7209, %r7210, %r7211 };
	// end inline asm
	// begin inline asm
	@%p69 st.global.v4.b32 [ %rd515 + 0 ], { %r7212, %r7213, %r7214, %r7215 };
	// end inline asm
	// begin inline asm
	@%p74 st.global.v4.b32 [ %rd516 + 0 ], { %r7216, %r7217, %r7218, %r7219 };
	// end inline asm
	// begin inline asm
	@%p79 st.global.v4.b32 [ %rd517 + 0 ], { %r7220, %r7221, %r7222, %r7223 };
	// end inline asm
	.loc	1 280 4                         // prefix_prefill.py:280:4
	ret;
$L__tmp27:
$L__func_end0:
                                        // -- End function
}
	.file	1 "/opt/conda/envs/rl/lib/python3.10/site-packages/vllm/attention/ops/prefix_prefill.py"
	.file	2 "/opt/conda/envs/rl/lib/python3.10/site-packages/triton/language/standard.py"
	.section	.debug_abbrev
	{
.b8 1                                   // Abbreviation Code
.b8 17                                  // DW_TAG_compile_unit
.b8 1                                   // DW_CHILDREN_yes
.b8 37                                  // DW_AT_producer
.b8 8                                   // DW_FORM_string
.b8 19                                  // DW_AT_language
.b8 5                                   // DW_FORM_data2
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 16                                  // DW_AT_stmt_list
.b8 6                                   // DW_FORM_data4
.b8 27                                  // DW_AT_comp_dir
.b8 8                                   // DW_FORM_string
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 2                                   // Abbreviation Code
.b8 46                                  // DW_TAG_subprogram
.b8 0                                   // DW_CHILDREN_no
.b8 3                                   // DW_AT_name
.b8 8                                   // DW_FORM_string
.b8 32                                  // DW_AT_inline
.b8 11                                  // DW_FORM_data1
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 3                                   // Abbreviation Code
.b8 46                                  // DW_TAG_subprogram
.b8 1                                   // DW_CHILDREN_yes
.b8 17                                  // DW_AT_low_pc
.b8 1                                   // DW_FORM_addr
.b8 18                                  // DW_AT_high_pc
.b8 1                                   // DW_FORM_addr
.b8 49                                  // DW_AT_abstract_origin
.b8 19                                  // DW_FORM_ref4
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 4                                   // Abbreviation Code
.b8 29                                  // DW_TAG_inlined_subroutine
.b8 0                                   // DW_CHILDREN_no
.b8 49                                  // DW_AT_abstract_origin
.b8 19                                  // DW_FORM_ref4
.b8 17                                  // DW_AT_low_pc
.b8 1                                   // DW_FORM_addr
.b8 18                                  // DW_AT_high_pc
.b8 1                                   // DW_FORM_addr
.b8 88                                  // DW_AT_call_file
.b8 11                                  // DW_FORM_data1
.b8 89                                  // DW_AT_call_line
.b8 11                                  // DW_FORM_data1
.b8 87                                  // DW_AT_call_column
.b8 11                                  // DW_FORM_data1
.b8 0                                   // EOM(1)
.b8 0                                   // EOM(2)
.b8 0                                   // EOM(3)
	}
	.section	.debug_info
	{
.b32 239                                // Length of Unit
.b8 2                                   // DWARF version number
.b8 0
.b32 .debug_abbrev                      // Offset Into Abbrev. Section
.b8 8                                   // Address Size (in bytes)
.b8 1                                   // Abbrev [1] 0xb:0xe8 DW_TAG_compile_unit
.b8 116                                 // DW_AT_producer
.b8 114
.b8 105
.b8 116
.b8 111
.b8 110
.b8 0
.b8 2                                   // DW_AT_language
.b8 0
.b8 112                                 // DW_AT_name
.b8 114
.b8 101
.b8 102
.b8 105
.b8 120
.b8 95
.b8 112
.b8 114
.b8 101
.b8 102
.b8 105
.b8 108
.b8 108
.b8 46
.b8 112
.b8 121
.b8 0
.b32 .debug_line                        // DW_AT_stmt_list
.b8 47                                  // DW_AT_comp_dir
.b8 111
.b8 112
.b8 116
.b8 47
.b8 99
.b8 111
.b8 110
.b8 100
.b8 97
.b8 47
.b8 101
.b8 110
.b8 118
.b8 115
.b8 47
.b8 114
.b8 108
.b8 47
.b8 108
.b8 105
.b8 98
.b8 47
.b8 112
.b8 121
.b8 116
.b8 104
.b8 111
.b8 110
.b8 51
.b8 46
.b8 49
.b8 48
.b8 47
.b8 115
.b8 105
.b8 116
.b8 101
.b8 45
.b8 112
.b8 97
.b8 99
.b8 107
.b8 97
.b8 103
.b8 101
.b8 115
.b8 47
.b8 118
.b8 108
.b8 108
.b8 109
.b8 47
.b8 97
.b8 116
.b8 116
.b8 101
.b8 110
.b8 116
.b8 105
.b8 111
.b8 110
.b8 47
.b8 111
.b8 112
.b8 115
.b8 0
.b8 2                                   // Abbrev [2] 0x6e:0xe DW_TAG_subprogram
.b8 95                                  // DW_AT_name
.b8 102
.b8 119
.b8 100
.b8 95
.b8 107
.b8 101
.b8 114
.b8 110
.b8 101
.b8 108
.b8 0
.b8 1                                   // DW_AT_inline
.b8 3                                   // Abbrev [3] 0x7c:0x76 DW_TAG_subprogram
.b64 $L__func_begin0                    // DW_AT_low_pc
.b64 $L__func_end0                      // DW_AT_high_pc
.b32 110                                // DW_AT_abstract_origin
.b8 4                                   // Abbrev [4] 0x91:0x18 DW_TAG_inlined_subroutine
.b32 110                                // DW_AT_abstract_origin
.b64 $L__tmp1                           // DW_AT_low_pc
.b64 $L__tmp18                          // DW_AT_high_pc
.b8 1                                   // DW_AT_call_file
.b8 190                                 // DW_AT_call_line
.b8 38                                  // DW_AT_call_column
.b8 4                                   // Abbrev [4] 0xa9:0x18 DW_TAG_inlined_subroutine
.b32 110                                // DW_AT_abstract_origin
.b64 $L__tmp3                           // DW_AT_low_pc
.b64 $L__tmp20                          // DW_AT_high_pc
.b8 1                                   // DW_AT_call_file
.b8 192                                 // DW_AT_call_line
.b8 22                                  // DW_AT_call_column
.b8 4                                   // Abbrev [4] 0xc1:0x18 DW_TAG_inlined_subroutine
.b32 110                                // DW_AT_abstract_origin
.b64 $L__tmp21                          // DW_AT_low_pc
.b64 $L__tmp22                          // DW_AT_high_pc
.b8 1                                   // DW_AT_call_file
.b8 252                                 // DW_AT_call_line
.b8 38                                  // DW_AT_call_column
.b8 4                                   // Abbrev [4] 0xd9:0x18 DW_TAG_inlined_subroutine
.b32 110                                // DW_AT_abstract_origin
.b64 $L__tmp23                          // DW_AT_low_pc
.b64 $L__tmp26                          // DW_AT_high_pc
.b8 1                                   // DW_AT_call_file
.b8 254                                 // DW_AT_call_line
.b8 22                                  // DW_AT_call_column
.b8 0                                   // End Of Children Mark
.b8 0                                   // End Of Children Mark
	}
	.section	.debug_macinfo	{	}
